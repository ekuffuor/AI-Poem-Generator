{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emmanuel Osei Kuffuor\n",
    "#CIS 5898\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1 text\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "data_set = sorted(glob.glob(\"poetry.txt\"))\n",
    "\n",
    "print(\"Retrieved {} text\".format(len(data_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is 213594 characters long\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "raw_corpus = u\"\"\n",
    "for filename in data_set:\n",
    "    with codecs.open(filename, 'r', 'utf-8') as lit_text:\n",
    "        raw_corpus += lit_text.read()\n",
    "\n",
    "print(\"Corpus is {} characters long\".format(len(raw_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_tables(text):\n",
    "    glossary = set(text)\n",
    "    int_to_glossary = {key: word for key, word in enumerate(glossary)}\n",
    "    glossary_to_int = {word: key for key, word in enumerate(glossary)}\n",
    "    return glossary_to_int, int_to_glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to map punctuation into a token\n",
    "    :return: dictionary mapping punctuation to token\n",
    "    \"\"\"\n",
    "    return {\n",
    "        '.': '||period||',\n",
    "        ',': '||comma||',\n",
    "        '\"': '||quotes||',\n",
    "        ';': '||semicolon||',\n",
    "        '!': '||exclamation-mark||',\n",
    "        '?': '||question-mark||',\n",
    "        '(': '||left-parentheses||',\n",
    "        ')': '||right-parentheses||',\n",
    "        '--': '||emm-dash||',\n",
    "        '\\n': '||return||'\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "token_dict = token_lookup()\n",
    "for token, replacement in token_dict.items():\n",
    "    raw_corpus = raw_corpus.replace(token, ' {} '.format(replacement))\n",
    "raw_corpus = raw_corpus.lower()\n",
    "raw_corpus = raw_corpus.split()\n",
    "\n",
    "glossary_to_int, int_to_glossary = lookup_tables(raw_corpus)\n",
    "corpus_int = [glossary_to_int[word] for word in raw_corpus]\n",
    "pickle.dump((corpus_int, glossary_to_int, int_to_glossary, token_dict), open('preprocess.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_batches(int_text, n_batch, n_seq):\n",
    "   \n",
    "    words_per_batch = n_batch * n_seq\n",
    "    batch_num = len(int_text)//words_per_batch\n",
    "    int_text = int_text[:batch_num*words_per_batch]\n",
    "    y = np.array(int_text[1:] + [int_text[0]])\n",
    "    x = np.array(int_text)\n",
    "    \n",
    "    x_batches = np.split(x.reshape(n_batch, -1), batch_num, axis=1)\n",
    "    y_batches = np.split(y.reshape(n_batch, -1), batch_num, axis=1)\n",
    "    \n",
    "    batch_data = list(zip(x_batches, y_batches))\n",
    "    \n",
    "    return np.array(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 3000\n",
    "n_batch = 250\n",
    "n_rnn = 512\n",
    "n_layer = 3\n",
    "keep_prob = 0.7\n",
    "embed_dim = 512\n",
    "n_seq = 30\n",
    "learning_rate = 0.001\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():    \n",
    "    \n",
    "    # Initialize input placeholders\n",
    "    input_text = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    \n",
    "    # Calculate text attributes\n",
    "    glossary_size = len(int_to_glossary)\n",
    "    input_text_shape = tf.shape(input_text)\n",
    "    \n",
    "    # Build the RNN cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(num_units=n_rnn)\n",
    "    drop_cell = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop_cell] * n_layer)\n",
    "    \n",
    "    # Set the initial state\n",
    "    initial_state = cell.zero_state(input_text_shape[0], tf.float32)\n",
    "    initial_state = tf.identity(initial_state, name='initial_state')\n",
    "    \n",
    "    # Create word embedding as input to RNN\n",
    "    embed = tf.contrib.layers.embed_sequence(input_text, glossary_size, embed_dim)\n",
    "    \n",
    "    # Build RNN\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, name='final_state')\n",
    "\n",
    " # Take RNN output and make logits\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, glossary_size, activation_fn=None)\n",
    "    \n",
    "    # Calculate the probability of generating each word\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "    \n",
    "    # Define loss function\n",
    "    cost = tf.contrib.seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_text_shape[0], input_text_shape[1]])\n",
    "    )\n",
    "    \n",
    "    # Learning rate optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # Gradient clipping to avoid exploding gradients\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch    6/6   train_loss = 8.105   time_elapsed = 39.457   time_remaining = 118331\n",
      "Model Trained and Saved\n",
      "Epoch   2 Batch    6/6   train_loss = 6.552   time_elapsed = 42.231   time_remaining = 63304\n",
      "Epoch   3 Batch    6/6   train_loss = 6.442   time_elapsed = 44.361   time_remaining = 44317\n",
      "Epoch   4 Batch    6/6   train_loss = 6.352   time_elapsed = 46.584   time_remaining = 34891\n",
      "Epoch   5 Batch    6/6   train_loss = 6.286   time_elapsed = 48.709   time_remaining = 29176\n",
      "Epoch   6 Batch    6/6   train_loss = 6.264   time_elapsed = 50.850   time_remaining = 25374\n",
      "Epoch   7 Batch    6/6   train_loss = 6.241   time_elapsed = 52.997   time_remaining = 22660\n",
      "Epoch   8 Batch    6/6   train_loss = 6.223   time_elapsed = 55.137   time_remaining = 20621\n",
      "Epoch   9 Batch    6/6   train_loss = 6.219   time_elapsed = 57.280   time_remaining = 19036\n",
      "Epoch  10 Batch    6/6   train_loss = 6.207   time_elapsed = 59.423   time_remaining = 17767\n",
      "Epoch  11 Batch    6/6   train_loss = 6.205   time_elapsed = 61.565   time_remaining = 16729\n",
      "Model Trained and Saved\n",
      "Epoch  12 Batch    6/6   train_loss = 6.204   time_elapsed = 64.114   time_remaining = 15964\n",
      "Epoch  13 Batch    6/6   train_loss = 6.200   time_elapsed = 66.269   time_remaining = 15227\n",
      "Epoch  14 Batch    6/6   train_loss = 6.204   time_elapsed = 68.438   time_remaining = 14597\n",
      "Epoch  15 Batch    6/6   train_loss = 6.198   time_elapsed = 70.603   time_remaining = 14050\n",
      "Epoch  16 Batch    6/6   train_loss = 6.192   time_elapsed = 72.770   time_remaining = 13572\n",
      "Epoch  17 Batch    6/6   train_loss = 6.192   time_elapsed = 74.925   time_remaining = 13147\n",
      "Epoch  18 Batch    6/6   train_loss = 6.193   time_elapsed = 77.086   time_remaining = 12771\n",
      "Epoch  19 Batch    6/6   train_loss = 6.188   time_elapsed = 79.253   time_remaining = 12434\n",
      "Epoch  20 Batch    6/6   train_loss = 6.188   time_elapsed = 81.595   time_remaining = 12158\n",
      "Epoch  21 Batch    6/6   train_loss = 6.182   time_elapsed = 83.767   time_remaining = 11883\n",
      "Model Trained and Saved\n",
      "Epoch  22 Batch    6/6   train_loss = 6.176   time_elapsed = 86.335   time_remaining = 11687\n",
      "Epoch  23 Batch    6/6   train_loss = 6.175   time_elapsed = 88.497   time_remaining = 11455\n",
      "Epoch  24 Batch    6/6   train_loss = 6.176   time_elapsed = 90.662   time_remaining = 11242\n",
      "Epoch  25 Batch    6/6   train_loss = 6.172   time_elapsed = 92.939   time_remaining = 11060\n",
      "Epoch  26 Batch    6/6   train_loss = 6.172   time_elapsed = 95.105   time_remaining = 10879\n",
      "Epoch  27 Batch    6/6   train_loss = 6.167   time_elapsed = 97.288   time_remaining = 10712\n",
      "Epoch  28 Batch    6/6   train_loss = 6.167   time_elapsed = 99.567   time_remaining = 10568\n",
      "Epoch  29 Batch    6/6   train_loss = 6.168   time_elapsed = 101.734   time_remaining = 10422\n",
      "Epoch  30 Batch    6/6   train_loss = 6.162   time_elapsed = 103.915   time_remaining = 10288\n",
      "Epoch  31 Batch    6/6   train_loss = 6.161   time_elapsed = 106.079   time_remaining = 10160\n",
      "Model Trained and Saved\n",
      "Epoch  32 Batch    6/6   train_loss = 6.158   time_elapsed = 108.638   time_remaining = 10076\n",
      "Epoch  33 Batch    6/6   train_loss = 6.159   time_elapsed = 110.799   time_remaining = 9962\n",
      "Epoch  34 Batch    6/6   train_loss = 6.156   time_elapsed = 112.959   time_remaining = 9854\n",
      "Epoch  35 Batch    6/6   train_loss = 6.150   time_elapsed = 115.117   time_remaining = 9752\n",
      "Epoch  36 Batch    6/6   train_loss = 6.148   time_elapsed = 117.255   time_remaining = 9654\n",
      "Epoch  37 Batch    6/6   train_loss = 6.152   time_elapsed = 119.400   time_remaining = 9562\n",
      "Epoch  38 Batch    6/6   train_loss = 6.148   time_elapsed = 121.555   time_remaining = 9475\n",
      "Epoch  39 Batch    6/6   train_loss = 6.145   time_elapsed = 123.684   time_remaining = 9390\n",
      "Epoch  40 Batch    6/6   train_loss = 6.147   time_elapsed = 125.819   time_remaining = 9311\n",
      "Epoch  41 Batch    6/6   train_loss = 6.143   time_elapsed = 127.964   time_remaining = 9235\n",
      "Model Trained and Saved\n",
      "Epoch  42 Batch    6/6   train_loss = 6.139   time_elapsed = 130.556   time_remaining = 9195\n",
      "Epoch  43 Batch    6/6   train_loss = 6.139   time_elapsed = 132.692   time_remaining = 9125\n",
      "Epoch  44 Batch    6/6   train_loss = 6.141   time_elapsed = 134.830   time_remaining = 9058\n",
      "Epoch  45 Batch    6/6   train_loss = 6.133   time_elapsed = 136.970   time_remaining = 8994\n",
      "Epoch  46 Batch    6/6   train_loss = 6.132   time_elapsed = 139.099   time_remaining = 8933\n",
      "Epoch  47 Batch    6/6   train_loss = 6.129   time_elapsed = 141.237   time_remaining = 8874\n",
      "Epoch  48 Batch    6/6   train_loss = 6.129   time_elapsed = 143.459   time_remaining = 8823\n",
      "Epoch  49 Batch    6/6   train_loss = 6.131   time_elapsed = 145.597   time_remaining = 8768\n",
      "Epoch  50 Batch    6/6   train_loss = 6.127   time_elapsed = 147.724   time_remaining = 8716\n",
      "Epoch  51 Batch    6/6   train_loss = 6.120   time_elapsed = 149.847   time_remaining = 8665\n",
      "Model Trained and Saved\n",
      "Epoch  52 Batch    6/6   train_loss = 6.119   time_elapsed = 152.389   time_remaining = 8639\n",
      "Epoch  53 Batch    6/6   train_loss = 6.120   time_elapsed = 154.513   time_remaining = 8592\n",
      "Epoch  54 Batch    6/6   train_loss = 6.119   time_elapsed = 156.653   time_remaining = 8546\n",
      "Epoch  55 Batch    6/6   train_loss = 6.115   time_elapsed = 158.785   time_remaining = 8502\n",
      "Epoch  56 Batch    6/6   train_loss = 6.116   time_elapsed = 160.928   time_remaining = 8460\n",
      "Epoch  57 Batch    6/6   train_loss = 6.116   time_elapsed = 163.061   time_remaining = 8419\n",
      "Epoch  58 Batch    6/6   train_loss = 6.110   time_elapsed = 165.196   time_remaining = 8379\n",
      "Epoch  59 Batch    6/6   train_loss = 6.109   time_elapsed = 167.335   time_remaining = 8341\n",
      "Epoch  60 Batch    6/6   train_loss = 6.104   time_elapsed = 169.468   time_remaining = 8304\n",
      "Epoch  61 Batch    6/6   train_loss = 6.103   time_elapsed = 171.613   time_remaining = 8268\n",
      "Model Trained and Saved\n",
      "Epoch  62 Batch    6/6   train_loss = 6.107   time_elapsed = 174.165   time_remaining = 8253\n",
      "Epoch  63 Batch    6/6   train_loss = 6.100   time_elapsed = 176.302   time_remaining = 8219\n",
      "Epoch  64 Batch    6/6   train_loss = 6.100   time_elapsed = 178.457   time_remaining = 8187\n",
      "Epoch  65 Batch    6/6   train_loss = 6.097   time_elapsed = 180.606   time_remaining = 8155\n",
      "Epoch  66 Batch    6/6   train_loss = 6.098   time_elapsed = 182.762   time_remaining = 8125\n",
      "Epoch  67 Batch    6/6   train_loss = 6.089   time_elapsed = 184.916   time_remaining = 8095\n",
      "Epoch  68 Batch    6/6   train_loss = 6.089   time_elapsed = 187.069   time_remaining = 8066\n",
      "Epoch  69 Batch    6/6   train_loss = 6.087   time_elapsed = 189.317   time_remaining = 8042\n",
      "Epoch  70 Batch    6/6   train_loss = 6.087   time_elapsed = 191.495   time_remaining = 8015\n",
      "Epoch  71 Batch    6/6   train_loss = 6.087   time_elapsed = 193.668   time_remaining = 7990\n",
      "Model Trained and Saved\n",
      "Epoch  72 Batch    6/6   train_loss = 6.086   time_elapsed = 196.257   time_remaining = 7981\n",
      "Epoch  73 Batch    6/6   train_loss = 6.079   time_elapsed = 198.427   time_remaining = 7956\n",
      "Epoch  74 Batch    6/6   train_loss = 6.078   time_elapsed = 200.614   time_remaining = 7932\n",
      "Epoch  75 Batch    6/6   train_loss = 6.076   time_elapsed = 202.776   time_remaining = 7908\n",
      "Epoch  76 Batch    6/6   train_loss = 6.080   time_elapsed = 204.953   time_remaining = 7885\n",
      "Epoch  77 Batch    6/6   train_loss = 6.071   time_elapsed = 207.127   time_remaining = 7863\n",
      "Epoch  78 Batch    6/6   train_loss = 6.067   time_elapsed = 209.307   time_remaining = 7841\n",
      "Epoch  79 Batch    6/6   train_loss = 6.071   time_elapsed = 211.476   time_remaining = 7819\n",
      "Epoch  80 Batch    6/6   train_loss = 6.062   time_elapsed = 213.647   time_remaining = 7798\n",
      "Epoch  81 Batch    6/6   train_loss = 6.061   time_elapsed = 215.811   time_remaining = 7777\n",
      "Model Trained and Saved\n",
      "Epoch  82 Batch    6/6   train_loss = 6.059   time_elapsed = 218.502   time_remaining = 7775\n",
      "Epoch  83 Batch    6/6   train_loss = 6.059   time_elapsed = 220.675   time_remaining = 7756\n",
      "Epoch  84 Batch    6/6   train_loss = 6.058   time_elapsed = 222.855   time_remaining = 7736\n",
      "Epoch  85 Batch    6/6   train_loss = 6.066   time_elapsed = 225.032   time_remaining = 7717\n",
      "Epoch  86 Batch    6/6   train_loss = 6.070   time_elapsed = 227.207   time_remaining = 7699\n",
      "Epoch  87 Batch    6/6   train_loss = 6.048   time_elapsed = 229.377   time_remaining = 7680\n",
      "Epoch  88 Batch    6/6   train_loss = 6.050   time_elapsed = 231.545   time_remaining = 7662\n",
      "Epoch  89 Batch    6/6   train_loss = 6.049   time_elapsed = 233.729   time_remaining = 7645\n",
      "Epoch  90 Batch    6/6   train_loss = 6.048   time_elapsed = 235.897   time_remaining = 7627\n",
      "Epoch  91 Batch    6/6   train_loss = 6.041   time_elapsed = 238.071   time_remaining = 7610\n",
      "Model Trained and Saved\n",
      "Epoch  92 Batch    6/6   train_loss = 6.042   time_elapsed = 240.677   time_remaining = 7607\n",
      "Epoch  93 Batch    6/6   train_loss = 6.041   time_elapsed = 242.856   time_remaining = 7591\n",
      "Epoch  94 Batch    6/6   train_loss = 6.037   time_elapsed = 245.034   time_remaining = 7575\n",
      "Epoch  95 Batch    6/6   train_loss = 6.038   time_elapsed = 247.214   time_remaining = 7560\n",
      "Epoch  96 Batch    6/6   train_loss = 6.034   time_elapsed = 249.395   time_remaining = 7544\n",
      "Epoch  97 Batch    6/6   train_loss = 6.030   time_elapsed = 251.566   time_remaining = 7529\n",
      "Epoch  98 Batch    6/6   train_loss = 6.030   time_elapsed = 253.733   time_remaining = 7514\n",
      "Epoch  99 Batch    6/6   train_loss = 6.028   time_elapsed = 255.994   time_remaining = 7501\n",
      "Epoch 100 Batch    6/6   train_loss = 6.026   time_elapsed = 258.170   time_remaining = 7487\n",
      "Epoch 101 Batch    6/6   train_loss = 6.030   time_elapsed = 260.343   time_remaining = 7473\n",
      "Model Trained and Saved\n",
      "Epoch 102 Batch    6/6   train_loss = 6.015   time_elapsed = 262.921   time_remaining = 7470\n",
      "Epoch 103 Batch    6/6   train_loss = 6.019   time_elapsed = 265.096   time_remaining = 7456\n",
      "Epoch 104 Batch    6/6   train_loss = 6.023   time_elapsed = 267.271   time_remaining = 7442\n",
      "Epoch 105 Batch    6/6   train_loss = 6.025   time_elapsed = 269.438   time_remaining = 7429\n",
      "Epoch 106 Batch    6/6   train_loss = 6.015   time_elapsed = 271.610   time_remaining = 7415\n",
      "Epoch 107 Batch    6/6   train_loss = 6.006   time_elapsed = 273.790   time_remaining = 7403\n",
      "Epoch 108 Batch    6/6   train_loss = 6.011   time_elapsed = 275.953   time_remaining = 7389\n",
      "Epoch 109 Batch    6/6   train_loss = 6.007   time_elapsed = 278.118   time_remaining = 7377\n",
      "Epoch 110 Batch    6/6   train_loss = 5.998   time_elapsed = 280.297   time_remaining = 7364\n",
      "Epoch 111 Batch    6/6   train_loss = 6.004   time_elapsed = 282.466   time_remaining = 7352\n",
      "Model Trained and Saved\n",
      "Epoch 112 Batch    6/6   train_loss = 6.004   time_elapsed = 285.053   time_remaining = 7350\n",
      "Epoch 113 Batch    6/6   train_loss = 6.007   time_elapsed = 287.217   time_remaining = 7338\n",
      "Epoch 114 Batch    6/6   train_loss = 5.999   time_elapsed = 289.394   time_remaining = 7326\n",
      "Epoch 115 Batch    6/6   train_loss = 5.994   time_elapsed = 291.563   time_remaining = 7314\n",
      "Epoch 116 Batch    6/6   train_loss = 5.996   time_elapsed = 293.725   time_remaining = 7303\n",
      "Epoch 117 Batch    6/6   train_loss = 5.989   time_elapsed = 295.893   time_remaining = 7291\n",
      "Epoch 118 Batch    6/6   train_loss = 5.988   time_elapsed = 298.060   time_remaining = 7280\n",
      "Epoch 119 Batch    6/6   train_loss = 5.986   time_elapsed = 300.228   time_remaining = 7269\n",
      "Epoch 120 Batch    6/6   train_loss = 5.985   time_elapsed = 302.412   time_remaining = 7258\n",
      "Epoch 121 Batch    6/6   train_loss = 5.981   time_elapsed = 304.577   time_remaining = 7247\n",
      "Model Trained and Saved\n",
      "Epoch 122 Batch    6/6   train_loss = 5.980   time_elapsed = 307.269   time_remaining = 7249\n",
      "Epoch 123 Batch    6/6   train_loss = 5.980   time_elapsed = 309.423   time_remaining = 7237\n",
      "Epoch 124 Batch    6/6   train_loss = 5.973   time_elapsed = 311.586   time_remaining = 7227\n",
      "Epoch 125 Batch    6/6   train_loss = 5.972   time_elapsed = 313.749   time_remaining = 7216\n",
      "Epoch 126 Batch    6/6   train_loss = 5.967   time_elapsed = 315.902   time_remaining = 7206\n",
      "Epoch 127 Batch    6/6   train_loss = 5.967   time_elapsed = 318.069   time_remaining = 7195\n",
      "Epoch 128 Batch    6/6   train_loss = 5.964   time_elapsed = 320.244   time_remaining = 7185\n",
      "Epoch 129 Batch    6/6   train_loss = 5.966   time_elapsed = 322.424   time_remaining = 7176\n",
      "Epoch 130 Batch    6/6   train_loss = 5.961   time_elapsed = 324.600   time_remaining = 7166\n",
      "Epoch 131 Batch    6/6   train_loss = 5.957   time_elapsed = 326.765   time_remaining = 7156\n",
      "Model Trained and Saved\n",
      "Epoch 132 Batch    6/6   train_loss = 5.958   time_elapsed = 329.481   time_remaining = 7159\n",
      "Epoch 133 Batch    6/6   train_loss = 5.958   time_elapsed = 331.661   time_remaining = 7149\n",
      "Epoch 134 Batch    6/6   train_loss = 5.953   time_elapsed = 333.832   time_remaining = 7140\n",
      "Epoch 135 Batch    6/6   train_loss = 5.954   time_elapsed = 336.017   time_remaining = 7131\n",
      "Epoch 136 Batch    6/6   train_loss = 5.946   time_elapsed = 338.201   time_remaining = 7122\n",
      "Epoch 137 Batch    6/6   train_loss = 5.952   time_elapsed = 340.375   time_remaining = 7113\n",
      "Epoch 138 Batch    6/6   train_loss = 5.944   time_elapsed = 342.552   time_remaining = 7104\n",
      "Epoch 139 Batch    6/6   train_loss = 5.941   time_elapsed = 344.728   time_remaining = 7095\n",
      "Epoch 140 Batch    6/6   train_loss = 5.943   time_elapsed = 346.902   time_remaining = 7087\n",
      "Epoch 141 Batch    6/6   train_loss = 5.940   time_elapsed = 349.062   time_remaining = 7078\n",
      "Model Trained and Saved\n",
      "Epoch 142 Batch    6/6   train_loss = 5.934   time_elapsed = 351.654   time_remaining = 7078\n",
      "Epoch 143 Batch    6/6   train_loss = 5.937   time_elapsed = 353.825   time_remaining = 7069\n",
      "Epoch 144 Batch    6/6   train_loss = 5.936   time_elapsed = 355.999   time_remaining = 7061\n",
      "Epoch 145 Batch    6/6   train_loss = 5.936   time_elapsed = 358.178   time_remaining = 7052\n",
      "Epoch 146 Batch    6/6   train_loss = 5.931   time_elapsed = 360.348   time_remaining = 7044\n",
      "Epoch 147 Batch    6/6   train_loss = 5.922   time_elapsed = 362.522   time_remaining = 7036\n",
      "Epoch 148 Batch    6/6   train_loss = 5.921   time_elapsed = 364.686   time_remaining = 7028\n",
      "Epoch 149 Batch    6/6   train_loss = 5.922   time_elapsed = 366.855   time_remaining = 7019\n",
      "Epoch 150 Batch    6/6   train_loss = 5.920   time_elapsed = 369.036   time_remaining = 7012\n",
      "Epoch 151 Batch    6/6   train_loss = 5.912   time_elapsed = 371.217   time_remaining = 7004\n",
      "Model Trained and Saved\n",
      "Epoch 152 Batch    6/6   train_loss = 5.914   time_elapsed = 373.817   time_remaining = 7004\n",
      "Epoch 153 Batch    6/6   train_loss = 5.908   time_elapsed = 375.991   time_remaining = 6996\n",
      "Epoch 154 Batch    6/6   train_loss = 5.909   time_elapsed = 378.177   time_remaining = 6989\n",
      "Epoch 155 Batch    6/6   train_loss = 5.909   time_elapsed = 380.338   time_remaining = 6981\n",
      "Epoch 156 Batch    6/6   train_loss = 5.905   time_elapsed = 382.511   time_remaining = 6973\n",
      "Epoch 157 Batch    6/6   train_loss = 5.900   time_elapsed = 384.693   time_remaining = 6966\n",
      "Epoch 158 Batch    6/6   train_loss = 5.876   time_elapsed = 386.869   time_remaining = 6959\n",
      "Epoch 159 Batch    6/6   train_loss = 5.855   time_elapsed = 389.042   time_remaining = 6951\n",
      "Epoch 160 Batch    6/6   train_loss = 5.810   time_elapsed = 391.217   time_remaining = 6944\n",
      "Epoch 161 Batch    6/6   train_loss = 5.790   time_elapsed = 393.409   time_remaining = 6937\n",
      "Model Trained and Saved\n",
      "Epoch 162 Batch    6/6   train_loss = 5.759   time_elapsed = 395.996   time_remaining = 6937\n",
      "Epoch 163 Batch    6/6   train_loss = 5.744   time_elapsed = 398.175   time_remaining = 6930\n",
      "Epoch 164 Batch    6/6   train_loss = 5.712   time_elapsed = 400.343   time_remaining = 6923\n",
      "Epoch 165 Batch    6/6   train_loss = 5.698   time_elapsed = 402.521   time_remaining = 6916\n",
      "Epoch 166 Batch    6/6   train_loss = 5.689   time_elapsed = 404.706   time_remaining = 6909\n",
      "Epoch 167 Batch    6/6   train_loss = 5.677   time_elapsed = 406.896   time_remaining = 6903\n",
      "Epoch 168 Batch    6/6   train_loss = 5.664   time_elapsed = 409.074   time_remaining = 6896\n",
      "Epoch 169 Batch    6/6   train_loss = 5.666   time_elapsed = 411.249   time_remaining = 6889\n",
      "Epoch 170 Batch    6/6   train_loss = 5.636   time_elapsed = 413.422   time_remaining = 6882\n",
      "Epoch 171 Batch    6/6   train_loss = 5.624   time_elapsed = 415.597   time_remaining = 6876\n",
      "Model Trained and Saved\n",
      "Epoch 172 Batch    6/6   train_loss = 5.604   time_elapsed = 418.209   time_remaining = 6876\n",
      "Epoch 173 Batch    6/6   train_loss = 5.589   time_elapsed = 420.385   time_remaining = 6870\n",
      "Epoch 174 Batch    6/6   train_loss = 5.572   time_elapsed = 422.578   time_remaining = 6863\n",
      "Epoch 175 Batch    6/6   train_loss = 5.555   time_elapsed = 424.755   time_remaining = 6857\n",
      "Epoch 176 Batch    6/6   train_loss = 5.579   time_elapsed = 426.924   time_remaining = 6850\n",
      "Epoch 177 Batch    6/6   train_loss = 5.543   time_elapsed = 429.111   time_remaining = 6844\n",
      "Epoch 178 Batch    6/6   train_loss = 5.523   time_elapsed = 431.289   time_remaining = 6838\n",
      "Epoch 179 Batch    6/6   train_loss = 5.504   time_elapsed = 433.459   time_remaining = 6831\n",
      "Epoch 180 Batch    6/6   train_loss = 5.487   time_elapsed = 435.638   time_remaining = 6825\n",
      "Epoch 181 Batch    6/6   train_loss = 5.482   time_elapsed = 437.819   time_remaining = 6819\n",
      "Model Trained and Saved\n",
      "Epoch 182 Batch    6/6   train_loss = 5.469   time_elapsed = 440.574   time_remaining = 6822\n",
      "Epoch 183 Batch    6/6   train_loss = 5.447   time_elapsed = 442.753   time_remaining = 6815\n",
      "Epoch 184 Batch    6/6   train_loss = 5.442   time_elapsed = 444.946   time_remaining = 6810\n",
      "Epoch 185 Batch    6/6   train_loss = 5.437   time_elapsed = 447.121   time_remaining = 6803\n",
      "Epoch 186 Batch    6/6   train_loss = 5.413   time_elapsed = 449.304   time_remaining = 6798\n",
      "Epoch 187 Batch    6/6   train_loss = 5.411   time_elapsed = 451.486   time_remaining = 6792\n",
      "Epoch 188 Batch    6/6   train_loss = 5.391   time_elapsed = 453.663   time_remaining = 6786\n",
      "Epoch 189 Batch    6/6   train_loss = 5.376   time_elapsed = 455.843   time_remaining = 6780\n",
      "Epoch 190 Batch    6/6   train_loss = 5.368   time_elapsed = 458.032   time_remaining = 6774\n",
      "Epoch 191 Batch    6/6   train_loss = 5.354   time_elapsed = 460.215   time_remaining = 6768\n",
      "Model Trained and Saved\n",
      "Epoch 192 Batch    6/6   train_loss = 5.347   time_elapsed = 462.821   time_remaining = 6769\n",
      "Epoch 193 Batch    6/6   train_loss = 5.350   time_elapsed = 465.000   time_remaining = 6763\n",
      "Epoch 194 Batch    6/6   train_loss = 5.320   time_elapsed = 467.184   time_remaining = 6757\n",
      "Epoch 195 Batch    6/6   train_loss = 5.301   time_elapsed = 469.360   time_remaining = 6752\n",
      "Epoch 196 Batch    6/6   train_loss = 5.289   time_elapsed = 471.549   time_remaining = 6746\n",
      "Epoch 197 Batch    6/6   train_loss = 5.291   time_elapsed = 473.727   time_remaining = 6740\n",
      "Epoch 198 Batch    6/6   train_loss = 5.272   time_elapsed = 475.918   time_remaining = 6735\n",
      "Epoch 199 Batch    6/6   train_loss = 5.263   time_elapsed = 478.108   time_remaining = 6730\n",
      "Epoch 200 Batch    6/6   train_loss = 5.242   time_elapsed = 480.285   time_remaining = 6724\n",
      "Epoch 201 Batch    6/6   train_loss = 5.229   time_elapsed = 482.470   time_remaining = 6719\n",
      "Model Trained and Saved\n",
      "Epoch 202 Batch    6/6   train_loss = 5.221   time_elapsed = 485.123   time_remaining = 6720\n",
      "Epoch 203 Batch    6/6   train_loss = 5.227   time_elapsed = 487.306   time_remaining = 6714\n",
      "Epoch 204 Batch    6/6   train_loss = 5.209   time_elapsed = 489.486   time_remaining = 6709\n",
      "Epoch 205 Batch    6/6   train_loss = 5.201   time_elapsed = 491.666   time_remaining = 6703\n",
      "Epoch 206 Batch    6/6   train_loss = 5.170   time_elapsed = 493.854   time_remaining = 6698\n",
      "Epoch 207 Batch    6/6   train_loss = 5.172   time_elapsed = 496.038   time_remaining = 6693\n",
      "Epoch 208 Batch    6/6   train_loss = 5.149   time_elapsed = 498.225   time_remaining = 6688\n",
      "Epoch 209 Batch    6/6   train_loss = 5.132   time_elapsed = 500.413   time_remaining = 6683\n",
      "Epoch 210 Batch    6/6   train_loss = 5.131   time_elapsed = 502.600   time_remaining = 6677\n",
      "Epoch 211 Batch    6/6   train_loss = 5.100   time_elapsed = 504.787   time_remaining = 6672\n",
      "Model Trained and Saved\n",
      "Epoch 212 Batch    6/6   train_loss = 5.094   time_elapsed = 507.428   time_remaining = 6673\n",
      "Epoch 213 Batch    6/6   train_loss = 5.090   time_elapsed = 509.606   time_remaining = 6668\n",
      "Epoch 214 Batch    6/6   train_loss = 5.084   time_elapsed = 511.883   time_remaining = 6664\n",
      "Epoch 215 Batch    6/6   train_loss = 5.095   time_elapsed = 514.069   time_remaining = 6659\n",
      "Epoch 216 Batch    6/6   train_loss = 5.053   time_elapsed = 516.246   time_remaining = 6654\n",
      "Epoch 217 Batch    6/6   train_loss = 5.051   time_elapsed = 518.431   time_remaining = 6649\n",
      "Epoch 218 Batch    6/6   train_loss = 5.055   time_elapsed = 520.621   time_remaining = 6644\n",
      "Epoch 219 Batch    6/6   train_loss = 5.030   time_elapsed = 522.920   time_remaining = 6640\n",
      "Epoch 220 Batch    6/6   train_loss = 4.999   time_elapsed = 525.119   time_remaining = 6636\n",
      "Epoch 221 Batch    6/6   train_loss = 4.996   time_elapsed = 527.311   time_remaining = 6631\n",
      "Model Trained and Saved\n",
      "Epoch 222 Batch    6/6   train_loss = 4.984   time_elapsed = 529.980   time_remaining = 6632\n",
      "Epoch 223 Batch    6/6   train_loss = 4.956   time_elapsed = 532.172   time_remaining = 6627\n",
      "Epoch 224 Batch    6/6   train_loss = 4.959   time_elapsed = 534.358   time_remaining = 6622\n",
      "Epoch 225 Batch    6/6   train_loss = 4.948   time_elapsed = 536.544   time_remaining = 6617\n",
      "Epoch 226 Batch    6/6   train_loss = 4.942   time_elapsed = 538.720   time_remaining = 6612\n",
      "Epoch 227 Batch    6/6   train_loss = 4.909   time_elapsed = 540.905   time_remaining = 6608\n",
      "Epoch 228 Batch    6/6   train_loss = 4.919   time_elapsed = 543.089   time_remaining = 6603\n",
      "Epoch 229 Batch    6/6   train_loss = 4.932   time_elapsed = 545.272   time_remaining = 6598\n",
      "Epoch 230 Batch    6/6   train_loss = 4.905   time_elapsed = 547.451   time_remaining = 6593\n",
      "Epoch 231 Batch    6/6   train_loss = 4.946   time_elapsed = 549.638   time_remaining = 6589\n",
      "Model Trained and Saved\n",
      "Epoch 232 Batch    6/6   train_loss = 4.931   time_elapsed = 552.296   time_remaining = 6589\n",
      "Epoch 233 Batch    6/6   train_loss = 4.945   time_elapsed = 554.578   time_remaining = 6586\n",
      "Epoch 234 Batch    6/6   train_loss = 5.119   time_elapsed = 556.767   time_remaining = 6581\n",
      "Epoch 235 Batch    6/6   train_loss = 4.912   time_elapsed = 558.959   time_remaining = 6577\n",
      "Epoch 236 Batch    6/6   train_loss = 4.875   time_elapsed = 561.150   time_remaining = 6572\n",
      "Epoch 237 Batch    6/6   train_loss = 4.874   time_elapsed = 563.349   time_remaining = 6568\n",
      "Epoch 238 Batch    6/6   train_loss = 4.818   time_elapsed = 565.632   time_remaining = 6564\n",
      "Epoch 239 Batch    6/6   train_loss = 4.801   time_elapsed = 567.820   time_remaining = 6560\n",
      "Epoch 240 Batch    6/6   train_loss = 4.796   time_elapsed = 570.009   time_remaining = 6555\n",
      "Epoch 241 Batch    6/6   train_loss = 4.766   time_elapsed = 572.194   time_remaining = 6551\n",
      "Model Trained and Saved\n",
      "Epoch 242 Batch    6/6   train_loss = 4.758   time_elapsed = 574.934   time_remaining = 6552\n",
      "Epoch 243 Batch    6/6   train_loss = 4.740   time_elapsed = 577.123   time_remaining = 6548\n",
      "Epoch 244 Batch    6/6   train_loss = 4.719   time_elapsed = 579.305   time_remaining = 6543\n",
      "Epoch 245 Batch    6/6   train_loss = 4.713   time_elapsed = 581.479   time_remaining = 6539\n",
      "Epoch 246 Batch    6/6   train_loss = 4.695   time_elapsed = 583.654   time_remaining = 6534\n",
      "Epoch 247 Batch    6/6   train_loss = 4.698   time_elapsed = 585.815   time_remaining = 6529\n",
      "Epoch 248 Batch    6/6   train_loss = 4.681   time_elapsed = 587.979   time_remaining = 6525\n",
      "Epoch 249 Batch    6/6   train_loss = 4.665   time_elapsed = 590.152   time_remaining = 6520\n",
      "Epoch 250 Batch    6/6   train_loss = 4.666   time_elapsed = 592.315   time_remaining = 6515\n",
      "Epoch 251 Batch    6/6   train_loss = 4.657   time_elapsed = 594.476   time_remaining = 6511\n",
      "Model Trained and Saved\n",
      "Epoch 252 Batch    6/6   train_loss = 4.634   time_elapsed = 597.074   time_remaining = 6511\n",
      "Epoch 253 Batch    6/6   train_loss = 4.637   time_elapsed = 599.234   time_remaining = 6506\n",
      "Epoch 254 Batch    6/6   train_loss = 4.614   time_elapsed = 601.392   time_remaining = 6502\n",
      "Epoch 255 Batch    6/6   train_loss = 4.619   time_elapsed = 603.549   time_remaining = 6497\n",
      "Epoch 256 Batch    6/6   train_loss = 4.604   time_elapsed = 605.702   time_remaining = 6492\n",
      "Epoch 257 Batch    6/6   train_loss = 4.629   time_elapsed = 607.868   time_remaining = 6488\n",
      "Epoch 258 Batch    6/6   train_loss = 4.645   time_elapsed = 610.019   time_remaining = 6483\n",
      "Epoch 259 Batch    6/6   train_loss = 4.578   time_elapsed = 612.181   time_remaining = 6479\n",
      "Epoch 260 Batch    6/6   train_loss = 4.615   time_elapsed = 614.332   time_remaining = 6474\n",
      "Epoch 261 Batch    6/6   train_loss = 4.565   time_elapsed = 616.489   time_remaining = 6470\n",
      "Model Trained and Saved\n",
      "Epoch 262 Batch    6/6   train_loss = 4.541   time_elapsed = 619.114   time_remaining = 6470\n",
      "Epoch 263 Batch    6/6   train_loss = 4.519   time_elapsed = 621.270   time_remaining = 6465\n",
      "Epoch 264 Batch    6/6   train_loss = 4.506   time_elapsed = 623.417   time_remaining = 6461\n",
      "Epoch 265 Batch    6/6   train_loss = 4.488   time_elapsed = 625.570   time_remaining = 6456\n",
      "Epoch 266 Batch    6/6   train_loss = 4.484   time_elapsed = 627.721   time_remaining = 6452\n",
      "Epoch 267 Batch    6/6   train_loss = 4.473   time_elapsed = 629.879   time_remaining = 6447\n",
      "Epoch 268 Batch    6/6   train_loss = 4.459   time_elapsed = 632.034   time_remaining = 6443\n",
      "Epoch 269 Batch    6/6   train_loss = 4.448   time_elapsed = 634.184   time_remaining = 6438\n",
      "Epoch 270 Batch    6/6   train_loss = 4.457   time_elapsed = 636.332   time_remaining = 6434\n",
      "Epoch 271 Batch    6/6   train_loss = 4.431   time_elapsed = 638.474   time_remaining = 6430\n",
      "Model Trained and Saved\n",
      "Epoch 272 Batch    6/6   train_loss = 4.411   time_elapsed = 641.095   time_remaining = 6430\n",
      "Epoch 273 Batch    6/6   train_loss = 4.437   time_elapsed = 643.237   time_remaining = 6425\n",
      "Epoch 274 Batch    6/6   train_loss = 4.435   time_elapsed = 645.381   time_remaining = 6421\n",
      "Epoch 275 Batch    6/6   train_loss = 4.415   time_elapsed = 647.529   time_remaining = 6416\n",
      "Epoch 276 Batch    6/6   train_loss = 4.385   time_elapsed = 649.674   time_remaining = 6412\n",
      "Epoch 277 Batch    6/6   train_loss = 4.433   time_elapsed = 651.825   time_remaining = 6408\n",
      "Epoch 278 Batch    6/6   train_loss = 4.379   time_elapsed = 653.975   time_remaining = 6403\n",
      "Epoch 279 Batch    6/6   train_loss = 4.356   time_elapsed = 656.128   time_remaining = 6399\n",
      "Epoch 280 Batch    6/6   train_loss = 4.339   time_elapsed = 658.283   time_remaining = 6395\n",
      "Epoch 281 Batch    6/6   train_loss = 4.330   time_elapsed = 660.430   time_remaining = 6390\n",
      "Model Trained and Saved\n",
      "Epoch 282 Batch    6/6   train_loss = 4.315   time_elapsed = 663.025   time_remaining = 6390\n",
      "Epoch 283 Batch    6/6   train_loss = 4.303   time_elapsed = 665.167   time_remaining = 6386\n",
      "Epoch 284 Batch    6/6   train_loss = 4.288   time_elapsed = 667.306   time_remaining = 6382\n",
      "Epoch 285 Batch    6/6   train_loss = 4.272   time_elapsed = 669.452   time_remaining = 6377\n",
      "Epoch 286 Batch    6/6   train_loss = 4.251   time_elapsed = 671.595   time_remaining = 6373\n",
      "Epoch 287 Batch    6/6   train_loss = 4.250   time_elapsed = 673.728   time_remaining = 6369\n",
      "Epoch 288 Batch    6/6   train_loss = 4.242   time_elapsed = 675.865   time_remaining = 6364\n",
      "Epoch 289 Batch    6/6   train_loss = 4.236   time_elapsed = 678.018   time_remaining = 6360\n",
      "Epoch 290 Batch    6/6   train_loss = 4.236   time_elapsed = 680.154   time_remaining = 6356\n",
      "Epoch 291 Batch    6/6   train_loss = 4.221   time_elapsed = 682.297   time_remaining = 6352\n",
      "Model Trained and Saved\n",
      "Epoch 292 Batch    6/6   train_loss = 4.198   time_elapsed = 684.916   time_remaining = 6352\n",
      "Epoch 293 Batch    6/6   train_loss = 4.206   time_elapsed = 687.064   time_remaining = 6348\n",
      "Epoch 294 Batch    6/6   train_loss = 4.198   time_elapsed = 689.210   time_remaining = 6344\n",
      "Epoch 295 Batch    6/6   train_loss = 4.168   time_elapsed = 691.349   time_remaining = 6339\n",
      "Epoch 296 Batch    6/6   train_loss = 4.166   time_elapsed = 693.494   time_remaining = 6335\n",
      "Epoch 297 Batch    6/6   train_loss = 4.137   time_elapsed = 695.636   time_remaining = 6331\n",
      "Epoch 298 Batch    6/6   train_loss = 4.157   time_elapsed = 697.774   time_remaining = 6327\n",
      "Epoch 299 Batch    6/6   train_loss = 4.139   time_elapsed = 699.908   time_remaining = 6323\n",
      "Epoch 300 Batch    6/6   train_loss = 4.103   time_elapsed = 702.046   time_remaining = 6318\n",
      "Epoch 301 Batch    6/6   train_loss = 4.108   time_elapsed = 704.199   time_remaining = 6314\n",
      "Model Trained and Saved\n",
      "Epoch 302 Batch    6/6   train_loss = 4.111   time_elapsed = 706.944   time_remaining = 6316\n",
      "Epoch 303 Batch    6/6   train_loss = 4.071   time_elapsed = 709.081   time_remaining = 6312\n",
      "Epoch 304 Batch    6/6   train_loss = 4.058   time_elapsed = 711.225   time_remaining = 6307\n",
      "Epoch 305 Batch    6/6   train_loss = 4.047   time_elapsed = 713.355   time_remaining = 6303\n",
      "Epoch 306 Batch    6/6   train_loss = 4.035   time_elapsed = 715.499   time_remaining = 6299\n",
      "Epoch 307 Batch    6/6   train_loss = 4.010   time_elapsed = 717.638   time_remaining = 6295\n",
      "Epoch 308 Batch    6/6   train_loss = 4.007   time_elapsed = 719.771   time_remaining = 6291\n",
      "Epoch 309 Batch    6/6   train_loss = 4.010   time_elapsed = 721.914   time_remaining = 6287\n",
      "Epoch 310 Batch    6/6   train_loss = 3.989   time_elapsed = 724.060   time_remaining = 6283\n",
      "Epoch 311 Batch    6/6   train_loss = 3.964   time_elapsed = 726.194   time_remaining = 6279\n",
      "Model Trained and Saved\n",
      "Epoch 312 Batch    6/6   train_loss = 4.004   time_elapsed = 728.791   time_remaining = 6279\n",
      "Epoch 313 Batch    6/6   train_loss = 3.974   time_elapsed = 730.925   time_remaining = 6275\n",
      "Epoch 314 Batch    6/6   train_loss = 3.947   time_elapsed = 733.064   time_remaining = 6271\n",
      "Epoch 315 Batch    6/6   train_loss = 3.958   time_elapsed = 735.203   time_remaining = 6267\n",
      "Epoch 316 Batch    6/6   train_loss = 3.925   time_elapsed = 737.350   time_remaining = 6263\n",
      "Epoch 317 Batch    6/6   train_loss = 3.912   time_elapsed = 739.504   time_remaining = 6259\n",
      "Epoch 318 Batch    6/6   train_loss = 3.893   time_elapsed = 741.647   time_remaining = 6255\n",
      "Epoch 319 Batch    6/6   train_loss = 3.870   time_elapsed = 743.782   time_remaining = 6251\n",
      "Epoch 320 Batch    6/6   train_loss = 3.867   time_elapsed = 745.924   time_remaining = 6247\n",
      "Epoch 321 Batch    6/6   train_loss = 3.845   time_elapsed = 748.063   time_remaining = 6243\n",
      "Model Trained and Saved\n",
      "Epoch 322 Batch    6/6   train_loss = 3.833   time_elapsed = 750.656   time_remaining = 6243\n",
      "Epoch 323 Batch    6/6   train_loss = 3.825   time_elapsed = 752.796   time_remaining = 6239\n",
      "Epoch 324 Batch    6/6   train_loss = 3.821   time_elapsed = 754.934   time_remaining = 6235\n",
      "Epoch 325 Batch    6/6   train_loss = 3.824   time_elapsed = 757.075   time_remaining = 6231\n",
      "Epoch 326 Batch    6/6   train_loss = 3.788   time_elapsed = 759.211   time_remaining = 6227\n",
      "Epoch 327 Batch    6/6   train_loss = 3.806   time_elapsed = 761.343   time_remaining = 6223\n",
      "Epoch 328 Batch    6/6   train_loss = 3.796   time_elapsed = 763.482   time_remaining = 6220\n",
      "Epoch 329 Batch    6/6   train_loss = 3.763   time_elapsed = 765.620   time_remaining = 6216\n",
      "Epoch 330 Batch    6/6   train_loss = 3.764   time_elapsed = 767.766   time_remaining = 6212\n",
      "Epoch 331 Batch    6/6   train_loss = 3.747   time_elapsed = 769.909   time_remaining = 6208\n",
      "Model Trained and Saved\n",
      "Epoch 332 Batch    6/6   train_loss = 3.716   time_elapsed = 772.503   time_remaining = 6208\n",
      "Epoch 333 Batch    6/6   train_loss = 3.723   time_elapsed = 774.652   time_remaining = 6204\n",
      "Epoch 334 Batch    6/6   train_loss = 3.709   time_elapsed = 776.797   time_remaining = 6200\n",
      "Epoch 335 Batch    6/6   train_loss = 3.701   time_elapsed = 778.949   time_remaining = 6197\n",
      "Epoch 336 Batch    6/6   train_loss = 3.674   time_elapsed = 781.092   time_remaining = 6193\n",
      "Epoch 337 Batch    6/6   train_loss = 3.665   time_elapsed = 783.241   time_remaining = 6189\n",
      "Epoch 338 Batch    6/6   train_loss = 3.648   time_elapsed = 785.389   time_remaining = 6186\n",
      "Epoch 339 Batch    6/6   train_loss = 3.642   time_elapsed = 787.532   time_remaining = 6182\n",
      "Epoch 340 Batch    6/6   train_loss = 3.626   time_elapsed = 789.680   time_remaining = 6178\n",
      "Epoch 341 Batch    6/6   train_loss = 3.594   time_elapsed = 791.828   time_remaining = 6174\n",
      "Model Trained and Saved\n",
      "Epoch 342 Batch    6/6   train_loss = 3.596   time_elapsed = 794.434   time_remaining = 6174\n",
      "Epoch 343 Batch    6/6   train_loss = 3.581   time_elapsed = 796.583   time_remaining = 6171\n",
      "Epoch 344 Batch    6/6   train_loss = 3.573   time_elapsed = 798.719   time_remaining = 6167\n",
      "Epoch 345 Batch    6/6   train_loss = 3.577   time_elapsed = 800.864   time_remaining = 6163\n",
      "Epoch 346 Batch    6/6   train_loss = 3.544   time_elapsed = 803.013   time_remaining = 6160\n",
      "Epoch 347 Batch    6/6   train_loss = 3.531   time_elapsed = 805.145   time_remaining = 6156\n",
      "Epoch 348 Batch    6/6   train_loss = 3.547   time_elapsed = 807.296   time_remaining = 6152\n",
      "Epoch 349 Batch    6/6   train_loss = 3.518   time_elapsed = 809.433   time_remaining = 6148\n",
      "Epoch 350 Batch    6/6   train_loss = 3.514   time_elapsed = 811.570   time_remaining = 6145\n",
      "Epoch 351 Batch    6/6   train_loss = 3.496   time_elapsed = 813.713   time_remaining = 6141\n",
      "Model Trained and Saved\n",
      "Epoch 352 Batch    6/6   train_loss = 3.503   time_elapsed = 816.316   time_remaining = 6141\n",
      "Epoch 353 Batch    6/6   train_loss = 3.491   time_elapsed = 818.452   time_remaining = 6137\n",
      "Epoch 354 Batch    6/6   train_loss = 3.467   time_elapsed = 820.594   time_remaining = 6134\n",
      "Epoch 355 Batch    6/6   train_loss = 3.490   time_elapsed = 822.736   time_remaining = 6130\n",
      "Epoch 356 Batch    6/6   train_loss = 3.422   time_elapsed = 824.881   time_remaining = 6126\n",
      "Epoch 357 Batch    6/6   train_loss = 3.428   time_elapsed = 827.019   time_remaining = 6123\n",
      "Epoch 358 Batch    6/6   train_loss = 3.449   time_elapsed = 829.164   time_remaining = 6119\n",
      "Epoch 359 Batch    6/6   train_loss = 3.404   time_elapsed = 831.318   time_remaining = 6116\n",
      "Epoch 360 Batch    6/6   train_loss = 3.401   time_elapsed = 833.460   time_remaining = 6112\n",
      "Epoch 361 Batch    6/6   train_loss = 3.387   time_elapsed = 835.613   time_remaining = 6109\n",
      "Model Trained and Saved\n",
      "Epoch 362 Batch    6/6   train_loss = 3.366   time_elapsed = 838.224   time_remaining = 6108\n",
      "Epoch 363 Batch    6/6   train_loss = 3.353   time_elapsed = 840.361   time_remaining = 6105\n",
      "Epoch 364 Batch    6/6   train_loss = 3.355   time_elapsed = 842.507   time_remaining = 6101\n",
      "Epoch 365 Batch    6/6   train_loss = 3.333   time_elapsed = 844.652   time_remaining = 6098\n",
      "Epoch 366 Batch    6/6   train_loss = 3.323   time_elapsed = 846.800   time_remaining = 6094\n",
      "Epoch 367 Batch    6/6   train_loss = 3.349   time_elapsed = 848.948   time_remaining = 6091\n",
      "Epoch 368 Batch    6/6   train_loss = 3.301   time_elapsed = 851.094   time_remaining = 6087\n",
      "Epoch 369 Batch    6/6   train_loss = 3.274   time_elapsed = 853.241   time_remaining = 6084\n",
      "Epoch 370 Batch    6/6   train_loss = 3.301   time_elapsed = 855.389   time_remaining = 6080\n",
      "Epoch 371 Batch    6/6   train_loss = 3.284   time_elapsed = 857.538   time_remaining = 6077\n",
      "Model Trained and Saved\n",
      "Epoch 372 Batch    6/6   train_loss = 3.255   time_elapsed = 860.158   time_remaining = 6077\n",
      "Epoch 373 Batch    6/6   train_loss = 3.254   time_elapsed = 862.295   time_remaining = 6073\n",
      "Epoch 374 Batch    6/6   train_loss = 3.264   time_elapsed = 864.447   time_remaining = 6070\n",
      "Epoch 375 Batch    6/6   train_loss = 3.222   time_elapsed = 866.591   time_remaining = 6066\n",
      "Epoch 376 Batch    6/6   train_loss = 3.217   time_elapsed = 868.728   time_remaining = 6063\n",
      "Epoch 377 Batch    6/6   train_loss = 3.231   time_elapsed = 870.872   time_remaining = 6059\n",
      "Epoch 378 Batch    6/6   train_loss = 3.193   time_elapsed = 873.016   time_remaining = 6056\n",
      "Epoch 379 Batch    6/6   train_loss = 3.183   time_elapsed = 875.164   time_remaining = 6052\n",
      "Epoch 380 Batch    6/6   train_loss = 3.176   time_elapsed = 877.314   time_remaining = 6049\n",
      "Epoch 381 Batch    6/6   train_loss = 3.154   time_elapsed = 879.460   time_remaining = 6045\n",
      "Model Trained and Saved\n",
      "Epoch 382 Batch    6/6   train_loss = 3.155   time_elapsed = 882.080   time_remaining = 6045\n",
      "Epoch 383 Batch    6/6   train_loss = 3.127   time_elapsed = 884.225   time_remaining = 6042\n",
      "Epoch 384 Batch    6/6   train_loss = 3.137   time_elapsed = 886.375   time_remaining = 6038\n",
      "Epoch 385 Batch    6/6   train_loss = 3.099   time_elapsed = 888.524   time_remaining = 6035\n",
      "Epoch 386 Batch    6/6   train_loss = 3.099   time_elapsed = 890.669   time_remaining = 6032\n",
      "Epoch 387 Batch    6/6   train_loss = 3.077   time_elapsed = 892.802   time_remaining = 6028\n",
      "Epoch 388 Batch    6/6   train_loss = 3.059   time_elapsed = 894.949   time_remaining = 6025\n",
      "Epoch 389 Batch    6/6   train_loss = 3.059   time_elapsed = 897.085   time_remaining = 6021\n",
      "Epoch 390 Batch    6/6   train_loss = 3.063   time_elapsed = 899.228   time_remaining = 6018\n",
      "Epoch 391 Batch    6/6   train_loss = 3.029   time_elapsed = 901.361   time_remaining = 6014\n",
      "Model Trained and Saved\n",
      "Epoch 392 Batch    6/6   train_loss = 3.024   time_elapsed = 903.972   time_remaining = 6014\n",
      "Epoch 393 Batch    6/6   train_loss = 3.066   time_elapsed = 906.123   time_remaining = 6011\n",
      "Epoch 394 Batch    6/6   train_loss = 3.029   time_elapsed = 908.267   time_remaining = 6007\n",
      "Epoch 395 Batch    6/6   train_loss = 3.021   time_elapsed = 910.404   time_remaining = 6004\n",
      "Epoch 396 Batch    6/6   train_loss = 3.027   time_elapsed = 912.545   time_remaining = 6001\n",
      "Epoch 397 Batch    6/6   train_loss = 2.996   time_elapsed = 914.686   time_remaining = 5997\n",
      "Epoch 398 Batch    6/6   train_loss = 2.971   time_elapsed = 916.827   time_remaining = 5994\n",
      "Epoch 399 Batch    6/6   train_loss = 2.959   time_elapsed = 918.974   time_remaining = 5991\n",
      "Epoch 400 Batch    6/6   train_loss = 2.953   time_elapsed = 921.124   time_remaining = 5987\n",
      "Epoch 401 Batch    6/6   train_loss = 2.931   time_elapsed = 923.270   time_remaining = 5984\n",
      "Model Trained and Saved\n",
      "Epoch 402 Batch    6/6   train_loss = 2.926   time_elapsed = 925.896   time_remaining = 5984\n",
      "Epoch 403 Batch    6/6   train_loss = 2.917   time_elapsed = 928.036   time_remaining = 5980\n",
      "Epoch 404 Batch    6/6   train_loss = 2.918   time_elapsed = 930.169   time_remaining = 5977\n",
      "Epoch 405 Batch    6/6   train_loss = 2.896   time_elapsed = 932.310   time_remaining = 5974\n",
      "Epoch 406 Batch    6/6   train_loss = 2.900   time_elapsed = 934.452   time_remaining = 5970\n",
      "Epoch 407 Batch    6/6   train_loss = 2.896   time_elapsed = 936.598   time_remaining = 5967\n",
      "Epoch 408 Batch    6/6   train_loss = 2.870   time_elapsed = 938.747   time_remaining = 5964\n",
      "Epoch 409 Batch    6/6   train_loss = 2.877   time_elapsed = 940.893   time_remaining = 5961\n",
      "Epoch 410 Batch    6/6   train_loss = 2.861   time_elapsed = 943.029   time_remaining = 5957\n",
      "Epoch 411 Batch    6/6   train_loss = 2.843   time_elapsed = 945.175   time_remaining = 5954\n",
      "Model Trained and Saved\n",
      "Epoch 412 Batch    6/6   train_loss = 2.827   time_elapsed = 947.794   time_remaining = 5954\n",
      "Epoch 413 Batch    6/6   train_loss = 2.835   time_elapsed = 949.936   time_remaining = 5950\n",
      "Epoch 414 Batch    6/6   train_loss = 2.800   time_elapsed = 952.069   time_remaining = 5947\n",
      "Epoch 415 Batch    6/6   train_loss = 2.792   time_elapsed = 954.215   time_remaining = 5944\n",
      "Epoch 416 Batch    6/6   train_loss = 2.810   time_elapsed = 956.352   time_remaining = 5940\n",
      "Epoch 417 Batch    6/6   train_loss = 2.792   time_elapsed = 958.494   time_remaining = 5937\n",
      "Epoch 418 Batch    6/6   train_loss = 2.775   time_elapsed = 960.639   time_remaining = 5934\n",
      "Epoch 419 Batch    6/6   train_loss = 2.786   time_elapsed = 962.772   time_remaining = 5931\n",
      "Epoch 420 Batch    6/6   train_loss = 2.785   time_elapsed = 964.916   time_remaining = 5927\n",
      "Epoch 421 Batch    6/6   train_loss = 2.779   time_elapsed = 967.057   time_remaining = 5924\n",
      "Model Trained and Saved\n",
      "Epoch 422 Batch    6/6   train_loss = 2.802   time_elapsed = 969.675   time_remaining = 5924\n",
      "Epoch 423 Batch    6/6   train_loss = 2.734   time_elapsed = 971.810   time_remaining = 5920\n",
      "Epoch 424 Batch    6/6   train_loss = 2.742   time_elapsed = 973.952   time_remaining = 5917\n",
      "Epoch 425 Batch    6/6   train_loss = 2.763   time_elapsed = 976.098   time_remaining = 5914\n",
      "Epoch 426 Batch    6/6   train_loss = 2.715   time_elapsed = 978.245   time_remaining = 5911\n",
      "Epoch 427 Batch    6/6   train_loss = 2.724   time_elapsed = 980.386   time_remaining = 5908\n",
      "Epoch 428 Batch    6/6   train_loss = 2.747   time_elapsed = 982.532   time_remaining = 5904\n",
      "Epoch 429 Batch    6/6   train_loss = 2.724   time_elapsed = 984.676   time_remaining = 5901\n",
      "Epoch 430 Batch    6/6   train_loss = 2.686   time_elapsed = 986.808   time_remaining = 5898\n",
      "Epoch 431 Batch    6/6   train_loss = 2.684   time_elapsed = 988.959   time_remaining = 5895\n",
      "Model Trained and Saved\n",
      "Epoch 432 Batch    6/6   train_loss = 2.672   time_elapsed = 991.632   time_remaining = 5895\n",
      "Epoch 433 Batch    6/6   train_loss = 2.626   time_elapsed = 993.768   time_remaining = 5891\n",
      "Epoch 434 Batch    6/6   train_loss = 2.634   time_elapsed = 995.905   time_remaining = 5888\n",
      "Epoch 435 Batch    6/6   train_loss = 2.602   time_elapsed = 998.042   time_remaining = 5885\n",
      "Epoch 436 Batch    6/6   train_loss = 2.594   time_elapsed = 1000.377   time_remaining = 5883\n",
      "Epoch 437 Batch    6/6   train_loss = 2.587   time_elapsed = 1002.541   time_remaining = 5880\n",
      "Epoch 438 Batch    6/6   train_loss = 2.567   time_elapsed = 1004.695   time_remaining = 5877\n",
      "Epoch 439 Batch    6/6   train_loss = 2.560   time_elapsed = 1006.848   time_remaining = 5874\n",
      "Epoch 440 Batch    6/6   train_loss = 2.554   time_elapsed = 1009.000   time_remaining = 5871\n",
      "Epoch 441 Batch    6/6   train_loss = 2.557   time_elapsed = 1011.166   time_remaining = 5868\n",
      "Model Trained and Saved\n",
      "Epoch 442 Batch    6/6   train_loss = 2.522   time_elapsed = 1013.828   time_remaining = 5867\n",
      "Epoch 443 Batch    6/6   train_loss = 2.539   time_elapsed = 1015.988   time_remaining = 5864\n",
      "Epoch 444 Batch    6/6   train_loss = 2.529   time_elapsed = 1018.147   time_remaining = 5861\n",
      "Epoch 445 Batch    6/6   train_loss = 2.516   time_elapsed = 1020.306   time_remaining = 5858\n",
      "Epoch 446 Batch    6/6   train_loss = 2.507   time_elapsed = 1022.463   time_remaining = 5855\n",
      "Epoch 447 Batch    6/6   train_loss = 2.505   time_elapsed = 1024.632   time_remaining = 5852\n",
      "Epoch 448 Batch    6/6   train_loss = 2.493   time_elapsed = 1026.785   time_remaining = 5849\n",
      "Epoch 449 Batch    6/6   train_loss = 2.501   time_elapsed = 1028.958   time_remaining = 5846\n",
      "Epoch 450 Batch    6/6   train_loss = 2.481   time_elapsed = 1031.124   time_remaining = 5843\n",
      "Epoch 451 Batch    6/6   train_loss = 2.460   time_elapsed = 1033.288   time_remaining = 5840\n",
      "Model Trained and Saved\n",
      "Epoch 452 Batch    6/6   train_loss = 2.497   time_elapsed = 1035.940   time_remaining = 5840\n",
      "Epoch 453 Batch    6/6   train_loss = 2.459   time_elapsed = 1038.115   time_remaining = 5837\n",
      "Epoch 454 Batch    6/6   train_loss = 2.466   time_elapsed = 1040.282   time_remaining = 5834\n",
      "Epoch 455 Batch    6/6   train_loss = 2.441   time_elapsed = 1042.456   time_remaining = 5831\n",
      "Epoch 456 Batch    6/6   train_loss = 2.419   time_elapsed = 1044.633   time_remaining = 5828\n",
      "Epoch 457 Batch    6/6   train_loss = 2.410   time_elapsed = 1046.806   time_remaining = 5825\n",
      "Epoch 458 Batch    6/6   train_loss = 2.407   time_elapsed = 1048.978   time_remaining = 5822\n",
      "Epoch 459 Batch    6/6   train_loss = 2.402   time_elapsed = 1051.155   time_remaining = 5819\n",
      "Epoch 460 Batch    6/6   train_loss = 2.412   time_elapsed = 1053.331   time_remaining = 5816\n",
      "Epoch 461 Batch    6/6   train_loss = 2.390   time_elapsed = 1055.507   time_remaining = 5813\n",
      "Model Trained and Saved\n",
      "Epoch 462 Batch    6/6   train_loss = 2.382   time_elapsed = 1058.186   time_remaining = 5813\n",
      "Epoch 463 Batch    6/6   train_loss = 2.411   time_elapsed = 1060.361   time_remaining = 5810\n",
      "Epoch 464 Batch    6/6   train_loss = 2.436   time_elapsed = 1062.537   time_remaining = 5807\n",
      "Epoch 465 Batch    6/6   train_loss = 2.371   time_elapsed = 1064.718   time_remaining = 5804\n",
      "Epoch 466 Batch    6/6   train_loss = 2.427   time_elapsed = 1066.897   time_remaining = 5802\n",
      "Epoch 467 Batch    6/6   train_loss = 2.339   time_elapsed = 1069.082   time_remaining = 5799\n",
      "Epoch 468 Batch    6/6   train_loss = 2.372   time_elapsed = 1071.271   time_remaining = 5796\n",
      "Epoch 469 Batch    6/6   train_loss = 2.360   time_elapsed = 1073.444   time_remaining = 5793\n",
      "Epoch 470 Batch    6/6   train_loss = 2.320   time_elapsed = 1075.632   time_remaining = 5790\n",
      "Epoch 471 Batch    6/6   train_loss = 2.348   time_elapsed = 1077.822   time_remaining = 5787\n",
      "Model Trained and Saved\n",
      "Epoch 472 Batch    6/6   train_loss = 2.283   time_elapsed = 1080.500   time_remaining = 5787\n",
      "Epoch 473 Batch    6/6   train_loss = 2.302   time_elapsed = 1082.685   time_remaining = 5784\n",
      "Epoch 474 Batch    6/6   train_loss = 2.299   time_elapsed = 1084.886   time_remaining = 5781\n",
      "Epoch 475 Batch    6/6   train_loss = 2.277   time_elapsed = 1087.073   time_remaining = 5779\n",
      "Epoch 476 Batch    6/6   train_loss = 2.258   time_elapsed = 1089.250   time_remaining = 5776\n",
      "Epoch 477 Batch    6/6   train_loss = 2.254   time_elapsed = 1091.441   time_remaining = 5773\n",
      "Epoch 478 Batch    6/6   train_loss = 2.242   time_elapsed = 1093.624   time_remaining = 5770\n",
      "Epoch 479 Batch    6/6   train_loss = 2.246   time_elapsed = 1095.820   time_remaining = 5767\n",
      "Epoch 480 Batch    6/6   train_loss = 2.222   time_elapsed = 1098.012   time_remaining = 5765\n",
      "Epoch 481 Batch    6/6   train_loss = 2.256   time_elapsed = 1100.208   time_remaining = 5762\n",
      "Model Trained and Saved\n",
      "Epoch 482 Batch    6/6   train_loss = 2.200   time_elapsed = 1102.895   time_remaining = 5762\n",
      "Epoch 483 Batch    6/6   train_loss = 2.218   time_elapsed = 1105.090   time_remaining = 5759\n",
      "Epoch 484 Batch    6/6   train_loss = 2.209   time_elapsed = 1107.279   time_remaining = 5756\n",
      "Epoch 485 Batch    6/6   train_loss = 2.190   time_elapsed = 1109.473   time_remaining = 5753\n",
      "Epoch 486 Batch    6/6   train_loss = 2.190   time_elapsed = 1111.659   time_remaining = 5750\n",
      "Epoch 487 Batch    6/6   train_loss = 2.196   time_elapsed = 1113.857   time_remaining = 5748\n",
      "Epoch 488 Batch    6/6   train_loss = 2.191   time_elapsed = 1116.056   time_remaining = 5745\n",
      "Epoch 489 Batch    6/6   train_loss = 2.157   time_elapsed = 1118.252   time_remaining = 5742\n",
      "Epoch 490 Batch    6/6   train_loss = 2.191   time_elapsed = 1120.443   time_remaining = 5739\n",
      "Epoch 491 Batch    6/6   train_loss = 2.183   time_elapsed = 1122.626   time_remaining = 5737\n",
      "Model Trained and Saved\n",
      "Epoch 492 Batch    6/6   train_loss = 2.142   time_elapsed = 1125.446   time_remaining = 5737\n",
      "Epoch 493 Batch    6/6   train_loss = 2.179   time_elapsed = 1127.630   time_remaining = 5734\n",
      "Epoch 494 Batch    6/6   train_loss = 2.145   time_elapsed = 1129.814   time_remaining = 5731\n",
      "Epoch 495 Batch    6/6   train_loss = 2.131   time_elapsed = 1132.012   time_remaining = 5729\n",
      "Epoch 496 Batch    6/6   train_loss = 2.133   time_elapsed = 1134.195   time_remaining = 5726\n",
      "Epoch 497 Batch    6/6   train_loss = 2.110   time_elapsed = 1136.389   time_remaining = 5723\n",
      "Epoch 498 Batch    6/6   train_loss = 2.100   time_elapsed = 1138.584   time_remaining = 5720\n",
      "Epoch 499 Batch    6/6   train_loss = 2.086   time_elapsed = 1140.772   time_remaining = 5718\n",
      "Epoch 500 Batch    6/6   train_loss = 2.081   time_elapsed = 1142.959   time_remaining = 5715\n",
      "Epoch 501 Batch    6/6   train_loss = 2.087   time_elapsed = 1145.150   time_remaining = 5712\n",
      "Model Trained and Saved\n",
      "Epoch 502 Batch    6/6   train_loss = 2.061   time_elapsed = 1147.833   time_remaining = 5712\n",
      "Epoch 503 Batch    6/6   train_loss = 2.076   time_elapsed = 1150.014   time_remaining = 5709\n",
      "Epoch 504 Batch    6/6   train_loss = 2.069   time_elapsed = 1152.195   time_remaining = 5706\n",
      "Epoch 505 Batch    6/6   train_loss = 2.064   time_elapsed = 1154.385   time_remaining = 5703\n",
      "Epoch 506 Batch    6/6   train_loss = 2.060   time_elapsed = 1156.578   time_remaining = 5701\n",
      "Epoch 507 Batch    6/6   train_loss = 2.064   time_elapsed = 1158.761   time_remaining = 5698\n",
      "Epoch 508 Batch    6/6   train_loss = 2.050   time_elapsed = 1160.956   time_remaining = 5695\n",
      "Epoch 509 Batch    6/6   train_loss = 2.034   time_elapsed = 1163.140   time_remaining = 5692\n",
      "Epoch 510 Batch    6/6   train_loss = 2.022   time_elapsed = 1165.331   time_remaining = 5690\n",
      "Epoch 511 Batch    6/6   train_loss = 1.990   time_elapsed = 1167.519   time_remaining = 5687\n",
      "Model Trained and Saved\n",
      "Epoch 512 Batch    6/6   train_loss = 2.022   time_elapsed = 1170.227   time_remaining = 5687\n",
      "Epoch 513 Batch    6/6   train_loss = 1.972   time_elapsed = 1172.406   time_remaining = 5684\n",
      "Epoch 514 Batch    6/6   train_loss = 1.987   time_elapsed = 1174.604   time_remaining = 5681\n",
      "Epoch 515 Batch    6/6   train_loss = 1.988   time_elapsed = 1176.790   time_remaining = 5678\n",
      "Epoch 516 Batch    6/6   train_loss = 1.955   time_elapsed = 1178.992   time_remaining = 5676\n",
      "Epoch 517 Batch    6/6   train_loss = 1.973   time_elapsed = 1181.182   time_remaining = 5673\n",
      "Epoch 518 Batch    6/6   train_loss = 1.943   time_elapsed = 1183.370   time_remaining = 5670\n",
      "Epoch 519 Batch    6/6   train_loss = 1.960   time_elapsed = 1185.570   time_remaining = 5667\n",
      "Epoch 520 Batch    6/6   train_loss = 1.925   time_elapsed = 1187.756   time_remaining = 5665\n",
      "Epoch 521 Batch    6/6   train_loss = 1.932   time_elapsed = 1189.944   time_remaining = 5662\n",
      "Model Trained and Saved\n",
      "Epoch 522 Batch    6/6   train_loss = 1.923   time_elapsed = 1192.635   time_remaining = 5662\n",
      "Epoch 523 Batch    6/6   train_loss = 1.895   time_elapsed = 1194.826   time_remaining = 5659\n",
      "Epoch 524 Batch    6/6   train_loss = 1.919   time_elapsed = 1197.019   time_remaining = 5656\n",
      "Epoch 525 Batch    6/6   train_loss = 1.890   time_elapsed = 1199.210   time_remaining = 5653\n",
      "Epoch 526 Batch    6/6   train_loss = 1.893   time_elapsed = 1201.402   time_remaining = 5651\n",
      "Epoch 527 Batch    6/6   train_loss = 1.874   time_elapsed = 1203.595   time_remaining = 5648\n",
      "Epoch 528 Batch    6/6   train_loss = 1.886   time_elapsed = 1205.788   time_remaining = 5645\n",
      "Epoch 529 Batch    6/6   train_loss = 1.872   time_elapsed = 1207.977   time_remaining = 5643\n",
      "Epoch 530 Batch    6/6   train_loss = 1.882   time_elapsed = 1210.177   time_remaining = 5640\n",
      "Epoch 531 Batch    6/6   train_loss = 1.879   time_elapsed = 1212.367   time_remaining = 5637\n",
      "Model Trained and Saved\n",
      "Epoch 532 Batch    6/6   train_loss = 1.860   time_elapsed = 1215.097   time_remaining = 5637\n",
      "Epoch 533 Batch    6/6   train_loss = 1.846   time_elapsed = 1217.294   time_remaining = 5634\n",
      "Epoch 534 Batch    6/6   train_loss = 1.865   time_elapsed = 1219.481   time_remaining = 5632\n",
      "Epoch 535 Batch    6/6   train_loss = 1.828   time_elapsed = 1221.683   time_remaining = 5629\n",
      "Epoch 536 Batch    6/6   train_loss = 1.858   time_elapsed = 1223.877   time_remaining = 5626\n",
      "Epoch 537 Batch    6/6   train_loss = 1.822   time_elapsed = 1226.072   time_remaining = 5623\n",
      "Epoch 538 Batch    6/6   train_loss = 1.811   time_elapsed = 1228.253   time_remaining = 5621\n",
      "Epoch 539 Batch    6/6   train_loss = 1.808   time_elapsed = 1230.445   time_remaining = 5618\n",
      "Epoch 540 Batch    6/6   train_loss = 1.814   time_elapsed = 1232.634   time_remaining = 5615\n",
      "Epoch 541 Batch    6/6   train_loss = 1.768   time_elapsed = 1234.823   time_remaining = 5613\n",
      "Model Trained and Saved\n",
      "Epoch 542 Batch    6/6   train_loss = 1.791   time_elapsed = 1237.545   time_remaining = 5612\n",
      "Epoch 543 Batch    6/6   train_loss = 1.796   time_elapsed = 1239.735   time_remaining = 5610\n",
      "Epoch 544 Batch    6/6   train_loss = 1.782   time_elapsed = 1241.921   time_remaining = 5607\n",
      "Epoch 545 Batch    6/6   train_loss = 1.761   time_elapsed = 1244.113   time_remaining = 5604\n",
      "Epoch 546 Batch    6/6   train_loss = 1.786   time_elapsed = 1246.309   time_remaining = 5602\n",
      "Epoch 547 Batch    6/6   train_loss = 1.737   time_elapsed = 1248.513   time_remaining = 5599\n",
      "Epoch 548 Batch    6/6   train_loss = 1.742   time_elapsed = 1250.693   time_remaining = 5596\n",
      "Epoch 549 Batch    6/6   train_loss = 1.778   time_elapsed = 1252.863   time_remaining = 5593\n",
      "Epoch 550 Batch    6/6   train_loss = 1.746   time_elapsed = 1255.041   time_remaining = 5591\n",
      "Epoch 551 Batch    6/6   train_loss = 1.762   time_elapsed = 1257.213   time_remaining = 5588\n",
      "Model Trained and Saved\n",
      "Epoch 552 Batch    6/6   train_loss = 1.737   time_elapsed = 1259.908   time_remaining = 5587\n",
      "Epoch 553 Batch    6/6   train_loss = 1.713   time_elapsed = 1262.273   time_remaining = 5586\n",
      "Epoch 554 Batch    6/6   train_loss = 1.705   time_elapsed = 1264.469   time_remaining = 5583\n",
      "Epoch 555 Batch    6/6   train_loss = 1.738   time_elapsed = 1266.661   time_remaining = 5580\n",
      "Epoch 556 Batch    6/6   train_loss = 1.713   time_elapsed = 1268.850   time_remaining = 5577\n",
      "Epoch 557 Batch    6/6   train_loss = 1.715   time_elapsed = 1271.041   time_remaining = 5575\n",
      "Epoch 558 Batch    6/6   train_loss = 1.695   time_elapsed = 1273.234   time_remaining = 5572\n",
      "Epoch 559 Batch    6/6   train_loss = 1.735   time_elapsed = 1275.432   time_remaining = 5569\n",
      "Epoch 560 Batch    6/6   train_loss = 1.750   time_elapsed = 1277.624   time_remaining = 5567\n",
      "Epoch 561 Batch    6/6   train_loss = 1.685   time_elapsed = 1279.810   time_remaining = 5564\n",
      "Model Trained and Saved\n",
      "Epoch 562 Batch    6/6   train_loss = 1.714   time_elapsed = 1282.539   time_remaining = 5564\n",
      "Epoch 563 Batch    6/6   train_loss = 1.677   time_elapsed = 1284.722   time_remaining = 5561\n",
      "Epoch 564 Batch    6/6   train_loss = 1.662   time_elapsed = 1286.919   time_remaining = 5558\n",
      "Epoch 565 Batch    6/6   train_loss = 1.659   time_elapsed = 1289.106   time_remaining = 5556\n",
      "Epoch 566 Batch    6/6   train_loss = 1.654   time_elapsed = 1291.294   time_remaining = 5553\n",
      "Epoch 567 Batch    6/6   train_loss = 1.670   time_elapsed = 1293.489   time_remaining = 5550\n",
      "Epoch 568 Batch    6/6   train_loss = 1.649   time_elapsed = 1295.684   time_remaining = 5548\n",
      "Epoch 569 Batch    6/6   train_loss = 1.619   time_elapsed = 1297.869   time_remaining = 5545\n",
      "Epoch 570 Batch    6/6   train_loss = 1.645   time_elapsed = 1300.071   time_remaining = 5542\n",
      "Epoch 571 Batch    6/6   train_loss = 1.627   time_elapsed = 1302.260   time_remaining = 5540\n",
      "Model Trained and Saved\n",
      "Epoch 572 Batch    6/6   train_loss = 1.623   time_elapsed = 1305.112   time_remaining = 5540\n",
      "Epoch 573 Batch    6/6   train_loss = 1.595   time_elapsed = 1307.300   time_remaining = 5537\n",
      "Epoch 574 Batch    6/6   train_loss = 1.605   time_elapsed = 1309.489   time_remaining = 5535\n",
      "Epoch 575 Batch    6/6   train_loss = 1.566   time_elapsed = 1311.684   time_remaining = 5532\n",
      "Epoch 576 Batch    6/6   train_loss = 1.573   time_elapsed = 1313.876   time_remaining = 5529\n",
      "Epoch 577 Batch    6/6   train_loss = 1.558   time_elapsed = 1316.083   time_remaining = 5527\n",
      "Epoch 578 Batch    6/6   train_loss = 1.557   time_elapsed = 1318.275   time_remaining = 5524\n",
      "Epoch 579 Batch    6/6   train_loss = 1.558   time_elapsed = 1320.467   time_remaining = 5521\n",
      "Epoch 580 Batch    6/6   train_loss = 1.548   time_elapsed = 1322.652   time_remaining = 5519\n",
      "Epoch 581 Batch    6/6   train_loss = 1.562   time_elapsed = 1324.847   time_remaining = 5516\n",
      "Model Trained and Saved\n",
      "Epoch 582 Batch    6/6   train_loss = 1.539   time_elapsed = 1327.641   time_remaining = 5516\n",
      "Epoch 583 Batch    6/6   train_loss = 1.547   time_elapsed = 1329.835   time_remaining = 5513\n",
      "Epoch 584 Batch    6/6   train_loss = 1.522   time_elapsed = 1332.022   time_remaining = 5511\n",
      "Epoch 585 Batch    6/6   train_loss = 1.528   time_elapsed = 1334.211   time_remaining = 5508\n",
      "Epoch 586 Batch    6/6   train_loss = 1.517   time_elapsed = 1336.400   time_remaining = 5505\n",
      "Epoch 587 Batch    6/6   train_loss = 1.506   time_elapsed = 1338.598   time_remaining = 5503\n",
      "Epoch 588 Batch    6/6   train_loss = 1.506   time_elapsed = 1340.790   time_remaining = 5500\n",
      "Epoch 589 Batch    6/6   train_loss = 1.528   time_elapsed = 1342.979   time_remaining = 5497\n",
      "Epoch 590 Batch    6/6   train_loss = 1.541   time_elapsed = 1345.173   time_remaining = 5495\n",
      "Epoch 591 Batch    6/6   train_loss = 1.535   time_elapsed = 1347.369   time_remaining = 5492\n",
      "Model Trained and Saved\n",
      "Epoch 592 Batch    6/6   train_loss = 1.527   time_elapsed = 1350.116   time_remaining = 5492\n",
      "Epoch 593 Batch    6/6   train_loss = 1.572   time_elapsed = 1352.308   time_remaining = 5489\n",
      "Epoch 594 Batch    6/6   train_loss = 1.522   time_elapsed = 1354.493   time_remaining = 5486\n",
      "Epoch 595 Batch    6/6   train_loss = 1.519   time_elapsed = 1356.687   time_remaining = 5484\n",
      "Epoch 596 Batch    6/6   train_loss = 1.463   time_elapsed = 1358.877   time_remaining = 5481\n",
      "Epoch 597 Batch    6/6   train_loss = 1.493   time_elapsed = 1361.065   time_remaining = 5478\n",
      "Epoch 598 Batch    6/6   train_loss = 1.461   time_elapsed = 1363.256   time_remaining = 5476\n",
      "Epoch 599 Batch    6/6   train_loss = 1.450   time_elapsed = 1365.454   time_remaining = 5473\n",
      "Epoch 600 Batch    6/6   train_loss = 1.427   time_elapsed = 1367.634   time_remaining = 5471\n",
      "Epoch 601 Batch    6/6   train_loss = 1.419   time_elapsed = 1369.832   time_remaining = 5468\n",
      "Model Trained and Saved\n",
      "Epoch 602 Batch    6/6   train_loss = 1.429   time_elapsed = 1372.570   time_remaining = 5467\n",
      "Epoch 603 Batch    6/6   train_loss = 1.432   time_elapsed = 1374.761   time_remaining = 5465\n",
      "Epoch 604 Batch    6/6   train_loss = 1.411   time_elapsed = 1376.943   time_remaining = 5462\n",
      "Epoch 605 Batch    6/6   train_loss = 1.406   time_elapsed = 1379.134   time_remaining = 5460\n",
      "Epoch 606 Batch    6/6   train_loss = 1.419   time_elapsed = 1381.332   time_remaining = 5457\n",
      "Epoch 607 Batch    6/6   train_loss = 1.423   time_elapsed = 1383.516   time_remaining = 5454\n",
      "Epoch 608 Batch    6/6   train_loss = 1.413   time_elapsed = 1385.713   time_remaining = 5452\n",
      "Epoch 609 Batch    6/6   train_loss = 1.414   time_elapsed = 1387.910   time_remaining = 5449\n",
      "Epoch 610 Batch    6/6   train_loss = 1.400   time_elapsed = 1390.094   time_remaining = 5446\n",
      "Epoch 611 Batch    6/6   train_loss = 1.441   time_elapsed = 1392.289   time_remaining = 5444\n",
      "Model Trained and Saved\n",
      "Epoch 612 Batch    6/6   train_loss = 1.434   time_elapsed = 1395.196   time_remaining = 5444\n",
      "Epoch 613 Batch    6/6   train_loss = 1.400   time_elapsed = 1397.375   time_remaining = 5441\n",
      "Epoch 614 Batch    6/6   train_loss = 1.439   time_elapsed = 1399.565   time_remaining = 5439\n",
      "Epoch 615 Batch    6/6   train_loss = 1.408   time_elapsed = 1401.762   time_remaining = 5436\n",
      "Epoch 616 Batch    6/6   train_loss = 1.397   time_elapsed = 1403.959   time_remaining = 5434\n",
      "Epoch 617 Batch    6/6   train_loss = 1.358   time_elapsed = 1406.155   time_remaining = 5431\n",
      "Epoch 618 Batch    6/6   train_loss = 1.387   time_elapsed = 1408.349   time_remaining = 5428\n",
      "Epoch 619 Batch    6/6   train_loss = 1.353   time_elapsed = 1410.539   time_remaining = 5426\n",
      "Epoch 620 Batch    6/6   train_loss = 1.353   time_elapsed = 1412.724   time_remaining = 5423\n",
      "Epoch 621 Batch    6/6   train_loss = 1.345   time_elapsed = 1414.914   time_remaining = 5420\n",
      "Model Trained and Saved\n",
      "Epoch 622 Batch    6/6   train_loss = 1.350   time_elapsed = 1417.733   time_remaining = 5420\n",
      "Epoch 623 Batch    6/6   train_loss = 1.332   time_elapsed = 1419.944   time_remaining = 5418\n",
      "Epoch 624 Batch    6/6   train_loss = 1.345   time_elapsed = 1422.131   time_remaining = 5415\n",
      "Epoch 625 Batch    6/6   train_loss = 1.338   time_elapsed = 1424.328   time_remaining = 5412\n",
      "Epoch 626 Batch    6/6   train_loss = 1.321   time_elapsed = 1426.514   time_remaining = 5410\n",
      "Epoch 627 Batch    6/6   train_loss = 1.310   time_elapsed = 1428.710   time_remaining = 5407\n",
      "Epoch 628 Batch    6/6   train_loss = 1.326   time_elapsed = 1430.895   time_remaining = 5405\n",
      "Epoch 629 Batch    6/6   train_loss = 1.290   time_elapsed = 1433.087   time_remaining = 5402\n",
      "Epoch 630 Batch    6/6   train_loss = 1.296   time_elapsed = 1435.281   time_remaining = 5399\n",
      "Epoch 631 Batch    6/6   train_loss = 1.293   time_elapsed = 1437.481   time_remaining = 5397\n",
      "Model Trained and Saved\n",
      "Epoch 632 Batch    6/6   train_loss = 1.298   time_elapsed = 1440.226   time_remaining = 5396\n",
      "Epoch 633 Batch    6/6   train_loss = 1.264   time_elapsed = 1442.425   time_remaining = 5394\n",
      "Epoch 634 Batch    6/6   train_loss = 1.289   time_elapsed = 1444.616   time_remaining = 5391\n",
      "Epoch 635 Batch    6/6   train_loss = 1.301   time_elapsed = 1446.804   time_remaining = 5388\n",
      "Epoch 636 Batch    6/6   train_loss = 1.258   time_elapsed = 1449.008   time_remaining = 5386\n",
      "Epoch 637 Batch    6/6   train_loss = 1.268   time_elapsed = 1451.200   time_remaining = 5383\n",
      "Epoch 638 Batch    6/6   train_loss = 1.277   time_elapsed = 1453.392   time_remaining = 5381\n",
      "Epoch 639 Batch    6/6   train_loss = 1.229   time_elapsed = 1455.583   time_remaining = 5378\n",
      "Epoch 640 Batch    6/6   train_loss = 1.254   time_elapsed = 1457.773   time_remaining = 5376\n",
      "Epoch 641 Batch    6/6   train_loss = 1.259   time_elapsed = 1459.962   time_remaining = 5373\n",
      "Model Trained and Saved\n",
      "Epoch 642 Batch    6/6   train_loss = 1.237   time_elapsed = 1462.697   time_remaining = 5372\n",
      "Epoch 643 Batch    6/6   train_loss = 1.244   time_elapsed = 1464.884   time_remaining = 5370\n",
      "Epoch 644 Batch    6/6   train_loss = 1.265   time_elapsed = 1467.069   time_remaining = 5367\n",
      "Epoch 645 Batch    6/6   train_loss = 1.230   time_elapsed = 1469.260   time_remaining = 5365\n",
      "Epoch 646 Batch    6/6   train_loss = 1.237   time_elapsed = 1471.454   time_remaining = 5362\n",
      "Epoch 647 Batch    6/6   train_loss = 1.246   time_elapsed = 1473.629   time_remaining = 5359\n",
      "Epoch 648 Batch    6/6   train_loss = 1.231   time_elapsed = 1475.824   time_remaining = 5357\n",
      "Epoch 649 Batch    6/6   train_loss = 1.222   time_elapsed = 1478.019   time_remaining = 5354\n",
      "Epoch 650 Batch    6/6   train_loss = 1.227   time_elapsed = 1480.208   time_remaining = 5352\n",
      "Epoch 651 Batch    6/6   train_loss = 1.216   time_elapsed = 1482.406   time_remaining = 5349\n",
      "Model Trained and Saved\n",
      "Epoch 652 Batch    6/6   train_loss = 1.225   time_elapsed = 1485.378   time_remaining = 5349\n",
      "Epoch 653 Batch    6/6   train_loss = 1.242   time_elapsed = 1487.564   time_remaining = 5347\n",
      "Epoch 654 Batch    6/6   train_loss = 1.204   time_elapsed = 1489.754   time_remaining = 5344\n",
      "Epoch 655 Batch    6/6   train_loss = 1.198   time_elapsed = 1491.946   time_remaining = 5341\n",
      "Epoch 656 Batch    6/6   train_loss = 1.215   time_elapsed = 1494.136   time_remaining = 5339\n",
      "Epoch 657 Batch    6/6   train_loss = 1.174   time_elapsed = 1496.324   time_remaining = 5336\n",
      "Epoch 658 Batch    6/6   train_loss = 1.206   time_elapsed = 1498.512   time_remaining = 5334\n",
      "Epoch 659 Batch    6/6   train_loss = 1.180   time_elapsed = 1500.701   time_remaining = 5331\n",
      "Epoch 660 Batch    6/6   train_loss = 1.177   time_elapsed = 1502.898   time_remaining = 5328\n",
      "Epoch 661 Batch    6/6   train_loss = 1.153   time_elapsed = 1505.081   time_remaining = 5326\n",
      "Model Trained and Saved\n",
      "Epoch 662 Batch    6/6   train_loss = 1.148   time_elapsed = 1507.814   time_remaining = 5325\n",
      "Epoch 663 Batch    6/6   train_loss = 1.154   time_elapsed = 1510.004   time_remaining = 5323\n",
      "Epoch 664 Batch    6/6   train_loss = 1.163   time_elapsed = 1512.182   time_remaining = 5320\n",
      "Epoch 665 Batch    6/6   train_loss = 1.137   time_elapsed = 1514.349   time_remaining = 5317\n",
      "Epoch 666 Batch    6/6   train_loss = 1.164   time_elapsed = 1516.532   time_remaining = 5315\n",
      "Epoch 667 Batch    6/6   train_loss = 1.144   time_elapsed = 1518.806   time_remaining = 5312\n",
      "Epoch 668 Batch    6/6   train_loss = 1.141   time_elapsed = 1520.969   time_remaining = 5310\n",
      "Epoch 669 Batch    6/6   train_loss = 1.133   time_elapsed = 1523.137   time_remaining = 5307\n",
      "Epoch 670 Batch    6/6   train_loss = 1.144   time_elapsed = 1525.408   time_remaining = 5305\n",
      "Epoch 671 Batch    6/6   train_loss = 1.135   time_elapsed = 1527.598   time_remaining = 5302\n",
      "Model Trained and Saved\n",
      "Epoch 672 Batch    6/6   train_loss = 1.135   time_elapsed = 1530.336   time_remaining = 5302\n",
      "Epoch 673 Batch    6/6   train_loss = 1.137   time_elapsed = 1532.524   time_remaining = 5299\n",
      "Epoch 674 Batch    6/6   train_loss = 1.096   time_elapsed = 1534.707   time_remaining = 5296\n",
      "Epoch 675 Batch    6/6   train_loss = 1.117   time_elapsed = 1536.907   time_remaining = 5294\n",
      "Epoch 676 Batch    6/6   train_loss = 1.140   time_elapsed = 1539.092   time_remaining = 5291\n",
      "Epoch 677 Batch    6/6   train_loss = 1.095   time_elapsed = 1541.280   time_remaining = 5289\n",
      "Epoch 678 Batch    6/6   train_loss = 1.165   time_elapsed = 1543.479   time_remaining = 5286\n",
      "Epoch 679 Batch    6/6   train_loss = 1.096   time_elapsed = 1545.668   time_remaining = 5283\n",
      "Epoch 680 Batch    6/6   train_loss = 1.150   time_elapsed = 1547.862   time_remaining = 5281\n",
      "Epoch 681 Batch    6/6   train_loss = 1.089   time_elapsed = 1550.061   time_remaining = 5278\n",
      "Model Trained and Saved\n",
      "Epoch 682 Batch    6/6   train_loss = 1.116   time_elapsed = 1552.810   time_remaining = 5278\n",
      "Epoch 683 Batch    6/6   train_loss = 1.092   time_elapsed = 1554.996   time_remaining = 5275\n",
      "Epoch 684 Batch    6/6   train_loss = 1.097   time_elapsed = 1557.186   time_remaining = 5273\n",
      "Epoch 685 Batch    6/6   train_loss = 1.079   time_elapsed = 1559.370   time_remaining = 5270\n",
      "Epoch 686 Batch    6/6   train_loss = 1.076   time_elapsed = 1561.554   time_remaining = 5267\n",
      "Epoch 687 Batch    6/6   train_loss = 1.091   time_elapsed = 1563.742   time_remaining = 5265\n",
      "Epoch 688 Batch    6/6   train_loss = 1.072   time_elapsed = 1565.935   time_remaining = 5262\n",
      "Epoch 689 Batch    6/6   train_loss = 1.056   time_elapsed = 1568.136   time_remaining = 5260\n",
      "Epoch 690 Batch    6/6   train_loss = 1.062   time_elapsed = 1570.411   time_remaining = 5257\n",
      "Epoch 691 Batch    6/6   train_loss = 1.056   time_elapsed = 1572.593   time_remaining = 5255\n",
      "Model Trained and Saved\n",
      "Epoch 692 Batch    6/6   train_loss = 1.050   time_elapsed = 1575.482   time_remaining = 5255\n",
      "Epoch 693 Batch    6/6   train_loss = 1.035   time_elapsed = 1577.668   time_remaining = 5252\n",
      "Epoch 694 Batch    6/6   train_loss = 1.044   time_elapsed = 1579.859   time_remaining = 5250\n",
      "Epoch 695 Batch    6/6   train_loss = 1.026   time_elapsed = 1582.054   time_remaining = 5247\n",
      "Epoch 696 Batch    6/6   train_loss = 1.035   time_elapsed = 1584.251   time_remaining = 5244\n",
      "Epoch 697 Batch    6/6   train_loss = 1.027   time_elapsed = 1586.442   time_remaining = 5242\n",
      "Epoch 698 Batch    6/6   train_loss = 1.007   time_elapsed = 1588.624   time_remaining = 5239\n",
      "Epoch 699 Batch    6/6   train_loss = 1.031   time_elapsed = 1590.818   time_remaining = 5237\n",
      "Epoch 700 Batch    6/6   train_loss = 1.019   time_elapsed = 1592.996   time_remaining = 5234\n",
      "Epoch 701 Batch    6/6   train_loss = 1.028   time_elapsed = 1595.198   time_remaining = 5232\n",
      "Model Trained and Saved\n",
      "Epoch 702 Batch    6/6   train_loss = 1.022   time_elapsed = 1597.963   time_remaining = 5231\n",
      "Epoch 703 Batch    6/6   train_loss = 1.002   time_elapsed = 1600.152   time_remaining = 5228\n",
      "Epoch 704 Batch    6/6   train_loss = 0.991   time_elapsed = 1602.340   time_remaining = 5226\n",
      "Epoch 705 Batch    6/6   train_loss = 1.000   time_elapsed = 1604.526   time_remaining = 5223\n",
      "Epoch 706 Batch    6/6   train_loss = 0.975   time_elapsed = 1606.722   time_remaining = 5221\n",
      "Epoch 707 Batch    6/6   train_loss = 0.998   time_elapsed = 1608.919   time_remaining = 5218\n",
      "Epoch 708 Batch    6/6   train_loss = 0.983   time_elapsed = 1611.125   time_remaining = 5216\n",
      "Epoch 709 Batch    6/6   train_loss = 0.984   time_elapsed = 1613.317   time_remaining = 5213\n",
      "Epoch 710 Batch    6/6   train_loss = 0.975   time_elapsed = 1615.493   time_remaining = 5211\n",
      "Epoch 711 Batch    6/6   train_loss = 0.981   time_elapsed = 1617.690   time_remaining = 5208\n",
      "Model Trained and Saved\n",
      "Epoch 712 Batch    6/6   train_loss = 0.963   time_elapsed = 1620.716   time_remaining = 5208\n",
      "Epoch 713 Batch    6/6   train_loss = 0.957   time_elapsed = 1622.915   time_remaining = 5206\n",
      "Epoch 714 Batch    6/6   train_loss = 0.967   time_elapsed = 1625.113   time_remaining = 5203\n",
      "Epoch 715 Batch    6/6   train_loss = 0.988   time_elapsed = 1627.311   time_remaining = 5201\n",
      "Epoch 716 Batch    6/6   train_loss = 0.967   time_elapsed = 1629.512   time_remaining = 5198\n",
      "Epoch 717 Batch    6/6   train_loss = 0.995   time_elapsed = 1631.703   time_remaining = 5196\n",
      "Epoch 718 Batch    6/6   train_loss = 0.961   time_elapsed = 1633.893   time_remaining = 5193\n",
      "Epoch 719 Batch    6/6   train_loss = 0.969   time_elapsed = 1636.090   time_remaining = 5190\n",
      "Epoch 720 Batch    6/6   train_loss = 0.974   time_elapsed = 1638.282   time_remaining = 5188\n",
      "Epoch 721 Batch    6/6   train_loss = 0.960   time_elapsed = 1640.477   time_remaining = 5185\n",
      "Model Trained and Saved\n",
      "Epoch 722 Batch    6/6   train_loss = 0.939   time_elapsed = 1643.348   time_remaining = 5185\n",
      "Epoch 723 Batch    6/6   train_loss = 0.936   time_elapsed = 1645.549   time_remaining = 5182\n",
      "Epoch 724 Batch    6/6   train_loss = 0.951   time_elapsed = 1647.753   time_remaining = 5180\n",
      "Epoch 725 Batch    6/6   train_loss = 0.929   time_elapsed = 1649.942   time_remaining = 5177\n",
      "Epoch 726 Batch    6/6   train_loss = 0.933   time_elapsed = 1652.137   time_remaining = 5175\n",
      "Epoch 727 Batch    6/6   train_loss = 0.938   time_elapsed = 1654.319   time_remaining = 5172\n",
      "Epoch 728 Batch    6/6   train_loss = 0.916   time_elapsed = 1656.502   time_remaining = 5170\n",
      "Epoch 729 Batch    6/6   train_loss = 0.923   time_elapsed = 1658.695   time_remaining = 5167\n",
      "Epoch 730 Batch    6/6   train_loss = 0.905   time_elapsed = 1660.889   time_remaining = 5165\n",
      "Epoch 731 Batch    6/6   train_loss = 0.907   time_elapsed = 1663.090   time_remaining = 5162\n",
      "Model Trained and Saved\n",
      "Epoch 732 Batch    6/6   train_loss = 0.905   time_elapsed = 1665.867   time_remaining = 5161\n",
      "Epoch 733 Batch    6/6   train_loss = 0.895   time_elapsed = 1668.052   time_remaining = 5159\n",
      "Epoch 734 Batch    6/6   train_loss = 0.898   time_elapsed = 1670.240   time_remaining = 5156\n",
      "Epoch 735 Batch    6/6   train_loss = 0.917   time_elapsed = 1672.427   time_remaining = 5154\n",
      "Epoch 736 Batch    6/6   train_loss = 0.884   time_elapsed = 1674.621   time_remaining = 5151\n",
      "Epoch 737 Batch    6/6   train_loss = 0.916   time_elapsed = 1676.810   time_remaining = 5149\n",
      "Epoch 738 Batch    6/6   train_loss = 0.912   time_elapsed = 1679.007   time_remaining = 5146\n",
      "Epoch 739 Batch    6/6   train_loss = 0.904   time_elapsed = 1681.193   time_remaining = 5144\n",
      "Epoch 740 Batch    6/6   train_loss = 0.898   time_elapsed = 1683.388   time_remaining = 5141\n",
      "Epoch 741 Batch    6/6   train_loss = 0.896   time_elapsed = 1685.584   time_remaining = 5139\n",
      "Model Trained and Saved\n",
      "Epoch 742 Batch    6/6   train_loss = 0.876   time_elapsed = 1688.348   time_remaining = 5138\n",
      "Epoch 743 Batch    6/6   train_loss = 0.888   time_elapsed = 1690.543   time_remaining = 5135\n",
      "Epoch 744 Batch    6/6   train_loss = 0.861   time_elapsed = 1692.731   time_remaining = 5133\n",
      "Epoch 745 Batch    6/6   train_loss = 0.864   time_elapsed = 1694.918   time_remaining = 5130\n",
      "Epoch 746 Batch    6/6   train_loss = 0.852   time_elapsed = 1697.117   time_remaining = 5128\n",
      "Epoch 747 Batch    6/6   train_loss = 0.869   time_elapsed = 1699.315   time_remaining = 5125\n",
      "Epoch 748 Batch    6/6   train_loss = 0.821   time_elapsed = 1701.508   time_remaining = 5123\n",
      "Epoch 749 Batch    6/6   train_loss = 0.865   time_elapsed = 1703.695   time_remaining = 5120\n",
      "Epoch 750 Batch    6/6   train_loss = 0.876   time_elapsed = 1705.889   time_remaining = 5118\n",
      "Epoch 751 Batch    6/6   train_loss = 0.841   time_elapsed = 1708.077   time_remaining = 5115\n",
      "Model Trained and Saved\n",
      "Epoch 752 Batch    6/6   train_loss = 0.859   time_elapsed = 1710.855   time_remaining = 5114\n",
      "Epoch 753 Batch    6/6   train_loss = 0.885   time_elapsed = 1713.053   time_remaining = 5112\n",
      "Epoch 754 Batch    6/6   train_loss = 0.853   time_elapsed = 1715.251   time_remaining = 5109\n",
      "Epoch 755 Batch    6/6   train_loss = 0.866   time_elapsed = 1717.437   time_remaining = 5107\n",
      "Epoch 756 Batch    6/6   train_loss = 0.871   time_elapsed = 1719.626   time_remaining = 5104\n",
      "Epoch 757 Batch    6/6   train_loss = 0.902   time_elapsed = 1721.817   time_remaining = 5102\n",
      "Epoch 758 Batch    6/6   train_loss = 0.859   time_elapsed = 1724.009   time_remaining = 5099\n",
      "Epoch 759 Batch    6/6   train_loss = 0.852   time_elapsed = 1726.196   time_remaining = 5097\n",
      "Epoch 760 Batch    6/6   train_loss = 0.876   time_elapsed = 1728.385   time_remaining = 5094\n",
      "Epoch 761 Batch    6/6   train_loss = 0.838   time_elapsed = 1730.581   time_remaining = 5092\n",
      "Model Trained and Saved\n",
      "Epoch 762 Batch    6/6   train_loss = 0.831   time_elapsed = 1733.356   time_remaining = 5091\n",
      "Epoch 763 Batch    6/6   train_loss = 0.830   time_elapsed = 1735.548   time_remaining = 5088\n",
      "Epoch 764 Batch    6/6   train_loss = 0.819   time_elapsed = 1737.727   time_remaining = 5086\n",
      "Epoch 765 Batch    6/6   train_loss = 0.806   time_elapsed = 1739.912   time_remaining = 5083\n",
      "Epoch 766 Batch    6/6   train_loss = 0.812   time_elapsed = 1742.097   time_remaining = 5081\n",
      "Epoch 767 Batch    6/6   train_loss = 0.825   time_elapsed = 1744.292   time_remaining = 5078\n",
      "Epoch 768 Batch    6/6   train_loss = 0.790   time_elapsed = 1746.479   time_remaining = 5076\n",
      "Epoch 769 Batch    6/6   train_loss = 0.802   time_elapsed = 1748.677   time_remaining = 5073\n",
      "Epoch 770 Batch    6/6   train_loss = 0.809   time_elapsed = 1750.866   time_remaining = 5071\n",
      "Epoch 771 Batch    6/6   train_loss = 0.784   time_elapsed = 1753.056   time_remaining = 5068\n",
      "Model Trained and Saved\n",
      "Epoch 772 Batch    6/6   train_loss = 0.777   time_elapsed = 1755.850   time_remaining = 5067\n",
      "Epoch 773 Batch    6/6   train_loss = 0.804   time_elapsed = 1758.033   time_remaining = 5065\n",
      "Epoch 774 Batch    6/6   train_loss = 0.780   time_elapsed = 1760.218   time_remaining = 5062\n",
      "Epoch 775 Batch    6/6   train_loss = 0.790   time_elapsed = 1762.404   time_remaining = 5060\n",
      "Epoch 776 Batch    6/6   train_loss = 0.786   time_elapsed = 1764.603   time_remaining = 5057\n",
      "Epoch 777 Batch    6/6   train_loss = 0.769   time_elapsed = 1766.785   time_remaining = 5055\n",
      "Epoch 778 Batch    6/6   train_loss = 0.803   time_elapsed = 1768.979   time_remaining = 5052\n",
      "Epoch 779 Batch    6/6   train_loss = 0.770   time_elapsed = 1771.174   time_remaining = 5050\n",
      "Epoch 780 Batch    6/6   train_loss = 0.767   time_elapsed = 1773.377   time_remaining = 5047\n",
      "Epoch 781 Batch    6/6   train_loss = 0.789   time_elapsed = 1775.563   time_remaining = 5045\n",
      "Model Trained and Saved\n",
      "Epoch 782 Batch    6/6   train_loss = 0.779   time_elapsed = 1778.361   time_remaining = 5044\n",
      "Epoch 783 Batch    6/6   train_loss = 0.772   time_elapsed = 1780.554   time_remaining = 5041\n",
      "Epoch 784 Batch    6/6   train_loss = 0.772   time_elapsed = 1782.744   time_remaining = 5039\n",
      "Epoch 785 Batch    6/6   train_loss = 0.798   time_elapsed = 1784.929   time_remaining = 5036\n",
      "Epoch 786 Batch    6/6   train_loss = 0.757   time_elapsed = 1787.107   time_remaining = 5034\n",
      "Epoch 787 Batch    6/6   train_loss = 0.787   time_elapsed = 1789.276   time_remaining = 5031\n",
      "Epoch 788 Batch    6/6   train_loss = 0.782   time_elapsed = 1791.446   time_remaining = 5029\n",
      "Epoch 789 Batch    6/6   train_loss = 0.749   time_elapsed = 1793.620   time_remaining = 5026\n",
      "Epoch 790 Batch    6/6   train_loss = 0.778   time_elapsed = 1795.801   time_remaining = 5024\n",
      "Epoch 791 Batch    6/6   train_loss = 0.774   time_elapsed = 1797.985   time_remaining = 5021\n",
      "Model Trained and Saved\n",
      "Epoch 792 Batch    6/6   train_loss = 0.748   time_elapsed = 1800.758   time_remaining = 5020\n",
      "Epoch 793 Batch    6/6   train_loss = 0.759   time_elapsed = 1802.956   time_remaining = 5018\n",
      "Epoch 794 Batch    6/6   train_loss = 0.777   time_elapsed = 1805.144   time_remaining = 5015\n",
      "Epoch 795 Batch    6/6   train_loss = 0.752   time_elapsed = 1807.320   time_remaining = 5013\n",
      "Epoch 796 Batch    6/6   train_loss = 0.740   time_elapsed = 1809.512   time_remaining = 5010\n",
      "Epoch 797 Batch    6/6   train_loss = 0.744   time_elapsed = 1811.693   time_remaining = 5008\n",
      "Epoch 798 Batch    6/6   train_loss = 0.727   time_elapsed = 1813.870   time_remaining = 5005\n",
      "Epoch 799 Batch    6/6   train_loss = 0.729   time_elapsed = 1816.056   time_remaining = 5003\n",
      "Epoch 800 Batch    6/6   train_loss = 0.742   time_elapsed = 1818.245   time_remaining = 5000\n",
      "Epoch 801 Batch    6/6   train_loss = 0.743   time_elapsed = 1820.445   time_remaining = 4998\n",
      "Model Trained and Saved\n",
      "Epoch 802 Batch    6/6   train_loss = 0.726   time_elapsed = 1823.240   time_remaining = 4997\n",
      "Epoch 803 Batch    6/6   train_loss = 0.713   time_elapsed = 1825.436   time_remaining = 4994\n",
      "Epoch 804 Batch    6/6   train_loss = 0.727   time_elapsed = 1827.624   time_remaining = 4992\n",
      "Epoch 805 Batch    6/6   train_loss = 0.702   time_elapsed = 1829.801   time_remaining = 4989\n",
      "Epoch 806 Batch    6/6   train_loss = 0.690   time_elapsed = 1831.992   time_remaining = 4987\n",
      "Epoch 807 Batch    6/6   train_loss = 0.709   time_elapsed = 1834.176   time_remaining = 4984\n",
      "Epoch 808 Batch    6/6   train_loss = 0.689   time_elapsed = 1836.356   time_remaining = 4982\n",
      "Epoch 809 Batch    6/6   train_loss = 0.706   time_elapsed = 1838.544   time_remaining = 4979\n",
      "Epoch 810 Batch    6/6   train_loss = 0.710   time_elapsed = 1840.735   time_remaining = 4977\n",
      "Epoch 811 Batch    6/6   train_loss = 0.697   time_elapsed = 1842.936   time_remaining = 4974\n",
      "Model Trained and Saved\n",
      "Epoch 812 Batch    6/6   train_loss = 0.709   time_elapsed = 1845.752   time_remaining = 4974\n",
      "Epoch 813 Batch    6/6   train_loss = 0.679   time_elapsed = 1847.940   time_remaining = 4971\n",
      "Epoch 814 Batch    6/6   train_loss = 0.702   time_elapsed = 1850.131   time_remaining = 4969\n",
      "Epoch 815 Batch    6/6   train_loss = 0.701   time_elapsed = 1852.321   time_remaining = 4966\n",
      "Epoch 816 Batch    6/6   train_loss = 0.682   time_elapsed = 1854.512   time_remaining = 4964\n",
      "Epoch 817 Batch    6/6   train_loss = 0.690   time_elapsed = 1856.703   time_remaining = 4961\n",
      "Epoch 818 Batch    6/6   train_loss = 0.672   time_elapsed = 1858.899   time_remaining = 4959\n",
      "Epoch 819 Batch    6/6   train_loss = 0.677   time_elapsed = 1861.088   time_remaining = 4956\n",
      "Epoch 820 Batch    6/6   train_loss = 0.676   time_elapsed = 1863.280   time_remaining = 4954\n",
      "Epoch 821 Batch    6/6   train_loss = 0.666   time_elapsed = 1865.461   time_remaining = 4951\n",
      "Model Trained and Saved\n",
      "Epoch 822 Batch    6/6   train_loss = 0.688   time_elapsed = 1868.270   time_remaining = 4950\n",
      "Epoch 823 Batch    6/6   train_loss = 0.661   time_elapsed = 1870.462   time_remaining = 4948\n",
      "Epoch 824 Batch    6/6   train_loss = 0.688   time_elapsed = 1872.666   time_remaining = 4945\n",
      "Epoch 825 Batch    6/6   train_loss = 0.668   time_elapsed = 1874.858   time_remaining = 4943\n",
      "Epoch 826 Batch    6/6   train_loss = 0.681   time_elapsed = 1877.043   time_remaining = 4940\n",
      "Epoch 827 Batch    6/6   train_loss = 0.673   time_elapsed = 1879.217   time_remaining = 4938\n",
      "Epoch 828 Batch    6/6   train_loss = 0.677   time_elapsed = 1881.406   time_remaining = 4935\n",
      "Epoch 829 Batch    6/6   train_loss = 0.666   time_elapsed = 1883.601   time_remaining = 4933\n",
      "Epoch 830 Batch    6/6   train_loss = 0.675   time_elapsed = 1885.794   time_remaining = 4930\n",
      "Epoch 831 Batch    6/6   train_loss = 0.661   time_elapsed = 1887.980   time_remaining = 4928\n",
      "Model Trained and Saved\n",
      "Epoch 832 Batch    6/6   train_loss = 0.652   time_elapsed = 1890.769   time_remaining = 4927\n",
      "Epoch 833 Batch    6/6   train_loss = 0.661   time_elapsed = 1892.975   time_remaining = 4924\n",
      "Epoch 834 Batch    6/6   train_loss = 0.661   time_elapsed = 1895.167   time_remaining = 4922\n",
      "Epoch 835 Batch    6/6   train_loss = 0.648   time_elapsed = 1897.373   time_remaining = 4920\n",
      "Epoch 836 Batch    6/6   train_loss = 0.666   time_elapsed = 1899.575   time_remaining = 4917\n",
      "Epoch 837 Batch    6/6   train_loss = 0.672   time_elapsed = 1901.774   time_remaining = 4915\n",
      "Epoch 838 Batch    6/6   train_loss = 0.632   time_elapsed = 1903.968   time_remaining = 4912\n",
      "Epoch 839 Batch    6/6   train_loss = 0.654   time_elapsed = 1906.158   time_remaining = 4910\n",
      "Epoch 840 Batch    6/6   train_loss = 0.647   time_elapsed = 1908.357   time_remaining = 4907\n",
      "Epoch 841 Batch    6/6   train_loss = 0.645   time_elapsed = 1910.546   time_remaining = 4905\n",
      "Model Trained and Saved\n",
      "Epoch 842 Batch    6/6   train_loss = 0.629   time_elapsed = 1913.413   time_remaining = 4904\n",
      "Epoch 843 Batch    6/6   train_loss = 0.642   time_elapsed = 1915.599   time_remaining = 4901\n",
      "Epoch 844 Batch    6/6   train_loss = 0.657   time_elapsed = 1917.778   time_remaining = 4899\n",
      "Epoch 845 Batch    6/6   train_loss = 0.625   time_elapsed = 1919.973   time_remaining = 4896\n",
      "Epoch 846 Batch    6/6   train_loss = 0.656   time_elapsed = 1922.162   time_remaining = 4894\n",
      "Epoch 847 Batch    6/6   train_loss = 0.632   time_elapsed = 1924.359   time_remaining = 4892\n",
      "Epoch 848 Batch    6/6   train_loss = 0.630   time_elapsed = 1926.556   time_remaining = 4889\n",
      "Epoch 849 Batch    6/6   train_loss = 0.644   time_elapsed = 1928.732   time_remaining = 4887\n",
      "Epoch 850 Batch    6/6   train_loss = 0.636   time_elapsed = 1930.914   time_remaining = 4884\n",
      "Epoch 851 Batch    6/6   train_loss = 0.629   time_elapsed = 1933.093   time_remaining = 4882\n",
      "Model Trained and Saved\n",
      "Epoch 852 Batch    6/6   train_loss = 0.626   time_elapsed = 1935.928   time_remaining = 4881\n",
      "Epoch 853 Batch    6/6   train_loss = 0.612   time_elapsed = 1938.122   time_remaining = 4878\n",
      "Epoch 854 Batch    6/6   train_loss = 0.616   time_elapsed = 1940.298   time_remaining = 4876\n",
      "Epoch 855 Batch    6/6   train_loss = 0.609   time_elapsed = 1942.485   time_remaining = 4873\n",
      "Epoch 856 Batch    6/6   train_loss = 0.615   time_elapsed = 1944.670   time_remaining = 4871\n",
      "Epoch 857 Batch    6/6   train_loss = 0.599   time_elapsed = 1946.866   time_remaining = 4868\n",
      "Epoch 858 Batch    6/6   train_loss = 0.601   time_elapsed = 1949.034   time_remaining = 4866\n",
      "Epoch 859 Batch    6/6   train_loss = 0.608   time_elapsed = 1951.217   time_remaining = 4863\n",
      "Epoch 860 Batch    6/6   train_loss = 0.600   time_elapsed = 1953.404   time_remaining = 4861\n",
      "Epoch 861 Batch    6/6   train_loss = 0.588   time_elapsed = 1955.583   time_remaining = 4858\n",
      "Model Trained and Saved\n",
      "Epoch 862 Batch    6/6   train_loss = 0.612   time_elapsed = 1958.385   time_remaining = 4857\n",
      "Epoch 863 Batch    6/6   train_loss = 0.585   time_elapsed = 1960.575   time_remaining = 4855\n",
      "Epoch 864 Batch    6/6   train_loss = 0.591   time_elapsed = 1962.763   time_remaining = 4852\n",
      "Epoch 865 Batch    6/6   train_loss = 0.595   time_elapsed = 1964.957   time_remaining = 4850\n",
      "Epoch 866 Batch    6/6   train_loss = 0.609   time_elapsed = 1967.152   time_remaining = 4847\n",
      "Epoch 867 Batch    6/6   train_loss = 0.593   time_elapsed = 1969.332   time_remaining = 4845\n",
      "Epoch 868 Batch    6/6   train_loss = 0.598   time_elapsed = 1971.617   time_remaining = 4843\n",
      "Epoch 869 Batch    6/6   train_loss = 0.597   time_elapsed = 1973.815   time_remaining = 4840\n",
      "Epoch 870 Batch    6/6   train_loss = 0.577   time_elapsed = 1976.013   time_remaining = 4838\n",
      "Epoch 871 Batch    6/6   train_loss = 0.588   time_elapsed = 1978.212   time_remaining = 4835\n",
      "Model Trained and Saved\n",
      "Epoch 872 Batch    6/6   train_loss = 0.600   time_elapsed = 1981.401   time_remaining = 4835\n",
      "Epoch 873 Batch    6/6   train_loss = 0.578   time_elapsed = 1983.679   time_remaining = 4833\n",
      "Epoch 874 Batch    6/6   train_loss = 0.573   time_elapsed = 1985.858   time_remaining = 4831\n",
      "Epoch 875 Batch    6/6   train_loss = 0.568   time_elapsed = 1988.052   time_remaining = 4828\n",
      "Epoch 876 Batch    6/6   train_loss = 0.566   time_elapsed = 1990.236   time_remaining = 4826\n",
      "Epoch 877 Batch    6/6   train_loss = 0.582   time_elapsed = 1992.424   time_remaining = 4823\n",
      "Epoch 878 Batch    6/6   train_loss = 0.574   time_elapsed = 1994.697   time_remaining = 4821\n",
      "Epoch 879 Batch    6/6   train_loss = 0.571   time_elapsed = 1996.894   time_remaining = 4818\n",
      "Epoch 880 Batch    6/6   train_loss = 0.560   time_elapsed = 1999.082   time_remaining = 4816\n",
      "Epoch 881 Batch    6/6   train_loss = 0.552   time_elapsed = 2001.272   time_remaining = 4814\n",
      "Model Trained and Saved\n",
      "Epoch 882 Batch    6/6   train_loss = 0.569   time_elapsed = 2004.089   time_remaining = 4813\n",
      "Epoch 883 Batch    6/6   train_loss = 0.569   time_elapsed = 2006.280   time_remaining = 4810\n",
      "Epoch 884 Batch    6/6   train_loss = 0.547   time_elapsed = 2008.459   time_remaining = 4808\n",
      "Epoch 885 Batch    6/6   train_loss = 0.556   time_elapsed = 2010.749   time_remaining = 4805\n",
      "Epoch 886 Batch    6/6   train_loss = 0.540   time_elapsed = 2012.936   time_remaining = 4803\n",
      "Epoch 887 Batch    6/6   train_loss = 0.563   time_elapsed = 2015.121   time_remaining = 4800\n",
      "Epoch 888 Batch    6/6   train_loss = 0.552   time_elapsed = 2017.299   time_remaining = 4798\n",
      "Epoch 889 Batch    6/6   train_loss = 0.550   time_elapsed = 2019.496   time_remaining = 4795\n",
      "Epoch 890 Batch    6/6   train_loss = 0.559   time_elapsed = 2021.690   time_remaining = 4793\n",
      "Epoch 891 Batch    6/6   train_loss = 0.547   time_elapsed = 2023.883   time_remaining = 4791\n",
      "Model Trained and Saved\n",
      "Epoch 892 Batch    6/6   train_loss = 0.553   time_elapsed = 2026.886   time_remaining = 4790\n",
      "Epoch 893 Batch    6/6   train_loss = 0.541   time_elapsed = 2029.066   time_remaining = 4788\n",
      "Epoch 894 Batch    6/6   train_loss = 0.536   time_elapsed = 2031.247   time_remaining = 4785\n",
      "Epoch 895 Batch    6/6   train_loss = 0.535   time_elapsed = 2033.437   time_remaining = 4783\n",
      "Epoch 896 Batch    6/6   train_loss = 0.532   time_elapsed = 2035.632   time_remaining = 4780\n",
      "Epoch 897 Batch    6/6   train_loss = 0.547   time_elapsed = 2037.824   time_remaining = 4778\n",
      "Epoch 898 Batch    6/6   train_loss = 0.539   time_elapsed = 2040.015   time_remaining = 4775\n",
      "Epoch 899 Batch    6/6   train_loss = 0.511   time_elapsed = 2042.206   time_remaining = 4773\n",
      "Epoch 900 Batch    6/6   train_loss = 0.547   time_elapsed = 2044.412   time_remaining = 4770\n",
      "Epoch 901 Batch    6/6   train_loss = 0.527   time_elapsed = 2046.606   time_remaining = 4768\n",
      "Model Trained and Saved\n",
      "Epoch 902 Batch    6/6   train_loss = 0.514   time_elapsed = 2049.510   time_remaining = 4767\n",
      "Epoch 903 Batch    6/6   train_loss = 0.520   time_elapsed = 2051.688   time_remaining = 4765\n",
      "Epoch 904 Batch    6/6   train_loss = 0.526   time_elapsed = 2053.882   time_remaining = 4762\n",
      "Epoch 905 Batch    6/6   train_loss = 0.534   time_elapsed = 2056.159   time_remaining = 4760\n",
      "Epoch 906 Batch    6/6   train_loss = 0.517   time_elapsed = 2058.343   time_remaining = 4757\n",
      "Epoch 907 Batch    6/6   train_loss = 0.543   time_elapsed = 2060.522   time_remaining = 4755\n",
      "Epoch 908 Batch    6/6   train_loss = 0.516   time_elapsed = 2062.701   time_remaining = 4752\n",
      "Epoch 909 Batch    6/6   train_loss = 0.532   time_elapsed = 2064.988   time_remaining = 4750\n",
      "Epoch 910 Batch    6/6   train_loss = 0.515   time_elapsed = 2067.195   time_remaining = 4748\n",
      "Epoch 911 Batch    6/6   train_loss = 0.504   time_elapsed = 2069.373   time_remaining = 4745\n",
      "Model Trained and Saved\n",
      "Epoch 912 Batch    6/6   train_loss = 0.512   time_elapsed = 2072.165   time_remaining = 4744\n",
      "Epoch 913 Batch    6/6   train_loss = 0.515   time_elapsed = 2074.435   time_remaining = 4742\n",
      "Epoch 914 Batch    6/6   train_loss = 0.513   time_elapsed = 2076.602   time_remaining = 4739\n",
      "Epoch 915 Batch    6/6   train_loss = 0.499   time_elapsed = 2078.778   time_remaining = 4737\n",
      "Epoch 916 Batch    6/6   train_loss = 0.519   time_elapsed = 2081.044   time_remaining = 4735\n",
      "Epoch 917 Batch    6/6   train_loss = 0.514   time_elapsed = 2083.226   time_remaining = 4732\n",
      "Epoch 918 Batch    6/6   train_loss = 0.500   time_elapsed = 2085.419   time_remaining = 4730\n",
      "Epoch 919 Batch    6/6   train_loss = 0.511   time_elapsed = 2087.597   time_remaining = 4727\n",
      "Epoch 920 Batch    6/6   train_loss = 0.505   time_elapsed = 2089.791   time_remaining = 4725\n",
      "Epoch 921 Batch    6/6   train_loss = 0.518   time_elapsed = 2091.978   time_remaining = 4722\n",
      "Model Trained and Saved\n",
      "Epoch 922 Batch    6/6   train_loss = 0.508   time_elapsed = 2094.821   time_remaining = 4721\n",
      "Epoch 923 Batch    6/6   train_loss = 0.491   time_elapsed = 2097.001   time_remaining = 4719\n",
      "Epoch 924 Batch    6/6   train_loss = 0.497   time_elapsed = 2099.184   time_remaining = 4716\n",
      "Epoch 925 Batch    6/6   train_loss = 0.487   time_elapsed = 2101.368   time_remaining = 4714\n",
      "Epoch 926 Batch    6/6   train_loss = 0.487   time_elapsed = 2103.551   time_remaining = 4711\n",
      "Epoch 927 Batch    6/6   train_loss = 0.500   time_elapsed = 2105.742   time_remaining = 4709\n",
      "Epoch 928 Batch    6/6   train_loss = 0.491   time_elapsed = 2107.932   time_remaining = 4707\n",
      "Epoch 929 Batch    6/6   train_loss = 0.495   time_elapsed = 2110.124   time_remaining = 4704\n",
      "Epoch 930 Batch    6/6   train_loss = 0.502   time_elapsed = 2112.328   time_remaining = 4702\n",
      "Epoch 931 Batch    6/6   train_loss = 0.483   time_elapsed = 2114.514   time_remaining = 4699\n",
      "Model Trained and Saved\n",
      "Epoch 932 Batch    6/6   train_loss = 0.482   time_elapsed = 2117.335   time_remaining = 4698\n",
      "Epoch 933 Batch    6/6   train_loss = 0.481   time_elapsed = 2119.521   time_remaining = 4696\n",
      "Epoch 934 Batch    6/6   train_loss = 0.466   time_elapsed = 2121.717   time_remaining = 4693\n",
      "Epoch 935 Batch    6/6   train_loss = 0.475   time_elapsed = 2123.905   time_remaining = 4691\n",
      "Epoch 936 Batch    6/6   train_loss = 0.471   time_elapsed = 2126.086   time_remaining = 4688\n",
      "Epoch 937 Batch    6/6   train_loss = 0.483   time_elapsed = 2128.269   time_remaining = 4686\n",
      "Epoch 938 Batch    6/6   train_loss = 0.485   time_elapsed = 2130.456   time_remaining = 4683\n",
      "Epoch 939 Batch    6/6   train_loss = 0.468   time_elapsed = 2132.640   time_remaining = 4681\n",
      "Epoch 940 Batch    6/6   train_loss = 0.485   time_elapsed = 2134.827   time_remaining = 4678\n",
      "Epoch 941 Batch    6/6   train_loss = 0.478   time_elapsed = 2137.012   time_remaining = 4676\n",
      "Model Trained and Saved\n",
      "Epoch 942 Batch    6/6   train_loss = 0.480   time_elapsed = 2139.932   time_remaining = 4675\n",
      "Epoch 943 Batch    6/6   train_loss = 0.482   time_elapsed = 2142.115   time_remaining = 4673\n",
      "Epoch 944 Batch    6/6   train_loss = 0.468   time_elapsed = 2144.303   time_remaining = 4670\n",
      "Epoch 945 Batch    6/6   train_loss = 0.467   time_elapsed = 2146.492   time_remaining = 4668\n",
      "Epoch 946 Batch    6/6   train_loss = 0.480   time_elapsed = 2148.681   time_remaining = 4665\n",
      "Epoch 947 Batch    6/6   train_loss = 0.476   time_elapsed = 2150.872   time_remaining = 4663\n",
      "Epoch 948 Batch    6/6   train_loss = 0.479   time_elapsed = 2153.079   time_remaining = 4660\n",
      "Epoch 949 Batch    6/6   train_loss = 0.464   time_elapsed = 2155.279   time_remaining = 4658\n",
      "Epoch 950 Batch    6/6   train_loss = 0.485   time_elapsed = 2157.459   time_remaining = 4656\n",
      "Epoch 951 Batch    6/6   train_loss = 0.466   time_elapsed = 2159.732   time_remaining = 4653\n",
      "Model Trained and Saved\n",
      "Epoch 952 Batch    6/6   train_loss = 0.441   time_elapsed = 2162.582   time_remaining = 4652\n",
      "Epoch 953 Batch    6/6   train_loss = 0.472   time_elapsed = 2164.786   time_remaining = 4650\n",
      "Epoch 954 Batch    6/6   train_loss = 0.472   time_elapsed = 2166.977   time_remaining = 4647\n",
      "Epoch 955 Batch    6/6   train_loss = 0.456   time_elapsed = 2169.155   time_remaining = 4645\n",
      "Epoch 956 Batch    6/6   train_loss = 0.450   time_elapsed = 2171.353   time_remaining = 4643\n",
      "Epoch 957 Batch    6/6   train_loss = 0.457   time_elapsed = 2173.556   time_remaining = 4640\n",
      "Epoch 958 Batch    6/6   train_loss = 0.458   time_elapsed = 2175.760   time_remaining = 4638\n",
      "Epoch 959 Batch    6/6   train_loss = 0.458   time_elapsed = 2177.953   time_remaining = 4635\n",
      "Epoch 960 Batch    6/6   train_loss = 0.453   time_elapsed = 2180.139   time_remaining = 4633\n",
      "Epoch 961 Batch    6/6   train_loss = 0.459   time_elapsed = 2182.327   time_remaining = 4630\n",
      "Model Trained and Saved\n",
      "Epoch 962 Batch    6/6   train_loss = 0.460   time_elapsed = 2185.288   time_remaining = 4630\n",
      "Epoch 963 Batch    6/6   train_loss = 0.448   time_elapsed = 2187.483   time_remaining = 4627\n",
      "Epoch 964 Batch    6/6   train_loss = 0.440   time_elapsed = 2189.669   time_remaining = 4625\n",
      "Epoch 965 Batch    6/6   train_loss = 0.426   time_elapsed = 2191.853   time_remaining = 4622\n",
      "Epoch 966 Batch    6/6   train_loss = 0.451   time_elapsed = 2194.044   time_remaining = 4620\n",
      "Epoch 967 Batch    6/6   train_loss = 0.443   time_elapsed = 2196.232   time_remaining = 4617\n",
      "Epoch 968 Batch    6/6   train_loss = 0.439   time_elapsed = 2198.419   time_remaining = 4615\n",
      "Epoch 969 Batch    6/6   train_loss = 0.447   time_elapsed = 2200.614   time_remaining = 4612\n",
      "Epoch 970 Batch    6/6   train_loss = 0.433   time_elapsed = 2202.801   time_remaining = 4610\n",
      "Epoch 971 Batch    6/6   train_loss = 0.427   time_elapsed = 2204.972   time_remaining = 4608\n",
      "Model Trained and Saved\n",
      "Epoch 972 Batch    6/6   train_loss = 0.434   time_elapsed = 2207.791   time_remaining = 4606\n",
      "Epoch 973 Batch    6/6   train_loss = 0.435   time_elapsed = 2209.982   time_remaining = 4604\n",
      "Epoch 974 Batch    6/6   train_loss = 0.438   time_elapsed = 2212.177   time_remaining = 4602\n",
      "Epoch 975 Batch    6/6   train_loss = 0.438   time_elapsed = 2214.356   time_remaining = 4599\n",
      "Epoch 976 Batch    6/6   train_loss = 0.418   time_elapsed = 2216.540   time_remaining = 4597\n",
      "Epoch 977 Batch    6/6   train_loss = 0.427   time_elapsed = 2218.730   time_remaining = 4594\n",
      "Epoch 978 Batch    6/6   train_loss = 0.443   time_elapsed = 2220.918   time_remaining = 4592\n",
      "Epoch 979 Batch    6/6   train_loss = 0.430   time_elapsed = 2223.115   time_remaining = 4589\n",
      "Epoch 980 Batch    6/6   train_loss = 0.433   time_elapsed = 2225.304   time_remaining = 4587\n",
      "Epoch 981 Batch    6/6   train_loss = 0.428   time_elapsed = 2227.489   time_remaining = 4584\n",
      "Model Trained and Saved\n",
      "Epoch 982 Batch    6/6   train_loss = 0.434   time_elapsed = 2230.461   time_remaining = 4584\n",
      "Epoch 983 Batch    6/6   train_loss = 0.419   time_elapsed = 2232.637   time_remaining = 4581\n",
      "Epoch 984 Batch    6/6   train_loss = 0.429   time_elapsed = 2234.824   time_remaining = 4579\n",
      "Epoch 985 Batch    6/6   train_loss = 0.423   time_elapsed = 2237.013   time_remaining = 4576\n",
      "Epoch 986 Batch    6/6   train_loss = 0.423   time_elapsed = 2239.204   time_remaining = 4574\n",
      "Epoch 987 Batch    6/6   train_loss = 0.439   time_elapsed = 2241.389   time_remaining = 4571\n",
      "Epoch 988 Batch    6/6   train_loss = 0.432   time_elapsed = 2243.576   time_remaining = 4569\n",
      "Epoch 989 Batch    6/6   train_loss = 0.413   time_elapsed = 2245.760   time_remaining = 4566\n",
      "Epoch 990 Batch    6/6   train_loss = 0.420   time_elapsed = 2247.947   time_remaining = 4564\n",
      "Epoch 991 Batch    6/6   train_loss = 0.406   time_elapsed = 2250.122   time_remaining = 4562\n",
      "Model Trained and Saved\n",
      "Epoch 992 Batch    6/6   train_loss = 0.401   time_elapsed = 2252.954   time_remaining = 4560\n",
      "Epoch 993 Batch    6/6   train_loss = 0.415   time_elapsed = 2255.126   time_remaining = 4558\n",
      "Epoch 994 Batch    6/6   train_loss = 0.406   time_elapsed = 2257.313   time_remaining = 4556\n",
      "Epoch 995 Batch    6/6   train_loss = 0.401   time_elapsed = 2259.498   time_remaining = 4553\n",
      "Epoch 996 Batch    6/6   train_loss = 0.416   time_elapsed = 2261.678   time_remaining = 4551\n",
      "Epoch 997 Batch    6/6   train_loss = 0.411   time_elapsed = 2263.869   time_remaining = 4548\n",
      "Epoch 998 Batch    6/6   train_loss = 0.407   time_elapsed = 2266.045   time_remaining = 4546\n",
      "Epoch 999 Batch    6/6   train_loss = 0.390   time_elapsed = 2268.231   time_remaining = 4543\n",
      "Epoch 1000 Batch    6/6   train_loss = 0.398   time_elapsed = 2270.411   time_remaining = 4541\n",
      "Epoch 1001 Batch    6/6   train_loss = 0.387   time_elapsed = 2272.599   time_remaining = 4538\n",
      "Model Trained and Saved\n",
      "Epoch 1002 Batch    6/6   train_loss = 0.398   time_elapsed = 2275.434   time_remaining = 4537\n",
      "Epoch 1003 Batch    6/6   train_loss = 0.410   time_elapsed = 2277.620   time_remaining = 4535\n",
      "Epoch 1004 Batch    6/6   train_loss = 0.406   time_elapsed = 2279.879   time_remaining = 4533\n",
      "Epoch 1005 Batch    6/6   train_loss = 0.406   time_elapsed = 2282.057   time_remaining = 4530\n",
      "Epoch 1006 Batch    6/6   train_loss = 0.403   time_elapsed = 2284.234   time_remaining = 4528\n",
      "Epoch 1007 Batch    6/6   train_loss = 0.402   time_elapsed = 2286.416   time_remaining = 4525\n",
      "Epoch 1008 Batch    6/6   train_loss = 0.410   time_elapsed = 2288.593   time_remaining = 4523\n",
      "Epoch 1009 Batch    6/6   train_loss = 0.409   time_elapsed = 2290.762   time_remaining = 4520\n",
      "Epoch 1010 Batch    6/6   train_loss = 0.412   time_elapsed = 2292.946   time_remaining = 4518\n",
      "Epoch 1011 Batch    6/6   train_loss = 0.402   time_elapsed = 2295.126   time_remaining = 4515\n",
      "Model Trained and Saved\n",
      "Epoch 1012 Batch    6/6   train_loss = 0.416   time_elapsed = 2297.992   time_remaining = 4514\n",
      "Epoch 1013 Batch    6/6   train_loss = 0.405   time_elapsed = 2300.274   time_remaining = 4512\n",
      "Epoch 1014 Batch    6/6   train_loss = 0.390   time_elapsed = 2302.457   time_remaining = 4510\n",
      "Epoch 1015 Batch    6/6   train_loss = 0.411   time_elapsed = 2304.655   time_remaining = 4507\n",
      "Epoch 1016 Batch    6/6   train_loss = 0.405   time_elapsed = 2306.831   time_remaining = 4505\n",
      "Epoch 1017 Batch    6/6   train_loss = 0.399   time_elapsed = 2309.033   time_remaining = 4502\n",
      "Epoch 1018 Batch    6/6   train_loss = 0.400   time_elapsed = 2311.203   time_remaining = 4500\n",
      "Epoch 1019 Batch    6/6   train_loss = 0.404   time_elapsed = 2313.377   time_remaining = 4497\n",
      "Epoch 1020 Batch    6/6   train_loss = 0.392   time_elapsed = 2315.566   time_remaining = 4495\n",
      "Epoch 1021 Batch    6/6   train_loss = 0.389   time_elapsed = 2317.857   time_remaining = 4493\n",
      "Model Trained and Saved\n",
      "Epoch 1022 Batch    6/6   train_loss = 0.402   time_elapsed = 2320.724   time_remaining = 4492\n",
      "Epoch 1023 Batch    6/6   train_loss = 0.384   time_elapsed = 2322.903   time_remaining = 4489\n",
      "Epoch 1024 Batch    6/6   train_loss = 0.385   time_elapsed = 2325.081   time_remaining = 4487\n",
      "Epoch 1025 Batch    6/6   train_loss = 0.384   time_elapsed = 2327.352   time_remaining = 4484\n",
      "Epoch 1026 Batch    6/6   train_loss = 0.375   time_elapsed = 2329.529   time_remaining = 4482\n",
      "Epoch 1027 Batch    6/6   train_loss = 0.388   time_elapsed = 2331.722   time_remaining = 4480\n",
      "Epoch 1028 Batch    6/6   train_loss = 0.376   time_elapsed = 2333.907   time_remaining = 4477\n",
      "Epoch 1029 Batch    6/6   train_loss = 0.370   time_elapsed = 2336.096   time_remaining = 4475\n",
      "Epoch 1030 Batch    6/6   train_loss = 0.378   time_elapsed = 2338.293   time_remaining = 4472\n",
      "Epoch 1031 Batch    6/6   train_loss = 0.372   time_elapsed = 2340.471   time_remaining = 4470\n",
      "Model Trained and Saved\n",
      "Epoch 1032 Batch    6/6   train_loss = 0.362   time_elapsed = 2343.325   time_remaining = 4469\n",
      "Epoch 1033 Batch    6/6   train_loss = 0.369   time_elapsed = 2345.510   time_remaining = 4466\n",
      "Epoch 1034 Batch    6/6   train_loss = 0.370   time_elapsed = 2347.692   time_remaining = 4464\n",
      "Epoch 1035 Batch    6/6   train_loss = 0.380   time_elapsed = 2349.884   time_remaining = 4461\n",
      "Epoch 1036 Batch    6/6   train_loss = 0.368   time_elapsed = 2352.068   time_remaining = 4459\n",
      "Epoch 1037 Batch    6/6   train_loss = 0.355   time_elapsed = 2354.250   time_remaining = 4457\n",
      "Epoch 1038 Batch    6/6   train_loss = 0.360   time_elapsed = 2356.430   time_remaining = 4454\n",
      "Epoch 1039 Batch    6/6   train_loss = 0.373   time_elapsed = 2358.612   time_remaining = 4452\n",
      "Epoch 1040 Batch    6/6   train_loss = 0.356   time_elapsed = 2360.794   time_remaining = 4449\n",
      "Epoch 1041 Batch    6/6   train_loss = 0.370   time_elapsed = 2362.963   time_remaining = 4447\n",
      "Model Trained and Saved\n",
      "Epoch 1042 Batch    6/6   train_loss = 0.374   time_elapsed = 2365.888   time_remaining = 4446\n",
      "Epoch 1043 Batch    6/6   train_loss = 0.373   time_elapsed = 2368.063   time_remaining = 4443\n",
      "Epoch 1044 Batch    6/6   train_loss = 0.374   time_elapsed = 2370.237   time_remaining = 4441\n",
      "Epoch 1045 Batch    6/6   train_loss = 0.356   time_elapsed = 2372.411   time_remaining = 4438\n",
      "Epoch 1046 Batch    6/6   train_loss = 0.354   time_elapsed = 2374.580   time_remaining = 4436\n",
      "Epoch 1047 Batch    6/6   train_loss = 0.378   time_elapsed = 2376.745   time_remaining = 4433\n",
      "Epoch 1048 Batch    6/6   train_loss = 0.354   time_elapsed = 2378.909   time_remaining = 4431\n",
      "Epoch 1049 Batch    6/6   train_loss = 0.364   time_elapsed = 2381.057   time_remaining = 4428\n",
      "Epoch 1050 Batch    6/6   train_loss = 0.365   time_elapsed = 2383.221   time_remaining = 4426\n",
      "Epoch 1051 Batch    6/6   train_loss = 0.372   time_elapsed = 2385.378   time_remaining = 4424\n",
      "Model Trained and Saved\n",
      "Epoch 1052 Batch    6/6   train_loss = 0.346   time_elapsed = 2388.172   time_remaining = 4422\n",
      "Epoch 1053 Batch    6/6   train_loss = 0.351   time_elapsed = 2390.330   time_remaining = 4420\n",
      "Epoch 1054 Batch    6/6   train_loss = 0.350   time_elapsed = 2392.490   time_remaining = 4417\n",
      "Epoch 1055 Batch    6/6   train_loss = 0.350   time_elapsed = 2394.653   time_remaining = 4415\n",
      "Epoch 1056 Batch    6/6   train_loss = 0.345   time_elapsed = 2396.806   time_remaining = 4412\n",
      "Epoch 1057 Batch    6/6   train_loss = 0.356   time_elapsed = 2398.964   time_remaining = 4410\n",
      "Epoch 1058 Batch    6/6   train_loss = 0.362   time_elapsed = 2401.125   time_remaining = 4407\n",
      "Epoch 1059 Batch    6/6   train_loss = 0.354   time_elapsed = 2403.283   time_remaining = 4405\n",
      "Epoch 1060 Batch    6/6   train_loss = 0.353   time_elapsed = 2405.441   time_remaining = 4402\n",
      "Epoch 1061 Batch    6/6   train_loss = 0.345   time_elapsed = 2407.594   time_remaining = 4400\n",
      "Model Trained and Saved\n",
      "Epoch 1062 Batch    6/6   train_loss = 0.350   time_elapsed = 2410.519   time_remaining = 4399\n",
      "Epoch 1063 Batch    6/6   train_loss = 0.361   time_elapsed = 2412.670   time_remaining = 4396\n",
      "Epoch 1064 Batch    6/6   train_loss = 0.352   time_elapsed = 2414.823   time_remaining = 4394\n",
      "Epoch 1065 Batch    6/6   train_loss = 0.345   time_elapsed = 2416.976   time_remaining = 4391\n",
      "Epoch 1066 Batch    6/6   train_loss = 0.338   time_elapsed = 2419.124   time_remaining = 4389\n",
      "Epoch 1067 Batch    6/6   train_loss = 0.349   time_elapsed = 2421.277   time_remaining = 4386\n",
      "Epoch 1068 Batch    6/6   train_loss = 0.352   time_elapsed = 2423.431   time_remaining = 4384\n",
      "Epoch 1069 Batch    6/6   train_loss = 0.343   time_elapsed = 2425.583   time_remaining = 4381\n",
      "Epoch 1070 Batch    6/6   train_loss = 0.341   time_elapsed = 2427.740   time_remaining = 4379\n",
      "Epoch 1071 Batch    6/6   train_loss = 0.339   time_elapsed = 2429.892   time_remaining = 4377\n",
      "Model Trained and Saved\n",
      "Epoch 1072 Batch    6/6   train_loss = 0.339   time_elapsed = 2432.704   time_remaining = 4375\n",
      "Epoch 1073 Batch    6/6   train_loss = 0.341   time_elapsed = 2434.853   time_remaining = 4373\n",
      "Epoch 1074 Batch    6/6   train_loss = 0.331   time_elapsed = 2437.005   time_remaining = 4370\n",
      "Epoch 1075 Batch    6/6   train_loss = 0.340   time_elapsed = 2439.151   time_remaining = 4368\n",
      "Epoch 1076 Batch    6/6   train_loss = 0.336   time_elapsed = 2441.298   time_remaining = 4365\n",
      "Epoch 1077 Batch    6/6   train_loss = 0.326   time_elapsed = 2443.449   time_remaining = 4363\n",
      "Epoch 1078 Batch    6/6   train_loss = 0.342   time_elapsed = 2445.596   time_remaining = 4360\n",
      "Epoch 1079 Batch    6/6   train_loss = 0.331   time_elapsed = 2447.729   time_remaining = 4358\n",
      "Epoch 1080 Batch    6/6   train_loss = 0.328   time_elapsed = 2449.877   time_remaining = 4355\n",
      "Epoch 1081 Batch    6/6   train_loss = 0.339   time_elapsed = 2452.022   time_remaining = 4353\n",
      "Model Trained and Saved\n",
      "Epoch 1082 Batch    6/6   train_loss = 0.339   time_elapsed = 2454.805   time_remaining = 4351\n",
      "Epoch 1083 Batch    6/6   train_loss = 0.330   time_elapsed = 2456.951   time_remaining = 4349\n",
      "Epoch 1084 Batch    6/6   train_loss = 0.321   time_elapsed = 2459.099   time_remaining = 4347\n",
      "Epoch 1085 Batch    6/6   train_loss = 0.334   time_elapsed = 2461.244   time_remaining = 4344\n",
      "Epoch 1086 Batch    6/6   train_loss = 0.331   time_elapsed = 2463.388   time_remaining = 4342\n",
      "Epoch 1087 Batch    6/6   train_loss = 0.328   time_elapsed = 2465.526   time_remaining = 4339\n",
      "Epoch 1088 Batch    6/6   train_loss = 0.322   time_elapsed = 2467.673   time_remaining = 4337\n",
      "Epoch 1089 Batch    6/6   train_loss = 0.321   time_elapsed = 2469.818   time_remaining = 4334\n",
      "Epoch 1090 Batch    6/6   train_loss = 0.325   time_elapsed = 2471.961   time_remaining = 4332\n",
      "Epoch 1091 Batch    6/6   train_loss = 0.325   time_elapsed = 2474.117   time_remaining = 4329\n",
      "Model Trained and Saved\n",
      "Epoch 1092 Batch    6/6   train_loss = 0.320   time_elapsed = 2476.924   time_remaining = 4328\n",
      "Epoch 1093 Batch    6/6   train_loss = 0.325   time_elapsed = 2479.064   time_remaining = 4325\n",
      "Epoch 1094 Batch    6/6   train_loss = 0.332   time_elapsed = 2481.207   time_remaining = 4323\n",
      "Epoch 1095 Batch    6/6   train_loss = 0.317   time_elapsed = 2483.355   time_remaining = 4320\n",
      "Epoch 1096 Batch    6/6   train_loss = 0.319   time_elapsed = 2485.495   time_remaining = 4318\n",
      "Epoch 1097 Batch    6/6   train_loss = 0.334   time_elapsed = 2487.636   time_remaining = 4315\n",
      "Epoch 1098 Batch    6/6   train_loss = 0.320   time_elapsed = 2489.777   time_remaining = 4313\n",
      "Epoch 1099 Batch    6/6   train_loss = 0.316   time_elapsed = 2491.921   time_remaining = 4310\n",
      "Epoch 1100 Batch    6/6   train_loss = 0.321   time_elapsed = 2494.063   time_remaining = 4308\n",
      "Epoch 1101 Batch    6/6   train_loss = 0.331   time_elapsed = 2496.212   time_remaining = 4305\n",
      "Model Trained and Saved\n",
      "Epoch 1102 Batch    6/6   train_loss = 0.310   time_elapsed = 2498.995   time_remaining = 4304\n",
      "Epoch 1103 Batch    6/6   train_loss = 0.321   time_elapsed = 2501.148   time_remaining = 4302\n",
      "Epoch 1104 Batch    6/6   train_loss = 0.336   time_elapsed = 2503.299   time_remaining = 4299\n",
      "Epoch 1105 Batch    6/6   train_loss = 0.319   time_elapsed = 2505.450   time_remaining = 4297\n",
      "Epoch 1106 Batch    6/6   train_loss = 0.321   time_elapsed = 2507.603   time_remaining = 4294\n",
      "Epoch 1107 Batch    6/6   train_loss = 0.321   time_elapsed = 2509.759   time_remaining = 4292\n",
      "Epoch 1108 Batch    6/6   train_loss = 0.317   time_elapsed = 2511.905   time_remaining = 4289\n",
      "Epoch 1109 Batch    6/6   train_loss = 0.321   time_elapsed = 2514.050   time_remaining = 4287\n",
      "Epoch 1110 Batch    6/6   train_loss = 0.305   time_elapsed = 2516.203   time_remaining = 4284\n",
      "Epoch 1111 Batch    6/6   train_loss = 0.313   time_elapsed = 2518.357   time_remaining = 4282\n",
      "Model Trained and Saved\n",
      "Epoch 1112 Batch    6/6   train_loss = 0.303   time_elapsed = 2521.170   time_remaining = 4281\n",
      "Epoch 1113 Batch    6/6   train_loss = 0.304   time_elapsed = 2523.313   time_remaining = 4278\n",
      "Epoch 1114 Batch    6/6   train_loss = 0.308   time_elapsed = 2525.463   time_remaining = 4276\n",
      "Epoch 1115 Batch    6/6   train_loss = 0.323   time_elapsed = 2527.616   time_remaining = 4273\n",
      "Epoch 1116 Batch    6/6   train_loss = 0.323   time_elapsed = 2529.771   time_remaining = 4271\n",
      "Epoch 1117 Batch    6/6   train_loss = 0.311   time_elapsed = 2531.923   time_remaining = 4268\n",
      "Epoch 1118 Batch    6/6   train_loss = 0.305   time_elapsed = 2534.076   time_remaining = 4266\n",
      "Epoch 1119 Batch    6/6   train_loss = 0.310   time_elapsed = 2536.219   time_remaining = 4263\n",
      "Epoch 1120 Batch    6/6   train_loss = 0.300   time_elapsed = 2538.368   time_remaining = 4261\n",
      "Epoch 1121 Batch    6/6   train_loss = 0.303   time_elapsed = 2540.514   time_remaining = 4258\n",
      "Model Trained and Saved\n",
      "Epoch 1122 Batch    6/6   train_loss = 0.294   time_elapsed = 2543.315   time_remaining = 4257\n",
      "Epoch 1123 Batch    6/6   train_loss = 0.299   time_elapsed = 2545.462   time_remaining = 4255\n",
      "Epoch 1124 Batch    6/6   train_loss = 0.313   time_elapsed = 2547.603   time_remaining = 4252\n",
      "Epoch 1125 Batch    6/6   train_loss = 0.286   time_elapsed = 2549.749   time_remaining = 4250\n",
      "Epoch 1126 Batch    6/6   train_loss = 0.298   time_elapsed = 2551.902   time_remaining = 4247\n",
      "Epoch 1127 Batch    6/6   train_loss = 0.299   time_elapsed = 2554.054   time_remaining = 4245\n",
      "Epoch 1128 Batch    6/6   train_loss = 0.294   time_elapsed = 2556.197   time_remaining = 4242\n",
      "Epoch 1129 Batch    6/6   train_loss = 0.305   time_elapsed = 2558.348   time_remaining = 4240\n",
      "Epoch 1130 Batch    6/6   train_loss = 0.301   time_elapsed = 2560.495   time_remaining = 4237\n",
      "Epoch 1131 Batch    6/6   train_loss = 0.292   time_elapsed = 2562.643   time_remaining = 4235\n",
      "Model Trained and Saved\n",
      "Epoch 1132 Batch    6/6   train_loss = 0.299   time_elapsed = 2565.462   time_remaining = 4233\n",
      "Epoch 1133 Batch    6/6   train_loss = 0.293   time_elapsed = 2567.617   time_remaining = 4231\n",
      "Epoch 1134 Batch    6/6   train_loss = 0.307   time_elapsed = 2569.773   time_remaining = 4229\n",
      "Epoch 1135 Batch    6/6   train_loss = 0.291   time_elapsed = 2571.929   time_remaining = 4226\n",
      "Epoch 1136 Batch    6/6   train_loss = 0.298   time_elapsed = 2574.067   time_remaining = 4224\n",
      "Epoch 1137 Batch    6/6   train_loss = 0.289   time_elapsed = 2576.219   time_remaining = 4221\n",
      "Epoch 1138 Batch    6/6   train_loss = 0.302   time_elapsed = 2578.365   time_remaining = 4219\n",
      "Epoch 1139 Batch    6/6   train_loss = 0.298   time_elapsed = 2580.508   time_remaining = 4216\n",
      "Epoch 1140 Batch    6/6   train_loss = 0.299   time_elapsed = 2582.646   time_remaining = 4214\n",
      "Epoch 1141 Batch    6/6   train_loss = 0.292   time_elapsed = 2584.797   time_remaining = 4211\n",
      "Model Trained and Saved\n",
      "Epoch 1142 Batch    6/6   train_loss = 0.293   time_elapsed = 2587.712   time_remaining = 4210\n",
      "Epoch 1143 Batch    6/6   train_loss = 0.301   time_elapsed = 2589.861   time_remaining = 4208\n",
      "Epoch 1144 Batch    6/6   train_loss = 0.297   time_elapsed = 2592.016   time_remaining = 4205\n",
      "Epoch 1145 Batch    6/6   train_loss = 0.298   time_elapsed = 2594.163   time_remaining = 4203\n",
      "Epoch 1146 Batch    6/6   train_loss = 0.293   time_elapsed = 2596.306   time_remaining = 4200\n",
      "Epoch 1147 Batch    6/6   train_loss = 0.294   time_elapsed = 2598.452   time_remaining = 4198\n",
      "Epoch 1148 Batch    6/6   train_loss = 0.294   time_elapsed = 2600.614   time_remaining = 4195\n",
      "Epoch 1149 Batch    6/6   train_loss = 0.288   time_elapsed = 2602.757   time_remaining = 4193\n",
      "Epoch 1150 Batch    6/6   train_loss = 0.298   time_elapsed = 2604.904   time_remaining = 4190\n",
      "Epoch 1151 Batch    6/6   train_loss = 0.288   time_elapsed = 2607.052   time_remaining = 4188\n",
      "Model Trained and Saved\n",
      "Epoch 1152 Batch    6/6   train_loss = 0.299   time_elapsed = 2609.879   time_remaining = 4187\n",
      "Epoch 1153 Batch    6/6   train_loss = 0.283   time_elapsed = 2612.017   time_remaining = 4184\n",
      "Epoch 1154 Batch    6/6   train_loss = 0.278   time_elapsed = 2614.163   time_remaining = 4182\n",
      "Epoch 1155 Batch    6/6   train_loss = 0.286   time_elapsed = 2616.308   time_remaining = 4179\n",
      "Epoch 1156 Batch    6/6   train_loss = 0.290   time_elapsed = 2618.448   time_remaining = 4177\n",
      "Epoch 1157 Batch    6/6   train_loss = 0.289   time_elapsed = 2620.590   time_remaining = 4174\n",
      "Epoch 1158 Batch    6/6   train_loss = 0.271   time_elapsed = 2622.738   time_remaining = 4172\n",
      "Epoch 1159 Batch    6/6   train_loss = 0.281   time_elapsed = 2624.878   time_remaining = 4169\n",
      "Epoch 1160 Batch    6/6   train_loss = 0.286   time_elapsed = 2627.021   time_remaining = 4167\n",
      "Epoch 1161 Batch    6/6   train_loss = 0.275   time_elapsed = 2629.162   time_remaining = 4165\n",
      "Model Trained and Saved\n",
      "Epoch 1162 Batch    6/6   train_loss = 0.275   time_elapsed = 2631.991   time_remaining = 4163\n",
      "Epoch 1163 Batch    6/6   train_loss = 0.278   time_elapsed = 2634.127   time_remaining = 4161\n",
      "Epoch 1164 Batch    6/6   train_loss = 0.273   time_elapsed = 2636.279   time_remaining = 4158\n",
      "Epoch 1165 Batch    6/6   train_loss = 0.268   time_elapsed = 2638.425   time_remaining = 4156\n",
      "Epoch 1166 Batch    6/6   train_loss = 0.277   time_elapsed = 2640.570   time_remaining = 4153\n",
      "Epoch 1167 Batch    6/6   train_loss = 0.265   time_elapsed = 2642.714   time_remaining = 4151\n",
      "Epoch 1168 Batch    6/6   train_loss = 0.275   time_elapsed = 2644.859   time_remaining = 4148\n",
      "Epoch 1169 Batch    6/6   train_loss = 0.274   time_elapsed = 2647.008   time_remaining = 4146\n",
      "Epoch 1170 Batch    6/6   train_loss = 0.270   time_elapsed = 2649.158   time_remaining = 4144\n",
      "Epoch 1171 Batch    6/6   train_loss = 0.279   time_elapsed = 2651.296   time_remaining = 4141\n",
      "Model Trained and Saved\n",
      "Epoch 1172 Batch    6/6   train_loss = 0.277   time_elapsed = 2654.115   time_remaining = 4140\n",
      "Epoch 1173 Batch    6/6   train_loss = 0.285   time_elapsed = 2656.260   time_remaining = 4137\n",
      "Epoch 1174 Batch    6/6   train_loss = 0.271   time_elapsed = 2658.397   time_remaining = 4135\n",
      "Epoch 1175 Batch    6/6   train_loss = 0.283   time_elapsed = 2660.533   time_remaining = 4132\n",
      "Epoch 1176 Batch    6/6   train_loss = 0.273   time_elapsed = 2662.678   time_remaining = 4130\n",
      "Epoch 1177 Batch    6/6   train_loss = 0.267   time_elapsed = 2664.825   time_remaining = 4127\n",
      "Epoch 1178 Batch    6/6   train_loss = 0.273   time_elapsed = 2666.964   time_remaining = 4125\n",
      "Epoch 1179 Batch    6/6   train_loss = 0.265   time_elapsed = 2669.115   time_remaining = 4123\n",
      "Epoch 1180 Batch    6/6   train_loss = 0.265   time_elapsed = 2671.259   time_remaining = 4120\n",
      "Epoch 1181 Batch    6/6   train_loss = 0.268   time_elapsed = 2673.406   time_remaining = 4118\n",
      "Model Trained and Saved\n",
      "Epoch 1182 Batch    6/6   train_loss = 0.270   time_elapsed = 2676.342   time_remaining = 4116\n",
      "Epoch 1183 Batch    6/6   train_loss = 0.271   time_elapsed = 2678.491   time_remaining = 4114\n",
      "Epoch 1184 Batch    6/6   train_loss = 0.264   time_elapsed = 2680.629   time_remaining = 4112\n",
      "Epoch 1185 Batch    6/6   train_loss = 0.270   time_elapsed = 2682.779   time_remaining = 4109\n",
      "Epoch 1186 Batch    6/6   train_loss = 0.273   time_elapsed = 2684.921   time_remaining = 4107\n",
      "Epoch 1187 Batch    6/6   train_loss = 0.275   time_elapsed = 2687.066   time_remaining = 4104\n",
      "Epoch 1188 Batch    6/6   train_loss = 0.270   time_elapsed = 2689.215   time_remaining = 4102\n",
      "Epoch 1189 Batch    6/6   train_loss = 0.266   time_elapsed = 2691.366   time_remaining = 4099\n",
      "Epoch 1190 Batch    6/6   train_loss = 0.263   time_elapsed = 2693.515   time_remaining = 4097\n",
      "Epoch 1191 Batch    6/6   train_loss = 0.271   time_elapsed = 2695.661   time_remaining = 4094\n",
      "Model Trained and Saved\n",
      "Epoch 1192 Batch    6/6   train_loss = 0.274   time_elapsed = 2698.518   time_remaining = 4093\n",
      "Epoch 1193 Batch    6/6   train_loss = 0.260   time_elapsed = 2700.666   time_remaining = 4091\n",
      "Epoch 1194 Batch    6/6   train_loss = 0.279   time_elapsed = 2702.818   time_remaining = 4088\n",
      "Epoch 1195 Batch    6/6   train_loss = 0.271   time_elapsed = 2704.973   time_remaining = 4086\n",
      "Epoch 1196 Batch    6/6   train_loss = 0.270   time_elapsed = 2707.126   time_remaining = 4083\n",
      "Epoch 1197 Batch    6/6   train_loss = 0.271   time_elapsed = 2709.281   time_remaining = 4081\n",
      "Epoch 1198 Batch    6/6   train_loss = 0.276   time_elapsed = 2711.429   time_remaining = 4078\n",
      "Epoch 1199 Batch    6/6   train_loss = 0.268   time_elapsed = 2713.581   time_remaining = 4076\n",
      "Epoch 1200 Batch    6/6   train_loss = 0.279   time_elapsed = 2715.739   time_remaining = 4074\n",
      "Epoch 1201 Batch    6/6   train_loss = 0.274   time_elapsed = 2717.890   time_remaining = 4071\n",
      "Model Trained and Saved\n",
      "Epoch 1202 Batch    6/6   train_loss = 0.268   time_elapsed = 2720.738   time_remaining = 4070\n",
      "Epoch 1203 Batch    6/6   train_loss = 0.268   time_elapsed = 2722.892   time_remaining = 4067\n",
      "Epoch 1204 Batch    6/6   train_loss = 0.269   time_elapsed = 2725.047   time_remaining = 4065\n",
      "Epoch 1205 Batch    6/6   train_loss = 0.247   time_elapsed = 2727.206   time_remaining = 4063\n",
      "Epoch 1206 Batch    6/6   train_loss = 0.260   time_elapsed = 2729.367   time_remaining = 4060\n",
      "Epoch 1207 Batch    6/6   train_loss = 0.265   time_elapsed = 2731.522   time_remaining = 4058\n",
      "Epoch 1208 Batch    6/6   train_loss = 0.255   time_elapsed = 2733.679   time_remaining = 4055\n",
      "Epoch 1209 Batch    6/6   train_loss = 0.264   time_elapsed = 2735.839   time_remaining = 4053\n",
      "Epoch 1210 Batch    6/6   train_loss = 0.256   time_elapsed = 2737.991   time_remaining = 4050\n",
      "Epoch 1211 Batch    6/6   train_loss = 0.246   time_elapsed = 2740.149   time_remaining = 4048\n",
      "Model Trained and Saved\n",
      "Epoch 1212 Batch    6/6   train_loss = 0.253   time_elapsed = 2742.998   time_remaining = 4047\n",
      "Epoch 1213 Batch    6/6   train_loss = 0.249   time_elapsed = 2745.150   time_remaining = 4044\n",
      "Epoch 1214 Batch    6/6   train_loss = 0.262   time_elapsed = 2747.301   time_remaining = 4042\n",
      "Epoch 1215 Batch    6/6   train_loss = 0.253   time_elapsed = 2749.462   time_remaining = 4039\n",
      "Epoch 1216 Batch    6/6   train_loss = 0.244   time_elapsed = 2751.622   time_remaining = 4037\n",
      "Epoch 1217 Batch    6/6   train_loss = 0.257   time_elapsed = 2753.775   time_remaining = 4034\n",
      "Epoch 1218 Batch    6/6   train_loss = 0.253   time_elapsed = 2755.937   time_remaining = 4032\n",
      "Epoch 1219 Batch    6/6   train_loss = 0.246   time_elapsed = 2758.094   time_remaining = 4030\n",
      "Epoch 1220 Batch    6/6   train_loss = 0.255   time_elapsed = 2760.259   time_remaining = 4027\n",
      "Epoch 1221 Batch    6/6   train_loss = 0.256   time_elapsed = 2762.421   time_remaining = 4025\n",
      "Model Trained and Saved\n",
      "Epoch 1222 Batch    6/6   train_loss = 0.242   time_elapsed = 2765.314   time_remaining = 4024\n",
      "Epoch 1223 Batch    6/6   train_loss = 0.263   time_elapsed = 2767.480   time_remaining = 4021\n",
      "Epoch 1224 Batch    6/6   train_loss = 0.242   time_elapsed = 2769.643   time_remaining = 4019\n",
      "Epoch 1225 Batch    6/6   train_loss = 0.263   time_elapsed = 2771.802   time_remaining = 4016\n",
      "Epoch 1226 Batch    6/6   train_loss = 0.253   time_elapsed = 2773.961   time_remaining = 4014\n",
      "Epoch 1227 Batch    6/6   train_loss = 0.254   time_elapsed = 2776.126   time_remaining = 4011\n",
      "Epoch 1228 Batch    6/6   train_loss = 0.252   time_elapsed = 2778.289   time_remaining = 4009\n",
      "Epoch 1229 Batch    6/6   train_loss = 0.258   time_elapsed = 2780.450   time_remaining = 4007\n",
      "Epoch 1230 Batch    6/6   train_loss = 0.250   time_elapsed = 2782.612   time_remaining = 4004\n",
      "Epoch 1231 Batch    6/6   train_loss = 0.257   time_elapsed = 2784.774   time_remaining = 4002\n",
      "Model Trained and Saved\n",
      "Epoch 1232 Batch    6/6   train_loss = 0.240   time_elapsed = 2787.631   time_remaining = 4000\n",
      "Epoch 1233 Batch    6/6   train_loss = 0.244   time_elapsed = 2789.797   time_remaining = 3998\n",
      "Epoch 1234 Batch    6/6   train_loss = 0.248   time_elapsed = 2791.967   time_remaining = 3996\n",
      "Epoch 1235 Batch    6/6   train_loss = 0.247   time_elapsed = 2794.123   time_remaining = 3993\n",
      "Epoch 1236 Batch    6/6   train_loss = 0.257   time_elapsed = 2796.286   time_remaining = 3991\n",
      "Epoch 1237 Batch    6/6   train_loss = 0.254   time_elapsed = 2798.449   time_remaining = 3988\n",
      "Epoch 1238 Batch    6/6   train_loss = 0.240   time_elapsed = 2800.614   time_remaining = 3986\n",
      "Epoch 1239 Batch    6/6   train_loss = 0.244   time_elapsed = 2802.777   time_remaining = 3984\n",
      "Epoch 1240 Batch    6/6   train_loss = 0.242   time_elapsed = 2804.946   time_remaining = 3981\n",
      "Epoch 1241 Batch    6/6   train_loss = 0.234   time_elapsed = 2807.117   time_remaining = 3979\n",
      "Model Trained and Saved\n",
      "Epoch 1242 Batch    6/6   train_loss = 0.244   time_elapsed = 2809.981   time_remaining = 3977\n",
      "Epoch 1243 Batch    6/6   train_loss = 0.245   time_elapsed = 2812.147   time_remaining = 3975\n",
      "Epoch 1244 Batch    6/6   train_loss = 0.241   time_elapsed = 2814.306   time_remaining = 3973\n",
      "Epoch 1245 Batch    6/6   train_loss = 0.238   time_elapsed = 2816.473   time_remaining = 3970\n",
      "Epoch 1246 Batch    6/6   train_loss = 0.241   time_elapsed = 2818.640   time_remaining = 3968\n",
      "Epoch 1247 Batch    6/6   train_loss = 0.243   time_elapsed = 2820.799   time_remaining = 3965\n",
      "Epoch 1248 Batch    6/6   train_loss = 0.252   time_elapsed = 2822.960   time_remaining = 3963\n",
      "Epoch 1249 Batch    6/6   train_loss = 0.236   time_elapsed = 2825.123   time_remaining = 3961\n",
      "Epoch 1250 Batch    6/6   train_loss = 0.236   time_elapsed = 2827.290   time_remaining = 3958\n",
      "Epoch 1251 Batch    6/6   train_loss = 0.242   time_elapsed = 2829.454   time_remaining = 3956\n",
      "Model Trained and Saved\n",
      "Epoch 1252 Batch    6/6   train_loss = 0.239   time_elapsed = 2832.354   time_remaining = 3954\n",
      "Epoch 1253 Batch    6/6   train_loss = 0.241   time_elapsed = 2834.521   time_remaining = 3952\n",
      "Epoch 1254 Batch    6/6   train_loss = 0.253   time_elapsed = 2836.681   time_remaining = 3950\n",
      "Epoch 1255 Batch    6/6   train_loss = 0.232   time_elapsed = 2838.845   time_remaining = 3947\n",
      "Epoch 1256 Batch    6/6   train_loss = 0.238   time_elapsed = 2841.020   time_remaining = 3945\n",
      "Epoch 1257 Batch    6/6   train_loss = 0.242   time_elapsed = 2843.186   time_remaining = 3942\n",
      "Epoch 1258 Batch    6/6   train_loss = 0.254   time_elapsed = 2845.353   time_remaining = 3940\n",
      "Epoch 1259 Batch    6/6   train_loss = 0.237   time_elapsed = 2847.513   time_remaining = 3938\n",
      "Epoch 1260 Batch    6/6   train_loss = 0.250   time_elapsed = 2849.685   time_remaining = 3935\n",
      "Epoch 1261 Batch    6/6   train_loss = 0.229   time_elapsed = 2851.851   time_remaining = 3933\n",
      "Model Trained and Saved\n",
      "Epoch 1262 Batch    6/6   train_loss = 0.227   time_elapsed = 2854.730   time_remaining = 3931\n",
      "Epoch 1263 Batch    6/6   train_loss = 0.228   time_elapsed = 2856.897   time_remaining = 3929\n",
      "Epoch 1264 Batch    6/6   train_loss = 0.237   time_elapsed = 2859.062   time_remaining = 3927\n",
      "Epoch 1265 Batch    6/6   train_loss = 0.235   time_elapsed = 2861.226   time_remaining = 3924\n",
      "Epoch 1266 Batch    6/6   train_loss = 0.234   time_elapsed = 2863.392   time_remaining = 3922\n",
      "Epoch 1267 Batch    6/6   train_loss = 0.233   time_elapsed = 2865.564   time_remaining = 3920\n",
      "Epoch 1268 Batch    6/6   train_loss = 0.230   time_elapsed = 2867.728   time_remaining = 3917\n",
      "Epoch 1269 Batch    6/6   train_loss = 0.234   time_elapsed = 2869.897   time_remaining = 3915\n",
      "Epoch 1270 Batch    6/6   train_loss = 0.227   time_elapsed = 2872.064   time_remaining = 3912\n",
      "Epoch 1271 Batch    6/6   train_loss = 0.232   time_elapsed = 2874.228   time_remaining = 3910\n",
      "Model Trained and Saved\n",
      "Epoch 1272 Batch    6/6   train_loss = 0.222   time_elapsed = 2877.347   time_remaining = 3909\n",
      "Epoch 1273 Batch    6/6   train_loss = 0.226   time_elapsed = 2879.519   time_remaining = 3906\n",
      "Epoch 1274 Batch    6/6   train_loss = 0.239   time_elapsed = 2881.682   time_remaining = 3904\n",
      "Epoch 1275 Batch    6/6   train_loss = 0.219   time_elapsed = 2883.856   time_remaining = 3902\n",
      "Epoch 1276 Batch    6/6   train_loss = 0.225   time_elapsed = 2886.016   time_remaining = 3899\n",
      "Epoch 1277 Batch    6/6   train_loss = 0.222   time_elapsed = 2888.183   time_remaining = 3897\n",
      "Epoch 1278 Batch    6/6   train_loss = 0.233   time_elapsed = 2890.347   time_remaining = 3895\n",
      "Epoch 1279 Batch    6/6   train_loss = 0.232   time_elapsed = 2892.517   time_remaining = 3892\n",
      "Epoch 1280 Batch    6/6   train_loss = 0.221   time_elapsed = 2894.678   time_remaining = 3890\n",
      "Epoch 1281 Batch    6/6   train_loss = 0.229   time_elapsed = 2896.842   time_remaining = 3887\n",
      "Model Trained and Saved\n",
      "Epoch 1282 Batch    6/6   train_loss = 0.225   time_elapsed = 2899.723   time_remaining = 3886\n",
      "Epoch 1283 Batch    6/6   train_loss = 0.239   time_elapsed = 2901.896   time_remaining = 3884\n",
      "Epoch 1284 Batch    6/6   train_loss = 0.225   time_elapsed = 2904.062   time_remaining = 3881\n",
      "Epoch 1285 Batch    6/6   train_loss = 0.221   time_elapsed = 2906.239   time_remaining = 3879\n",
      "Epoch 1286 Batch    6/6   train_loss = 0.226   time_elapsed = 2908.398   time_remaining = 3876\n",
      "Epoch 1287 Batch    6/6   train_loss = 0.231   time_elapsed = 2910.574   time_remaining = 3874\n",
      "Epoch 1288 Batch    6/6   train_loss = 0.230   time_elapsed = 2912.743   time_remaining = 3872\n",
      "Epoch 1289 Batch    6/6   train_loss = 0.224   time_elapsed = 2914.909   time_remaining = 3869\n",
      "Epoch 1290 Batch    6/6   train_loss = 0.228   time_elapsed = 2917.083   time_remaining = 3867\n",
      "Epoch 1291 Batch    6/6   train_loss = 0.226   time_elapsed = 2919.248   time_remaining = 3864\n",
      "Model Trained and Saved\n",
      "Epoch 1292 Batch    6/6   train_loss = 0.213   time_elapsed = 2922.150   time_remaining = 3863\n",
      "Epoch 1293 Batch    6/6   train_loss = 0.219   time_elapsed = 2924.314   time_remaining = 3861\n",
      "Epoch 1294 Batch    6/6   train_loss = 0.228   time_elapsed = 2926.494   time_remaining = 3858\n",
      "Epoch 1295 Batch    6/6   train_loss = 0.225   time_elapsed = 2928.659   time_remaining = 3856\n",
      "Epoch 1296 Batch    6/6   train_loss = 0.221   time_elapsed = 2930.829   time_remaining = 3853\n",
      "Epoch 1297 Batch    6/6   train_loss = 0.221   time_elapsed = 2933.001   time_remaining = 3851\n",
      "Epoch 1298 Batch    6/6   train_loss = 0.214   time_elapsed = 2935.170   time_remaining = 3849\n",
      "Epoch 1299 Batch    6/6   train_loss = 0.227   time_elapsed = 2937.337   time_remaining = 3846\n",
      "Epoch 1300 Batch    6/6   train_loss = 0.230   time_elapsed = 2939.500   time_remaining = 3844\n",
      "Epoch 1301 Batch    6/6   train_loss = 0.218   time_elapsed = 2941.673   time_remaining = 3842\n",
      "Model Trained and Saved\n",
      "Epoch 1302 Batch    6/6   train_loss = 0.223   time_elapsed = 2944.548   time_remaining = 3840\n",
      "Epoch 1303 Batch    6/6   train_loss = 0.220   time_elapsed = 2946.718   time_remaining = 3838\n",
      "Epoch 1304 Batch    6/6   train_loss = 0.226   time_elapsed = 2948.884   time_remaining = 3835\n",
      "Epoch 1305 Batch    6/6   train_loss = 0.230   time_elapsed = 2951.048   time_remaining = 3833\n",
      "Epoch 1306 Batch    6/6   train_loss = 0.218   time_elapsed = 2953.214   time_remaining = 3831\n",
      "Epoch 1307 Batch    6/6   train_loss = 0.219   time_elapsed = 2955.382   time_remaining = 3828\n",
      "Epoch 1308 Batch    6/6   train_loss = 0.222   time_elapsed = 2957.554   time_remaining = 3826\n",
      "Epoch 1309 Batch    6/6   train_loss = 0.219   time_elapsed = 2959.718   time_remaining = 3823\n",
      "Epoch 1310 Batch    6/6   train_loss = 0.207   time_elapsed = 2961.889   time_remaining = 3821\n",
      "Epoch 1311 Batch    6/6   train_loss = 0.217   time_elapsed = 2964.051   time_remaining = 3819\n",
      "Model Trained and Saved\n",
      "Epoch 1312 Batch    6/6   train_loss = 0.221   time_elapsed = 2966.943   time_remaining = 3817\n",
      "Epoch 1313 Batch    6/6   train_loss = 0.217   time_elapsed = 2969.106   time_remaining = 3815\n",
      "Epoch 1314 Batch    6/6   train_loss = 0.206   time_elapsed = 2971.271   time_remaining = 3812\n",
      "Epoch 1315 Batch    6/6   train_loss = 0.222   time_elapsed = 2973.440   time_remaining = 3810\n",
      "Epoch 1316 Batch    6/6   train_loss = 0.220   time_elapsed = 2975.599   time_remaining = 3808\n",
      "Epoch 1317 Batch    6/6   train_loss = 0.207   time_elapsed = 2977.765   time_remaining = 3805\n",
      "Epoch 1318 Batch    6/6   train_loss = 0.212   time_elapsed = 2979.928   time_remaining = 3803\n",
      "Epoch 1319 Batch    6/6   train_loss = 0.215   time_elapsed = 2982.088   time_remaining = 3801\n",
      "Epoch 1320 Batch    6/6   train_loss = 0.218   time_elapsed = 2984.254   time_remaining = 3798\n",
      "Epoch 1321 Batch    6/6   train_loss = 0.216   time_elapsed = 2986.417   time_remaining = 3796\n",
      "Model Trained and Saved\n",
      "Epoch 1322 Batch    6/6   train_loss = 0.216   time_elapsed = 2989.326   time_remaining = 3794\n",
      "Epoch 1323 Batch    6/6   train_loss = 0.215   time_elapsed = 2991.498   time_remaining = 3792\n",
      "Epoch 1324 Batch    6/6   train_loss = 0.218   time_elapsed = 2993.662   time_remaining = 3790\n",
      "Epoch 1325 Batch    6/6   train_loss = 0.206   time_elapsed = 2995.835   time_remaining = 3787\n",
      "Epoch 1326 Batch    6/6   train_loss = 0.216   time_elapsed = 2998.004   time_remaining = 3785\n",
      "Epoch 1327 Batch    6/6   train_loss = 0.214   time_elapsed = 3000.169   time_remaining = 3782\n",
      "Epoch 1328 Batch    6/6   train_loss = 0.220   time_elapsed = 3002.337   time_remaining = 3780\n",
      "Epoch 1329 Batch    6/6   train_loss = 0.214   time_elapsed = 3004.512   time_remaining = 3778\n",
      "Epoch 1330 Batch    6/6   train_loss = 0.223   time_elapsed = 3006.682   time_remaining = 3775\n",
      "Epoch 1331 Batch    6/6   train_loss = 0.216   time_elapsed = 3008.850   time_remaining = 3773\n",
      "Model Trained and Saved\n",
      "Epoch 1332 Batch    6/6   train_loss = 0.208   time_elapsed = 3011.761   time_remaining = 3771\n",
      "Epoch 1333 Batch    6/6   train_loss = 0.213   time_elapsed = 3013.925   time_remaining = 3769\n",
      "Epoch 1334 Batch    6/6   train_loss = 0.209   time_elapsed = 3016.092   time_remaining = 3767\n",
      "Epoch 1335 Batch    6/6   train_loss = 0.214   time_elapsed = 3018.256   time_remaining = 3764\n",
      "Epoch 1336 Batch    6/6   train_loss = 0.199   time_elapsed = 3020.433   time_remaining = 3762\n",
      "Epoch 1337 Batch    6/6   train_loss = 0.202   time_elapsed = 3022.607   time_remaining = 3760\n",
      "Epoch 1338 Batch    6/6   train_loss = 0.205   time_elapsed = 3024.769   time_remaining = 3757\n",
      "Epoch 1339 Batch    6/6   train_loss = 0.206   time_elapsed = 3026.932   time_remaining = 3755\n",
      "Epoch 1340 Batch    6/6   train_loss = 0.208   time_elapsed = 3029.101   time_remaining = 3752\n",
      "Epoch 1341 Batch    6/6   train_loss = 0.213   time_elapsed = 3031.285   time_remaining = 3750\n",
      "Model Trained and Saved\n",
      "Epoch 1342 Batch    6/6   train_loss = 0.209   time_elapsed = 3034.200   time_remaining = 3749\n",
      "Epoch 1343 Batch    6/6   train_loss = 0.202   time_elapsed = 3036.369   time_remaining = 3746\n",
      "Epoch 1344 Batch    6/6   train_loss = 0.212   time_elapsed = 3038.533   time_remaining = 3744\n",
      "Epoch 1345 Batch    6/6   train_loss = 0.207   time_elapsed = 3040.696   time_remaining = 3742\n",
      "Epoch 1346 Batch    6/6   train_loss = 0.204   time_elapsed = 3042.859   time_remaining = 3739\n",
      "Epoch 1347 Batch    6/6   train_loss = 0.197   time_elapsed = 3045.037   time_remaining = 3737\n",
      "Epoch 1348 Batch    6/6   train_loss = 0.204   time_elapsed = 3047.203   time_remaining = 3734\n",
      "Epoch 1349 Batch    6/6   train_loss = 0.206   time_elapsed = 3049.375   time_remaining = 3732\n",
      "Epoch 1350 Batch    6/6   train_loss = 0.207   time_elapsed = 3051.542   time_remaining = 3730\n",
      "Epoch 1351 Batch    6/6   train_loss = 0.207   time_elapsed = 3053.706   time_remaining = 3727\n",
      "Model Trained and Saved\n",
      "Epoch 1352 Batch    6/6   train_loss = 0.204   time_elapsed = 3056.614   time_remaining = 3726\n",
      "Epoch 1353 Batch    6/6   train_loss = 0.203   time_elapsed = 3058.780   time_remaining = 3723\n",
      "Epoch 1354 Batch    6/6   train_loss = 0.201   time_elapsed = 3060.943   time_remaining = 3721\n",
      "Epoch 1355 Batch    6/6   train_loss = 0.205   time_elapsed = 3063.118   time_remaining = 3719\n",
      "Epoch 1356 Batch    6/6   train_loss = 0.206   time_elapsed = 3065.285   time_remaining = 3716\n",
      "Epoch 1357 Batch    6/6   train_loss = 0.200   time_elapsed = 3067.448   time_remaining = 3714\n",
      "Epoch 1358 Batch    6/6   train_loss = 0.204   time_elapsed = 3069.607   time_remaining = 3712\n",
      "Epoch 1359 Batch    6/6   train_loss = 0.200   time_elapsed = 3071.766   time_remaining = 3709\n",
      "Epoch 1360 Batch    6/6   train_loss = 0.204   time_elapsed = 3073.928   time_remaining = 3707\n",
      "Epoch 1361 Batch    6/6   train_loss = 0.206   time_elapsed = 3076.100   time_remaining = 3704\n",
      "Model Trained and Saved\n",
      "Epoch 1362 Batch    6/6   train_loss = 0.197   time_elapsed = 3079.011   time_remaining = 3703\n",
      "Epoch 1363 Batch    6/6   train_loss = 0.210   time_elapsed = 3081.178   time_remaining = 3701\n",
      "Epoch 1364 Batch    6/6   train_loss = 0.201   time_elapsed = 3083.345   time_remaining = 3698\n",
      "Epoch 1365 Batch    6/6   train_loss = 0.200   time_elapsed = 3085.507   time_remaining = 3696\n",
      "Epoch 1366 Batch    6/6   train_loss = 0.205   time_elapsed = 3087.672   time_remaining = 3693\n",
      "Epoch 1367 Batch    6/6   train_loss = 0.200   time_elapsed = 3089.839   time_remaining = 3691\n",
      "Epoch 1368 Batch    6/6   train_loss = 0.201   time_elapsed = 3092.004   time_remaining = 3689\n",
      "Epoch 1369 Batch    6/6   train_loss = 0.203   time_elapsed = 3094.178   time_remaining = 3686\n",
      "Epoch 1370 Batch    6/6   train_loss = 0.207   time_elapsed = 3096.356   time_remaining = 3684\n",
      "Epoch 1371 Batch    6/6   train_loss = 0.196   time_elapsed = 3098.524   time_remaining = 3682\n",
      "Model Trained and Saved\n",
      "Epoch 1372 Batch    6/6   train_loss = 0.196   time_elapsed = 3101.443   time_remaining = 3680\n",
      "Epoch 1373 Batch    6/6   train_loss = 0.203   time_elapsed = 3103.609   time_remaining = 3678\n",
      "Epoch 1374 Batch    6/6   train_loss = 0.200   time_elapsed = 3105.782   time_remaining = 3675\n",
      "Epoch 1375 Batch    6/6   train_loss = 0.198   time_elapsed = 3107.947   time_remaining = 3673\n",
      "Epoch 1376 Batch    6/6   train_loss = 0.199   time_elapsed = 3110.116   time_remaining = 3671\n",
      "Epoch 1377 Batch    6/6   train_loss = 0.196   time_elapsed = 3112.273   time_remaining = 3668\n",
      "Epoch 1378 Batch    6/6   train_loss = 0.199   time_elapsed = 3114.440   time_remaining = 3666\n",
      "Epoch 1379 Batch    6/6   train_loss = 0.197   time_elapsed = 3116.609   time_remaining = 3664\n",
      "Epoch 1380 Batch    6/6   train_loss = 0.193   time_elapsed = 3118.770   time_remaining = 3661\n",
      "Epoch 1381 Batch    6/6   train_loss = 0.194   time_elapsed = 3120.935   time_remaining = 3659\n",
      "Model Trained and Saved\n",
      "Epoch 1382 Batch    6/6   train_loss = 0.196   time_elapsed = 3123.846   time_remaining = 3657\n",
      "Epoch 1383 Batch    6/6   train_loss = 0.192   time_elapsed = 3126.008   time_remaining = 3655\n",
      "Epoch 1384 Batch    6/6   train_loss = 0.174   time_elapsed = 3128.180   time_remaining = 3653\n",
      "Epoch 1385 Batch    6/6   train_loss = 0.196   time_elapsed = 3130.345   time_remaining = 3650\n",
      "Epoch 1386 Batch    6/6   train_loss = 0.204   time_elapsed = 3132.516   time_remaining = 3648\n",
      "Epoch 1387 Batch    6/6   train_loss = 0.192   time_elapsed = 3134.675   time_remaining = 3645\n",
      "Epoch 1388 Batch    6/6   train_loss = 0.206   time_elapsed = 3136.840   time_remaining = 3643\n",
      "Epoch 1389 Batch    6/6   train_loss = 0.199   time_elapsed = 3139.008   time_remaining = 3641\n",
      "Epoch 1390 Batch    6/6   train_loss = 0.199   time_elapsed = 3141.173   time_remaining = 3638\n",
      "Epoch 1391 Batch    6/6   train_loss = 0.189   time_elapsed = 3143.337   time_remaining = 3636\n",
      "Model Trained and Saved\n",
      "Epoch 1392 Batch    6/6   train_loss = 0.194   time_elapsed = 3146.244   time_remaining = 3634\n",
      "Epoch 1393 Batch    6/6   train_loss = 0.190   time_elapsed = 3148.414   time_remaining = 3632\n",
      "Epoch 1394 Batch    6/6   train_loss = 0.197   time_elapsed = 3150.581   time_remaining = 3630\n",
      "Epoch 1395 Batch    6/6   train_loss = 0.183   time_elapsed = 3152.745   time_remaining = 3627\n",
      "Epoch 1396 Batch    6/6   train_loss = 0.196   time_elapsed = 3154.906   time_remaining = 3625\n",
      "Epoch 1397 Batch    6/6   train_loss = 0.195   time_elapsed = 3157.068   time_remaining = 3623\n",
      "Epoch 1398 Batch    6/6   train_loss = 0.198   time_elapsed = 3159.229   time_remaining = 3620\n",
      "Epoch 1399 Batch    6/6   train_loss = 0.190   time_elapsed = 3161.400   time_remaining = 3618\n",
      "Epoch 1400 Batch    6/6   train_loss = 0.195   time_elapsed = 3163.569   time_remaining = 3616\n",
      "Epoch 1401 Batch    6/6   train_loss = 0.192   time_elapsed = 3165.736   time_remaining = 3613\n",
      "Model Trained and Saved\n",
      "Epoch 1402 Batch    6/6   train_loss = 0.193   time_elapsed = 3168.790   time_remaining = 3612\n",
      "Epoch 1403 Batch    6/6   train_loss = 0.198   time_elapsed = 3170.958   time_remaining = 3609\n",
      "Epoch 1404 Batch    6/6   train_loss = 0.188   time_elapsed = 3173.125   time_remaining = 3607\n",
      "Epoch 1405 Batch    6/6   train_loss = 0.201   time_elapsed = 3175.285   time_remaining = 3605\n",
      "Epoch 1406 Batch    6/6   train_loss = 0.195   time_elapsed = 3177.453   time_remaining = 3602\n",
      "Epoch 1407 Batch    6/6   train_loss = 0.191   time_elapsed = 3179.621   time_remaining = 3600\n",
      "Epoch 1408 Batch    6/6   train_loss = 0.185   time_elapsed = 3181.784   time_remaining = 3598\n",
      "Epoch 1409 Batch    6/6   train_loss = 0.201   time_elapsed = 3183.942   time_remaining = 3595\n",
      "Epoch 1410 Batch    6/6   train_loss = 0.196   time_elapsed = 3186.113   time_remaining = 3593\n",
      "Epoch 1411 Batch    6/6   train_loss = 0.188   time_elapsed = 3188.285   time_remaining = 3590\n",
      "Model Trained and Saved\n",
      "Epoch 1412 Batch    6/6   train_loss = 0.198   time_elapsed = 3191.219   time_remaining = 3589\n",
      "Epoch 1413 Batch    6/6   train_loss = 0.188   time_elapsed = 3193.386   time_remaining = 3587\n",
      "Epoch 1414 Batch    6/6   train_loss = 0.186   time_elapsed = 3195.551   time_remaining = 3584\n",
      "Epoch 1415 Batch    6/6   train_loss = 0.192   time_elapsed = 3197.708   time_remaining = 3582\n",
      "Epoch 1416 Batch    6/6   train_loss = 0.187   time_elapsed = 3199.868   time_remaining = 3580\n",
      "Epoch 1417 Batch    6/6   train_loss = 0.190   time_elapsed = 3202.026   time_remaining = 3577\n",
      "Epoch 1418 Batch    6/6   train_loss = 0.185   time_elapsed = 3204.189   time_remaining = 3575\n",
      "Epoch 1419 Batch    6/6   train_loss = 0.194   time_elapsed = 3206.344   time_remaining = 3572\n",
      "Epoch 1420 Batch    6/6   train_loss = 0.182   time_elapsed = 3208.504   time_remaining = 3570\n",
      "Epoch 1421 Batch    6/6   train_loss = 0.186   time_elapsed = 3210.654   time_remaining = 3568\n",
      "Model Trained and Saved\n",
      "Epoch 1422 Batch    6/6   train_loss = 0.191   time_elapsed = 3213.682   time_remaining = 3566\n",
      "Epoch 1423 Batch    6/6   train_loss = 0.182   time_elapsed = 3215.831   time_remaining = 3564\n",
      "Epoch 1424 Batch    6/6   train_loss = 0.190   time_elapsed = 3217.981   time_remaining = 3561\n",
      "Epoch 1425 Batch    6/6   train_loss = 0.183   time_elapsed = 3220.135   time_remaining = 3559\n",
      "Epoch 1426 Batch    6/6   train_loss = 0.188   time_elapsed = 3222.289   time_remaining = 3557\n",
      "Epoch 1427 Batch    6/6   train_loss = 0.179   time_elapsed = 3224.438   time_remaining = 3554\n",
      "Epoch 1428 Batch    6/6   train_loss = 0.197   time_elapsed = 3226.592   time_remaining = 3552\n",
      "Epoch 1429 Batch    6/6   train_loss = 0.182   time_elapsed = 3228.749   time_remaining = 3550\n",
      "Epoch 1430 Batch    6/6   train_loss = 0.185   time_elapsed = 3230.901   time_remaining = 3547\n",
      "Epoch 1431 Batch    6/6   train_loss = 0.186   time_elapsed = 3233.054   time_remaining = 3545\n",
      "Model Trained and Saved\n",
      "Epoch 1432 Batch    6/6   train_loss = 0.186   time_elapsed = 3235.962   time_remaining = 3543\n",
      "Epoch 1433 Batch    6/6   train_loss = 0.188   time_elapsed = 3238.108   time_remaining = 3541\n",
      "Epoch 1434 Batch    6/6   train_loss = 0.173   time_elapsed = 3240.261   time_remaining = 3539\n",
      "Epoch 1435 Batch    6/6   train_loss = 0.181   time_elapsed = 3242.404   time_remaining = 3536\n",
      "Epoch 1436 Batch    6/6   train_loss = 0.188   time_elapsed = 3244.565   time_remaining = 3534\n",
      "Epoch 1437 Batch    6/6   train_loss = 0.188   time_elapsed = 3246.719   time_remaining = 3531\n",
      "Epoch 1438 Batch    6/6   train_loss = 0.184   time_elapsed = 3248.875   time_remaining = 3529\n",
      "Epoch 1439 Batch    6/6   train_loss = 0.186   time_elapsed = 3251.028   time_remaining = 3527\n",
      "Epoch 1440 Batch    6/6   train_loss = 0.185   time_elapsed = 3253.180   time_remaining = 3524\n",
      "Epoch 1441 Batch    6/6   train_loss = 0.186   time_elapsed = 3255.339   time_remaining = 3522\n",
      "Model Trained and Saved\n",
      "Epoch 1442 Batch    6/6   train_loss = 0.183   time_elapsed = 3258.262   time_remaining = 3520\n",
      "Epoch 1443 Batch    6/6   train_loss = 0.181   time_elapsed = 3260.416   time_remaining = 3518\n",
      "Epoch 1444 Batch    6/6   train_loss = 0.182   time_elapsed = 3262.576   time_remaining = 3516\n",
      "Epoch 1445 Batch    6/6   train_loss = 0.178   time_elapsed = 3264.724   time_remaining = 3513\n",
      "Epoch 1446 Batch    6/6   train_loss = 0.177   time_elapsed = 3266.882   time_remaining = 3511\n",
      "Epoch 1447 Batch    6/6   train_loss = 0.182   time_elapsed = 3269.029   time_remaining = 3509\n",
      "Epoch 1448 Batch    6/6   train_loss = 0.178   time_elapsed = 3271.183   time_remaining = 3506\n",
      "Epoch 1449 Batch    6/6   train_loss = 0.184   time_elapsed = 3273.336   time_remaining = 3504\n",
      "Epoch 1450 Batch    6/6   train_loss = 0.177   time_elapsed = 3275.497   time_remaining = 3501\n",
      "Epoch 1451 Batch    6/6   train_loss = 0.177   time_elapsed = 3277.649   time_remaining = 3499\n",
      "Model Trained and Saved\n",
      "Epoch 1452 Batch    6/6   train_loss = 0.180   time_elapsed = 3280.697   time_remaining = 3498\n",
      "Epoch 1453 Batch    6/6   train_loss = 0.171   time_elapsed = 3282.857   time_remaining = 3495\n",
      "Epoch 1454 Batch    6/6   train_loss = 0.184   time_elapsed = 3285.014   time_remaining = 3493\n",
      "Epoch 1455 Batch    6/6   train_loss = 0.174   time_elapsed = 3287.172   time_remaining = 3491\n",
      "Epoch 1456 Batch    6/6   train_loss = 0.180   time_elapsed = 3289.325   time_remaining = 3488\n",
      "Epoch 1457 Batch    6/6   train_loss = 0.181   time_elapsed = 3291.487   time_remaining = 3486\n",
      "Epoch 1458 Batch    6/6   train_loss = 0.179   time_elapsed = 3293.638   time_remaining = 3483\n",
      "Epoch 1459 Batch    6/6   train_loss = 0.191   time_elapsed = 3295.794   time_remaining = 3481\n",
      "Epoch 1460 Batch    6/6   train_loss = 0.173   time_elapsed = 3297.950   time_remaining = 3479\n",
      "Epoch 1461 Batch    6/6   train_loss = 0.179   time_elapsed = 3300.109   time_remaining = 3476\n",
      "Model Trained and Saved\n",
      "Epoch 1462 Batch    6/6   train_loss = 0.186   time_elapsed = 3303.030   time_remaining = 3475\n",
      "Epoch 1463 Batch    6/6   train_loss = 0.181   time_elapsed = 3305.183   time_remaining = 3472\n",
      "Epoch 1464 Batch    6/6   train_loss = 0.178   time_elapsed = 3307.338   time_remaining = 3470\n",
      "Epoch 1465 Batch    6/6   train_loss = 0.181   time_elapsed = 3309.486   time_remaining = 3468\n",
      "Epoch 1466 Batch    6/6   train_loss = 0.177   time_elapsed = 3311.638   time_remaining = 3465\n",
      "Epoch 1467 Batch    6/6   train_loss = 0.185   time_elapsed = 3313.794   time_remaining = 3463\n",
      "Epoch 1468 Batch    6/6   train_loss = 0.178   time_elapsed = 3315.948   time_remaining = 3461\n",
      "Epoch 1469 Batch    6/6   train_loss = 0.182   time_elapsed = 3318.090   time_remaining = 3458\n",
      "Epoch 1470 Batch    6/6   train_loss = 0.180   time_elapsed = 3320.242   time_remaining = 3456\n",
      "Epoch 1471 Batch    6/6   train_loss = 0.174   time_elapsed = 3322.405   time_remaining = 3453\n",
      "Model Trained and Saved\n",
      "Epoch 1472 Batch    6/6   train_loss = 0.179   time_elapsed = 3325.350   time_remaining = 3452\n",
      "Epoch 1473 Batch    6/6   train_loss = 0.180   time_elapsed = 3327.504   time_remaining = 3449\n",
      "Epoch 1474 Batch    6/6   train_loss = 0.187   time_elapsed = 3329.657   time_remaining = 3447\n",
      "Epoch 1475 Batch    6/6   train_loss = 0.191   time_elapsed = 3331.808   time_remaining = 3445\n",
      "Epoch 1476 Batch    6/6   train_loss = 0.172   time_elapsed = 3333.968   time_remaining = 3442\n",
      "Epoch 1477 Batch    6/6   train_loss = 0.181   time_elapsed = 3336.123   time_remaining = 3440\n",
      "Epoch 1478 Batch    6/6   train_loss = 0.189   time_elapsed = 3338.276   time_remaining = 3438\n",
      "Epoch 1479 Batch    6/6   train_loss = 0.183   time_elapsed = 3340.425   time_remaining = 3435\n",
      "Epoch 1480 Batch    6/6   train_loss = 0.181   time_elapsed = 3342.585   time_remaining = 3433\n",
      "Epoch 1481 Batch    6/6   train_loss = 0.188   time_elapsed = 3344.740   time_remaining = 3431\n",
      "Model Trained and Saved\n",
      "Epoch 1482 Batch    6/6   train_loss = 0.175   time_elapsed = 3347.673   time_remaining = 3429\n",
      "Epoch 1483 Batch    6/6   train_loss = 0.181   time_elapsed = 3349.835   time_remaining = 3427\n",
      "Epoch 1484 Batch    6/6   train_loss = 0.176   time_elapsed = 3351.982   time_remaining = 3424\n",
      "Epoch 1485 Batch    6/6   train_loss = 0.179   time_elapsed = 3354.147   time_remaining = 3422\n",
      "Epoch 1486 Batch    6/6   train_loss = 0.181   time_elapsed = 3356.297   time_remaining = 3420\n",
      "Epoch 1487 Batch    6/6   train_loss = 0.177   time_elapsed = 3358.457   time_remaining = 3417\n",
      "Epoch 1488 Batch    6/6   train_loss = 0.177   time_elapsed = 3360.617   time_remaining = 3415\n",
      "Epoch 1489 Batch    6/6   train_loss = 0.178   time_elapsed = 3362.774   time_remaining = 3412\n",
      "Epoch 1490 Batch    6/6   train_loss = 0.173   time_elapsed = 3364.939   time_remaining = 3410\n",
      "Epoch 1491 Batch    6/6   train_loss = 0.168   time_elapsed = 3367.090   time_remaining = 3408\n",
      "Model Trained and Saved\n",
      "Epoch 1492 Batch    6/6   train_loss = 0.174   time_elapsed = 3370.021   time_remaining = 3406\n",
      "Epoch 1493 Batch    6/6   train_loss = 0.172   time_elapsed = 3372.178   time_remaining = 3404\n",
      "Epoch 1494 Batch    6/6   train_loss = 0.172   time_elapsed = 3374.339   time_remaining = 3401\n",
      "Epoch 1495 Batch    6/6   train_loss = 0.173   time_elapsed = 3376.489   time_remaining = 3399\n",
      "Epoch 1496 Batch    6/6   train_loss = 0.170   time_elapsed = 3378.647   time_remaining = 3397\n",
      "Epoch 1497 Batch    6/6   train_loss = 0.168   time_elapsed = 3380.804   time_remaining = 3394\n",
      "Epoch 1498 Batch    6/6   train_loss = 0.186   time_elapsed = 3382.969   time_remaining = 3392\n",
      "Epoch 1499 Batch    6/6   train_loss = 0.179   time_elapsed = 3385.131   time_remaining = 3390\n",
      "Epoch 1500 Batch    6/6   train_loss = 0.163   time_elapsed = 3387.286   time_remaining = 3387\n",
      "Epoch 1501 Batch    6/6   train_loss = 0.172   time_elapsed = 3389.445   time_remaining = 3385\n",
      "Model Trained and Saved\n",
      "Epoch 1502 Batch    6/6   train_loss = 0.182   time_elapsed = 3392.395   time_remaining = 3383\n",
      "Epoch 1503 Batch    6/6   train_loss = 0.175   time_elapsed = 3394.555   time_remaining = 3381\n",
      "Epoch 1504 Batch    6/6   train_loss = 0.179   time_elapsed = 3396.718   time_remaining = 3379\n",
      "Epoch 1505 Batch    6/6   train_loss = 0.179   time_elapsed = 3398.871   time_remaining = 3376\n",
      "Epoch 1506 Batch    6/6   train_loss = 0.175   time_elapsed = 3401.023   time_remaining = 3374\n",
      "Epoch 1507 Batch    6/6   train_loss = 0.174   time_elapsed = 3403.176   time_remaining = 3372\n",
      "Epoch 1508 Batch    6/6   train_loss = 0.179   time_elapsed = 3405.324   time_remaining = 3369\n",
      "Epoch 1509 Batch    6/6   train_loss = 0.172   time_elapsed = 3407.479   time_remaining = 3367\n",
      "Epoch 1510 Batch    6/6   train_loss = 0.172   time_elapsed = 3409.633   time_remaining = 3364\n",
      "Epoch 1511 Batch    6/6   train_loss = 0.168   time_elapsed = 3411.785   time_remaining = 3362\n",
      "Model Trained and Saved\n",
      "Epoch 1512 Batch    6/6   train_loss = 0.175   time_elapsed = 3414.736   time_remaining = 3361\n",
      "Epoch 1513 Batch    6/6   train_loss = 0.175   time_elapsed = 3416.892   time_remaining = 3358\n",
      "Epoch 1514 Batch    6/6   train_loss = 0.172   time_elapsed = 3419.046   time_remaining = 3356\n",
      "Epoch 1515 Batch    6/6   train_loss = 0.166   time_elapsed = 3421.206   time_remaining = 3353\n",
      "Epoch 1516 Batch    6/6   train_loss = 0.170   time_elapsed = 3423.372   time_remaining = 3351\n",
      "Epoch 1517 Batch    6/6   train_loss = 0.164   time_elapsed = 3425.539   time_remaining = 3349\n",
      "Epoch 1518 Batch    6/6   train_loss = 0.175   time_elapsed = 3427.694   time_remaining = 3346\n",
      "Epoch 1519 Batch    6/6   train_loss = 0.166   time_elapsed = 3429.851   time_remaining = 3344\n",
      "Epoch 1520 Batch    6/6   train_loss = 0.174   time_elapsed = 3432.008   time_remaining = 3342\n",
      "Epoch 1521 Batch    6/6   train_loss = 0.170   time_elapsed = 3434.170   time_remaining = 3339\n",
      "Model Trained and Saved\n",
      "Epoch 1522 Batch    6/6   train_loss = 0.159   time_elapsed = 3437.120   time_remaining = 3338\n",
      "Epoch 1523 Batch    6/6   train_loss = 0.165   time_elapsed = 3439.277   time_remaining = 3335\n",
      "Epoch 1524 Batch    6/6   train_loss = 0.166   time_elapsed = 3441.435   time_remaining = 3333\n",
      "Epoch 1525 Batch    6/6   train_loss = 0.166   time_elapsed = 3443.589   time_remaining = 3331\n",
      "Epoch 1526 Batch    6/6   train_loss = 0.162   time_elapsed = 3445.740   time_remaining = 3328\n",
      "Epoch 1527 Batch    6/6   train_loss = 0.171   time_elapsed = 3447.896   time_remaining = 3326\n",
      "Epoch 1528 Batch    6/6   train_loss = 0.159   time_elapsed = 3450.054   time_remaining = 3324\n",
      "Epoch 1529 Batch    6/6   train_loss = 0.167   time_elapsed = 3452.211   time_remaining = 3321\n",
      "Epoch 1530 Batch    6/6   train_loss = 0.164   time_elapsed = 3454.369   time_remaining = 3319\n",
      "Epoch 1531 Batch    6/6   train_loss = 0.174   time_elapsed = 3456.529   time_remaining = 3317\n",
      "Model Trained and Saved\n",
      "Epoch 1532 Batch    6/6   train_loss = 0.167   time_elapsed = 3459.476   time_remaining = 3315\n",
      "Epoch 1533 Batch    6/6   train_loss = 0.163   time_elapsed = 3461.632   time_remaining = 3313\n",
      "Epoch 1534 Batch    6/6   train_loss = 0.167   time_elapsed = 3463.784   time_remaining = 3310\n",
      "Epoch 1535 Batch    6/6   train_loss = 0.161   time_elapsed = 3465.936   time_remaining = 3308\n",
      "Epoch 1536 Batch    6/6   train_loss = 0.166   time_elapsed = 3468.082   time_remaining = 3306\n",
      "Epoch 1537 Batch    6/6   train_loss = 0.163   time_elapsed = 3470.245   time_remaining = 3303\n",
      "Epoch 1538 Batch    6/6   train_loss = 0.163   time_elapsed = 3472.394   time_remaining = 3301\n",
      "Epoch 1539 Batch    6/6   train_loss = 0.164   time_elapsed = 3474.558   time_remaining = 3298\n",
      "Epoch 1540 Batch    6/6   train_loss = 0.159   time_elapsed = 3476.712   time_remaining = 3296\n",
      "Epoch 1541 Batch    6/6   train_loss = 0.168   time_elapsed = 3478.869   time_remaining = 3294\n",
      "Model Trained and Saved\n",
      "Epoch 1542 Batch    6/6   train_loss = 0.156   time_elapsed = 3481.820   time_remaining = 3292\n",
      "Epoch 1543 Batch    6/6   train_loss = 0.154   time_elapsed = 3483.973   time_remaining = 3290\n",
      "Epoch 1544 Batch    6/6   train_loss = 0.161   time_elapsed = 3486.116   time_remaining = 3287\n",
      "Epoch 1545 Batch    6/6   train_loss = 0.156   time_elapsed = 3488.273   time_remaining = 3285\n",
      "Epoch 1546 Batch    6/6   train_loss = 0.160   time_elapsed = 3490.432   time_remaining = 3283\n",
      "Epoch 1547 Batch    6/6   train_loss = 0.173   time_elapsed = 3492.583   time_remaining = 3280\n",
      "Epoch 1548 Batch    6/6   train_loss = 0.156   time_elapsed = 3494.749   time_remaining = 3278\n",
      "Epoch 1549 Batch    6/6   train_loss = 0.158   time_elapsed = 3496.907   time_remaining = 3276\n",
      "Epoch 1550 Batch    6/6   train_loss = 0.160   time_elapsed = 3499.061   time_remaining = 3273\n",
      "Epoch 1551 Batch    6/6   train_loss = 0.166   time_elapsed = 3501.211   time_remaining = 3271\n",
      "Model Trained and Saved\n",
      "Epoch 1552 Batch    6/6   train_loss = 0.166   time_elapsed = 3504.169   time_remaining = 3269\n",
      "Epoch 1553 Batch    6/6   train_loss = 0.168   time_elapsed = 3506.318   time_remaining = 3267\n",
      "Epoch 1554 Batch    6/6   train_loss = 0.166   time_elapsed = 3508.469   time_remaining = 3265\n",
      "Epoch 1555 Batch    6/6   train_loss = 0.158   time_elapsed = 3510.626   time_remaining = 3262\n",
      "Epoch 1556 Batch    6/6   train_loss = 0.165   time_elapsed = 3512.773   time_remaining = 3260\n",
      "Epoch 1557 Batch    6/6   train_loss = 0.162   time_elapsed = 3514.933   time_remaining = 3258\n",
      "Epoch 1558 Batch    6/6   train_loss = 0.159   time_elapsed = 3517.092   time_remaining = 3255\n",
      "Epoch 1559 Batch    6/6   train_loss = 0.161   time_elapsed = 3519.247   time_remaining = 3253\n",
      "Epoch 1560 Batch    6/6   train_loss = 0.162   time_elapsed = 3521.395   time_remaining = 3251\n",
      "Epoch 1561 Batch    6/6   train_loss = 0.164   time_elapsed = 3523.544   time_remaining = 3248\n",
      "Model Trained and Saved\n",
      "Epoch 1562 Batch    6/6   train_loss = 0.169   time_elapsed = 3526.511   time_remaining = 3247\n",
      "Epoch 1563 Batch    6/6   train_loss = 0.162   time_elapsed = 3528.668   time_remaining = 3244\n",
      "Epoch 1564 Batch    6/6   train_loss = 0.159   time_elapsed = 3530.820   time_remaining = 3242\n",
      "Epoch 1565 Batch    6/6   train_loss = 0.163   time_elapsed = 3532.973   time_remaining = 3239\n",
      "Epoch 1566 Batch    6/6   train_loss = 0.160   time_elapsed = 3535.128   time_remaining = 3237\n",
      "Epoch 1567 Batch    6/6   train_loss = 0.155   time_elapsed = 3537.286   time_remaining = 3235\n",
      "Epoch 1568 Batch    6/6   train_loss = 0.162   time_elapsed = 3539.435   time_remaining = 3232\n",
      "Epoch 1569 Batch    6/6   train_loss = 0.165   time_elapsed = 3541.597   time_remaining = 3230\n",
      "Epoch 1570 Batch    6/6   train_loss = 0.161   time_elapsed = 3543.755   time_remaining = 3228\n",
      "Epoch 1571 Batch    6/6   train_loss = 0.156   time_elapsed = 3545.910   time_remaining = 3225\n",
      "Model Trained and Saved\n",
      "Epoch 1572 Batch    6/6   train_loss = 0.155   time_elapsed = 3548.855   time_remaining = 3224\n",
      "Epoch 1573 Batch    6/6   train_loss = 0.163   time_elapsed = 3551.009   time_remaining = 3221\n",
      "Epoch 1574 Batch    6/6   train_loss = 0.156   time_elapsed = 3553.164   time_remaining = 3219\n",
      "Epoch 1575 Batch    6/6   train_loss = 0.158   time_elapsed = 3555.326   time_remaining = 3217\n",
      "Epoch 1576 Batch    6/6   train_loss = 0.159   time_elapsed = 3557.481   time_remaining = 3214\n",
      "Epoch 1577 Batch    6/6   train_loss = 0.168   time_elapsed = 3559.638   time_remaining = 3212\n",
      "Epoch 1578 Batch    6/6   train_loss = 0.148   time_elapsed = 3561.780   time_remaining = 3210\n",
      "Epoch 1579 Batch    6/6   train_loss = 0.157   time_elapsed = 3563.943   time_remaining = 3207\n",
      "Epoch 1580 Batch    6/6   train_loss = 0.156   time_elapsed = 3566.089   time_remaining = 3205\n",
      "Epoch 1581 Batch    6/6   train_loss = 0.161   time_elapsed = 3568.250   time_remaining = 3203\n",
      "Model Trained and Saved\n",
      "Epoch 1582 Batch    6/6   train_loss = 0.163   time_elapsed = 3571.212   time_remaining = 3201\n",
      "Epoch 1583 Batch    6/6   train_loss = 0.158   time_elapsed = 3573.368   time_remaining = 3199\n",
      "Epoch 1584 Batch    6/6   train_loss = 0.155   time_elapsed = 3575.517   time_remaining = 3196\n",
      "Epoch 1585 Batch    6/6   train_loss = 0.164   time_elapsed = 3577.671   time_remaining = 3194\n",
      "Epoch 1586 Batch    6/6   train_loss = 0.159   time_elapsed = 3579.820   time_remaining = 3192\n",
      "Epoch 1587 Batch    6/6   train_loss = 0.160   time_elapsed = 3581.976   time_remaining = 3189\n",
      "Epoch 1588 Batch    6/6   train_loss = 0.153   time_elapsed = 3584.135   time_remaining = 3187\n",
      "Epoch 1589 Batch    6/6   train_loss = 0.153   time_elapsed = 3586.292   time_remaining = 3185\n",
      "Epoch 1590 Batch    6/6   train_loss = 0.160   time_elapsed = 3588.445   time_remaining = 3182\n",
      "Epoch 1591 Batch    6/6   train_loss = 0.153   time_elapsed = 3590.607   time_remaining = 3180\n",
      "Model Trained and Saved\n",
      "Epoch 1592 Batch    6/6   train_loss = 0.156   time_elapsed = 3593.573   time_remaining = 3178\n",
      "Epoch 1593 Batch    6/6   train_loss = 0.151   time_elapsed = 3595.724   time_remaining = 3176\n",
      "Epoch 1594 Batch    6/6   train_loss = 0.153   time_elapsed = 3597.878   time_remaining = 3174\n",
      "Epoch 1595 Batch    6/6   train_loss = 0.165   time_elapsed = 3600.029   time_remaining = 3171\n",
      "Epoch 1596 Batch    6/6   train_loss = 0.162   time_elapsed = 3602.190   time_remaining = 3169\n",
      "Epoch 1597 Batch    6/6   train_loss = 0.158   time_elapsed = 3604.351   time_remaining = 3167\n",
      "Epoch 1598 Batch    6/6   train_loss = 0.154   time_elapsed = 3606.501   time_remaining = 3164\n",
      "Epoch 1599 Batch    6/6   train_loss = 0.161   time_elapsed = 3608.656   time_remaining = 3162\n",
      "Epoch 1600 Batch    6/6   train_loss = 0.151   time_elapsed = 3610.805   time_remaining = 3159\n",
      "Epoch 1601 Batch    6/6   train_loss = 0.159   time_elapsed = 3612.957   time_remaining = 3157\n",
      "Model Trained and Saved\n",
      "Epoch 1602 Batch    6/6   train_loss = 0.155   time_elapsed = 3615.915   time_remaining = 3155\n",
      "Epoch 1603 Batch    6/6   train_loss = 0.158   time_elapsed = 3618.065   time_remaining = 3153\n",
      "Epoch 1604 Batch    6/6   train_loss = 0.155   time_elapsed = 3620.218   time_remaining = 3151\n",
      "Epoch 1605 Batch    6/6   train_loss = 0.154   time_elapsed = 3622.374   time_remaining = 3148\n",
      "Epoch 1606 Batch    6/6   train_loss = 0.153   time_elapsed = 3624.528   time_remaining = 3146\n",
      "Epoch 1607 Batch    6/6   train_loss = 0.155   time_elapsed = 3626.680   time_remaining = 3144\n",
      "Epoch 1608 Batch    6/6   train_loss = 0.151   time_elapsed = 3628.839   time_remaining = 3141\n",
      "Epoch 1609 Batch    6/6   train_loss = 0.156   time_elapsed = 3630.996   time_remaining = 3139\n",
      "Epoch 1610 Batch    6/6   train_loss = 0.147   time_elapsed = 3633.150   time_remaining = 3137\n",
      "Epoch 1611 Batch    6/6   train_loss = 0.154   time_elapsed = 3635.307   time_remaining = 3134\n",
      "Model Trained and Saved\n",
      "Epoch 1612 Batch    6/6   train_loss = 0.159   time_elapsed = 3638.451   time_remaining = 3133\n",
      "Epoch 1613 Batch    6/6   train_loss = 0.153   time_elapsed = 3640.608   time_remaining = 3131\n",
      "Epoch 1614 Batch    6/6   train_loss = 0.161   time_elapsed = 3642.763   time_remaining = 3128\n",
      "Epoch 1615 Batch    6/6   train_loss = 0.155   time_elapsed = 3644.921   time_remaining = 3126\n",
      "Epoch 1616 Batch    6/6   train_loss = 0.158   time_elapsed = 3647.068   time_remaining = 3123\n",
      "Epoch 1617 Batch    6/6   train_loss = 0.151   time_elapsed = 3649.222   time_remaining = 3121\n",
      "Epoch 1618 Batch    6/6   train_loss = 0.151   time_elapsed = 3651.380   time_remaining = 3119\n",
      "Epoch 1619 Batch    6/6   train_loss = 0.154   time_elapsed = 3653.535   time_remaining = 3116\n",
      "Epoch 1620 Batch    6/6   train_loss = 0.147   time_elapsed = 3655.684   time_remaining = 3114\n",
      "Epoch 1621 Batch    6/6   train_loss = 0.149   time_elapsed = 3657.837   time_remaining = 3112\n",
      "Model Trained and Saved\n",
      "Epoch 1622 Batch    6/6   train_loss = 0.150   time_elapsed = 3660.818   time_remaining = 3110\n",
      "Epoch 1623 Batch    6/6   train_loss = 0.151   time_elapsed = 3662.970   time_remaining = 3108\n",
      "Epoch 1624 Batch    6/6   train_loss = 0.155   time_elapsed = 3665.120   time_remaining = 3105\n",
      "Epoch 1625 Batch    6/6   train_loss = 0.156   time_elapsed = 3667.269   time_remaining = 3103\n",
      "Epoch 1626 Batch    6/6   train_loss = 0.159   time_elapsed = 3669.417   time_remaining = 3101\n",
      "Epoch 1627 Batch    6/6   train_loss = 0.157   time_elapsed = 3671.571   time_remaining = 3098\n",
      "Epoch 1628 Batch    6/6   train_loss = 0.151   time_elapsed = 3673.726   time_remaining = 3096\n",
      "Epoch 1629 Batch    6/6   train_loss = 0.149   time_elapsed = 3675.886   time_remaining = 3094\n",
      "Epoch 1630 Batch    6/6   train_loss = 0.149   time_elapsed = 3678.038   time_remaining = 3091\n",
      "Epoch 1631 Batch    6/6   train_loss = 0.155   time_elapsed = 3680.199   time_remaining = 3089\n",
      "Model Trained and Saved\n",
      "Epoch 1632 Batch    6/6   train_loss = 0.150   time_elapsed = 3683.193   time_remaining = 3087\n",
      "Epoch 1633 Batch    6/6   train_loss = 0.153   time_elapsed = 3685.349   time_remaining = 3085\n",
      "Epoch 1634 Batch    6/6   train_loss = 0.154   time_elapsed = 3687.502   time_remaining = 3083\n",
      "Epoch 1635 Batch    6/6   train_loss = 0.150   time_elapsed = 3689.658   time_remaining = 3080\n",
      "Epoch 1636 Batch    6/6   train_loss = 0.155   time_elapsed = 3691.812   time_remaining = 3078\n",
      "Epoch 1637 Batch    6/6   train_loss = 0.147   time_elapsed = 3693.971   time_remaining = 3076\n",
      "Epoch 1638 Batch    6/6   train_loss = 0.154   time_elapsed = 3696.123   time_remaining = 3073\n",
      "Epoch 1639 Batch    6/6   train_loss = 0.151   time_elapsed = 3698.275   time_remaining = 3071\n",
      "Epoch 1640 Batch    6/6   train_loss = 0.153   time_elapsed = 3700.430   time_remaining = 3069\n",
      "Epoch 1641 Batch    6/6   train_loss = 0.148   time_elapsed = 3702.586   time_remaining = 3066\n",
      "Model Trained and Saved\n",
      "Epoch 1642 Batch    6/6   train_loss = 0.158   time_elapsed = 3705.940   time_remaining = 3065\n",
      "Epoch 1643 Batch    6/6   train_loss = 0.148   time_elapsed = 3708.097   time_remaining = 3063\n",
      "Epoch 1644 Batch    6/6   train_loss = 0.162   time_elapsed = 3710.249   time_remaining = 3060\n",
      "Epoch 1645 Batch    6/6   train_loss = 0.144   time_elapsed = 3712.403   time_remaining = 3058\n",
      "Epoch 1646 Batch    6/6   train_loss = 0.149   time_elapsed = 3714.557   time_remaining = 3056\n",
      "Epoch 1647 Batch    6/6   train_loss = 0.148   time_elapsed = 3716.704   time_remaining = 3053\n",
      "Epoch 1648 Batch    6/6   train_loss = 0.149   time_elapsed = 3718.856   time_remaining = 3051\n",
      "Epoch 1649 Batch    6/6   train_loss = 0.151   time_elapsed = 3721.016   time_remaining = 3049\n",
      "Epoch 1650 Batch    6/6   train_loss = 0.150   time_elapsed = 3723.171   time_remaining = 3046\n",
      "Epoch 1651 Batch    6/6   train_loss = 0.143   time_elapsed = 3725.332   time_remaining = 3044\n",
      "Model Trained and Saved\n",
      "Epoch 1652 Batch    6/6   train_loss = 0.147   time_elapsed = 3728.330   time_remaining = 3042\n",
      "Epoch 1653 Batch    6/6   train_loss = 0.148   time_elapsed = 3730.483   time_remaining = 3040\n",
      "Epoch 1654 Batch    6/6   train_loss = 0.152   time_elapsed = 3732.638   time_remaining = 3038\n",
      "Epoch 1655 Batch    6/6   train_loss = 0.149   time_elapsed = 3734.792   time_remaining = 3035\n",
      "Epoch 1656 Batch    6/6   train_loss = 0.145   time_elapsed = 3736.951   time_remaining = 3033\n",
      "Epoch 1657 Batch    6/6   train_loss = 0.143   time_elapsed = 3739.110   time_remaining = 3031\n",
      "Epoch 1658 Batch    6/6   train_loss = 0.148   time_elapsed = 3741.263   time_remaining = 3028\n",
      "Epoch 1659 Batch    6/6   train_loss = 0.144   time_elapsed = 3743.416   time_remaining = 3026\n",
      "Epoch 1660 Batch    6/6   train_loss = 0.153   time_elapsed = 3745.573   time_remaining = 3024\n",
      "Epoch 1661 Batch    6/6   train_loss = 0.145   time_elapsed = 3747.733   time_remaining = 3021\n",
      "Model Trained and Saved\n",
      "Epoch 1662 Batch    6/6   train_loss = 0.150   time_elapsed = 3750.841   time_remaining = 3020\n",
      "Epoch 1663 Batch    6/6   train_loss = 0.146   time_elapsed = 3752.996   time_remaining = 3017\n",
      "Epoch 1664 Batch    6/6   train_loss = 0.153   time_elapsed = 3755.161   time_remaining = 3015\n",
      "Epoch 1665 Batch    6/6   train_loss = 0.150   time_elapsed = 3757.321   time_remaining = 3013\n",
      "Epoch 1666 Batch    6/6   train_loss = 0.144   time_elapsed = 3759.469   time_remaining = 3010\n",
      "Epoch 1667 Batch    6/6   train_loss = 0.143   time_elapsed = 3761.625   time_remaining = 3008\n",
      "Epoch 1668 Batch    6/6   train_loss = 0.141   time_elapsed = 3763.788   time_remaining = 3006\n",
      "Epoch 1669 Batch    6/6   train_loss = 0.147   time_elapsed = 3765.961   time_remaining = 3003\n",
      "Epoch 1670 Batch    6/6   train_loss = 0.148   time_elapsed = 3768.125   time_remaining = 3001\n",
      "Epoch 1671 Batch    6/6   train_loss = 0.153   time_elapsed = 3770.295   time_remaining = 2999\n",
      "Model Trained and Saved\n",
      "Epoch 1672 Batch    6/6   train_loss = 0.150   time_elapsed = 3773.325   time_remaining = 2997\n",
      "Epoch 1673 Batch    6/6   train_loss = 0.146   time_elapsed = 3775.491   time_remaining = 2995\n",
      "Epoch 1674 Batch    6/6   train_loss = 0.141   time_elapsed = 3777.659   time_remaining = 2992\n",
      "Epoch 1675 Batch    6/6   train_loss = 0.140   time_elapsed = 3779.824   time_remaining = 2990\n",
      "Epoch 1676 Batch    6/6   train_loss = 0.142   time_elapsed = 3781.991   time_remaining = 2988\n",
      "Epoch 1677 Batch    6/6   train_loss = 0.151   time_elapsed = 3784.160   time_remaining = 2985\n",
      "Epoch 1678 Batch    6/6   train_loss = 0.150   time_elapsed = 3786.319   time_remaining = 2983\n",
      "Epoch 1679 Batch    6/6   train_loss = 0.145   time_elapsed = 3788.482   time_remaining = 2981\n",
      "Epoch 1680 Batch    6/6   train_loss = 0.148   time_elapsed = 3790.650   time_remaining = 2978\n",
      "Epoch 1681 Batch    6/6   train_loss = 0.136   time_elapsed = 3792.811   time_remaining = 2976\n",
      "Model Trained and Saved\n",
      "Epoch 1682 Batch    6/6   train_loss = 0.141   time_elapsed = 3795.841   time_remaining = 2974\n",
      "Epoch 1683 Batch    6/6   train_loss = 0.146   time_elapsed = 3798.012   time_remaining = 2972\n",
      "Epoch 1684 Batch    6/6   train_loss = 0.155   time_elapsed = 3800.176   time_remaining = 2970\n",
      "Epoch 1685 Batch    6/6   train_loss = 0.144   time_elapsed = 3802.347   time_remaining = 2967\n",
      "Epoch 1686 Batch    6/6   train_loss = 0.150   time_elapsed = 3804.515   time_remaining = 2965\n",
      "Epoch 1687 Batch    6/6   train_loss = 0.145   time_elapsed = 3806.683   time_remaining = 2963\n",
      "Epoch 1688 Batch    6/6   train_loss = 0.145   time_elapsed = 3808.857   time_remaining = 2960\n",
      "Epoch 1689 Batch    6/6   train_loss = 0.151   time_elapsed = 3811.024   time_remaining = 2958\n",
      "Epoch 1690 Batch    6/6   train_loss = 0.140   time_elapsed = 3813.198   time_remaining = 2956\n",
      "Epoch 1691 Batch    6/6   train_loss = 0.144   time_elapsed = 3815.360   time_remaining = 2953\n",
      "Model Trained and Saved\n",
      "Epoch 1692 Batch    6/6   train_loss = 0.147   time_elapsed = 3818.369   time_remaining = 2952\n",
      "Epoch 1693 Batch    6/6   train_loss = 0.140   time_elapsed = 3820.545   time_remaining = 2949\n",
      "Epoch 1694 Batch    6/6   train_loss = 0.136   time_elapsed = 3822.712   time_remaining = 2947\n",
      "Epoch 1695 Batch    6/6   train_loss = 0.137   time_elapsed = 3824.874   time_remaining = 2945\n",
      "Epoch 1696 Batch    6/6   train_loss = 0.142   time_elapsed = 3827.038   time_remaining = 2942\n",
      "Epoch 1697 Batch    6/6   train_loss = 0.143   time_elapsed = 3829.206   time_remaining = 2940\n",
      "Epoch 1698 Batch    6/6   train_loss = 0.148   time_elapsed = 3831.379   time_remaining = 2938\n",
      "Epoch 1699 Batch    6/6   train_loss = 0.140   time_elapsed = 3833.543   time_remaining = 2936\n",
      "Epoch 1700 Batch    6/6   train_loss = 0.141   time_elapsed = 3835.709   time_remaining = 2933\n",
      "Epoch 1701 Batch    6/6   train_loss = 0.144   time_elapsed = 3837.877   time_remaining = 2931\n",
      "Model Trained and Saved\n",
      "Epoch 1702 Batch    6/6   train_loss = 0.149   time_elapsed = 3840.887   time_remaining = 2929\n",
      "Epoch 1703 Batch    6/6   train_loss = 0.148   time_elapsed = 3843.056   time_remaining = 2927\n",
      "Epoch 1704 Batch    6/6   train_loss = 0.140   time_elapsed = 3845.226   time_remaining = 2925\n",
      "Epoch 1705 Batch    6/6   train_loss = 0.132   time_elapsed = 3847.388   time_remaining = 2922\n",
      "Epoch 1706 Batch    6/6   train_loss = 0.140   time_elapsed = 3849.555   time_remaining = 2920\n",
      "Epoch 1707 Batch    6/6   train_loss = 0.145   time_elapsed = 3851.729   time_remaining = 2918\n",
      "Epoch 1708 Batch    6/6   train_loss = 0.144   time_elapsed = 3853.898   time_remaining = 2915\n",
      "Epoch 1709 Batch    6/6   train_loss = 0.144   time_elapsed = 3856.069   time_remaining = 2913\n",
      "Epoch 1710 Batch    6/6   train_loss = 0.128   time_elapsed = 3858.235   time_remaining = 2911\n",
      "Epoch 1711 Batch    6/6   train_loss = 0.141   time_elapsed = 3860.413   time_remaining = 2908\n",
      "Model Trained and Saved\n",
      "Epoch 1712 Batch    6/6   train_loss = 0.135   time_elapsed = 3863.428   time_remaining = 2907\n",
      "Epoch 1713 Batch    6/6   train_loss = 0.142   time_elapsed = 3865.590   time_remaining = 2904\n",
      "Epoch 1714 Batch    6/6   train_loss = 0.144   time_elapsed = 3867.758   time_remaining = 2902\n",
      "Epoch 1715 Batch    6/6   train_loss = 0.139   time_elapsed = 3869.922   time_remaining = 2900\n",
      "Epoch 1716 Batch    6/6   train_loss = 0.149   time_elapsed = 3872.089   time_remaining = 2897\n",
      "Epoch 1717 Batch    6/6   train_loss = 0.149   time_elapsed = 3874.258   time_remaining = 2895\n",
      "Epoch 1718 Batch    6/6   train_loss = 0.143   time_elapsed = 3876.418   time_remaining = 2893\n",
      "Epoch 1719 Batch    6/6   train_loss = 0.149   time_elapsed = 3878.586   time_remaining = 2890\n",
      "Epoch 1720 Batch    6/6   train_loss = 0.138   time_elapsed = 3880.741   time_remaining = 2888\n",
      "Epoch 1721 Batch    6/6   train_loss = 0.144   time_elapsed = 3882.904   time_remaining = 2886\n",
      "Model Trained and Saved\n",
      "Epoch 1722 Batch    6/6   train_loss = 0.148   time_elapsed = 3885.901   time_remaining = 2884\n",
      "Epoch 1723 Batch    6/6   train_loss = 0.139   time_elapsed = 3888.065   time_remaining = 2882\n",
      "Epoch 1724 Batch    6/6   train_loss = 0.137   time_elapsed = 3890.230   time_remaining = 2879\n",
      "Epoch 1725 Batch    6/6   train_loss = 0.143   time_elapsed = 3892.393   time_remaining = 2877\n",
      "Epoch 1726 Batch    6/6   train_loss = 0.140   time_elapsed = 3894.562   time_remaining = 2875\n",
      "Epoch 1727 Batch    6/6   train_loss = 0.139   time_elapsed = 3896.722   time_remaining = 2872\n",
      "Epoch 1728 Batch    6/6   train_loss = 0.138   time_elapsed = 3898.889   time_remaining = 2870\n",
      "Epoch 1729 Batch    6/6   train_loss = 0.131   time_elapsed = 3901.049   time_remaining = 2868\n",
      "Epoch 1730 Batch    6/6   train_loss = 0.145   time_elapsed = 3903.213   time_remaining = 2865\n",
      "Epoch 1731 Batch    6/6   train_loss = 0.144   time_elapsed = 3905.377   time_remaining = 2863\n",
      "Model Trained and Saved\n",
      "Epoch 1732 Batch    6/6   train_loss = 0.144   time_elapsed = 3908.419   time_remaining = 2861\n",
      "Epoch 1733 Batch    6/6   train_loss = 0.139   time_elapsed = 3910.581   time_remaining = 2859\n",
      "Epoch 1734 Batch    6/6   train_loss = 0.141   time_elapsed = 3912.744   time_remaining = 2857\n",
      "Epoch 1735 Batch    6/6   train_loss = 0.138   time_elapsed = 3914.904   time_remaining = 2854\n",
      "Epoch 1736 Batch    6/6   train_loss = 0.142   time_elapsed = 3917.060   time_remaining = 2852\n",
      "Epoch 1737 Batch    6/6   train_loss = 0.138   time_elapsed = 3919.227   time_remaining = 2850\n",
      "Epoch 1738 Batch    6/6   train_loss = 0.133   time_elapsed = 3921.391   time_remaining = 2847\n",
      "Epoch 1739 Batch    6/6   train_loss = 0.142   time_elapsed = 3923.559   time_remaining = 2845\n",
      "Epoch 1740 Batch    6/6   train_loss = 0.149   time_elapsed = 3925.723   time_remaining = 2843\n",
      "Epoch 1741 Batch    6/6   train_loss = 0.134   time_elapsed = 3927.891   time_remaining = 2840\n",
      "Model Trained and Saved\n",
      "Epoch 1742 Batch    6/6   train_loss = 0.138   time_elapsed = 3930.919   time_remaining = 2839\n",
      "Epoch 1743 Batch    6/6   train_loss = 0.137   time_elapsed = 3933.083   time_remaining = 2836\n",
      "Epoch 1744 Batch    6/6   train_loss = 0.144   time_elapsed = 3935.250   time_remaining = 2834\n",
      "Epoch 1745 Batch    6/6   train_loss = 0.142   time_elapsed = 3937.413   time_remaining = 2832\n",
      "Epoch 1746 Batch    6/6   train_loss = 0.139   time_elapsed = 3939.587   time_remaining = 2829\n",
      "Epoch 1747 Batch    6/6   train_loss = 0.138   time_elapsed = 3941.754   time_remaining = 2827\n",
      "Epoch 1748 Batch    6/6   train_loss = 0.140   time_elapsed = 3943.920   time_remaining = 2825\n",
      "Epoch 1749 Batch    6/6   train_loss = 0.136   time_elapsed = 3946.087   time_remaining = 2823\n",
      "Epoch 1750 Batch    6/6   train_loss = 0.136   time_elapsed = 3948.262   time_remaining = 2820\n",
      "Epoch 1751 Batch    6/6   train_loss = 0.140   time_elapsed = 3950.429   time_remaining = 2818\n",
      "Model Trained and Saved\n",
      "Epoch 1752 Batch    6/6   train_loss = 0.132   time_elapsed = 3953.479   time_remaining = 2816\n",
      "Epoch 1753 Batch    6/6   train_loss = 0.140   time_elapsed = 3955.652   time_remaining = 2814\n",
      "Epoch 1754 Batch    6/6   train_loss = 0.140   time_elapsed = 3957.822   time_remaining = 2812\n",
      "Epoch 1755 Batch    6/6   train_loss = 0.136   time_elapsed = 3959.992   time_remaining = 2809\n",
      "Epoch 1756 Batch    6/6   train_loss = 0.132   time_elapsed = 3962.163   time_remaining = 2807\n",
      "Epoch 1757 Batch    6/6   train_loss = 0.134   time_elapsed = 3964.329   time_remaining = 2805\n",
      "Epoch 1758 Batch    6/6   train_loss = 0.142   time_elapsed = 3966.491   time_remaining = 2802\n",
      "Epoch 1759 Batch    6/6   train_loss = 0.137   time_elapsed = 3968.657   time_remaining = 2800\n",
      "Epoch 1760 Batch    6/6   train_loss = 0.134   time_elapsed = 3970.818   time_remaining = 2798\n",
      "Epoch 1761 Batch    6/6   train_loss = 0.140   time_elapsed = 3972.991   time_remaining = 2795\n",
      "Model Trained and Saved\n",
      "Epoch 1762 Batch    6/6   train_loss = 0.141   time_elapsed = 3976.022   time_remaining = 2794\n",
      "Epoch 1763 Batch    6/6   train_loss = 0.129   time_elapsed = 3978.196   time_remaining = 2791\n",
      "Epoch 1764 Batch    6/6   train_loss = 0.141   time_elapsed = 3980.357   time_remaining = 2789\n",
      "Epoch 1765 Batch    6/6   train_loss = 0.144   time_elapsed = 3982.522   time_remaining = 2787\n",
      "Epoch 1766 Batch    6/6   train_loss = 0.141   time_elapsed = 3984.690   time_remaining = 2784\n",
      "Epoch 1767 Batch    6/6   train_loss = 0.143   time_elapsed = 3986.862   time_remaining = 2782\n",
      "Epoch 1768 Batch    6/6   train_loss = 0.132   time_elapsed = 3989.024   time_remaining = 2780\n",
      "Epoch 1769 Batch    6/6   train_loss = 0.135   time_elapsed = 3991.197   time_remaining = 2777\n",
      "Epoch 1770 Batch    6/6   train_loss = 0.138   time_elapsed = 3993.360   time_remaining = 2775\n",
      "Epoch 1771 Batch    6/6   train_loss = 0.130   time_elapsed = 3995.535   time_remaining = 2773\n",
      "Model Trained and Saved\n",
      "Epoch 1772 Batch    6/6   train_loss = 0.137   time_elapsed = 3998.561   time_remaining = 2771\n",
      "Epoch 1773 Batch    6/6   train_loss = 0.140   time_elapsed = 4000.730   time_remaining = 2769\n",
      "Epoch 1774 Batch    6/6   train_loss = 0.135   time_elapsed = 4002.900   time_remaining = 2766\n",
      "Epoch 1775 Batch    6/6   train_loss = 0.133   time_elapsed = 4005.065   time_remaining = 2764\n",
      "Epoch 1776 Batch    6/6   train_loss = 0.134   time_elapsed = 4007.236   time_remaining = 2762\n",
      "Epoch 1777 Batch    6/6   train_loss = 0.133   time_elapsed = 4009.405   time_remaining = 2759\n",
      "Epoch 1778 Batch    6/6   train_loss = 0.132   time_elapsed = 4011.577   time_remaining = 2757\n",
      "Epoch 1779 Batch    6/6   train_loss = 0.137   time_elapsed = 4013.741   time_remaining = 2755\n",
      "Epoch 1780 Batch    6/6   train_loss = 0.141   time_elapsed = 4015.921   time_remaining = 2752\n",
      "Epoch 1781 Batch    6/6   train_loss = 0.139   time_elapsed = 4018.092   time_remaining = 2750\n",
      "Model Trained and Saved\n",
      "Epoch 1782 Batch    6/6   train_loss = 0.134   time_elapsed = 4021.127   time_remaining = 2748\n",
      "Epoch 1783 Batch    6/6   train_loss = 0.142   time_elapsed = 4023.297   time_remaining = 2746\n",
      "Epoch 1784 Batch    6/6   train_loss = 0.137   time_elapsed = 4025.466   time_remaining = 2744\n",
      "Epoch 1785 Batch    6/6   train_loss = 0.130   time_elapsed = 4027.639   time_remaining = 2742\n",
      "Epoch 1786 Batch    6/6   train_loss = 0.135   time_elapsed = 4029.814   time_remaining = 2739\n",
      "Epoch 1787 Batch    6/6   train_loss = 0.137   time_elapsed = 4031.981   time_remaining = 2737\n",
      "Epoch 1788 Batch    6/6   train_loss = 0.140   time_elapsed = 4034.149   time_remaining = 2735\n",
      "Epoch 1789 Batch    6/6   train_loss = 0.127   time_elapsed = 4036.321   time_remaining = 2732\n",
      "Epoch 1790 Batch    6/6   train_loss = 0.134   time_elapsed = 4038.488   time_remaining = 2730\n",
      "Epoch 1791 Batch    6/6   train_loss = 0.134   time_elapsed = 4040.654   time_remaining = 2728\n",
      "Model Trained and Saved\n",
      "Epoch 1792 Batch    6/6   train_loss = 0.131   time_elapsed = 4043.691   time_remaining = 2726\n",
      "Epoch 1793 Batch    6/6   train_loss = 0.130   time_elapsed = 4045.861   time_remaining = 2724\n",
      "Epoch 1794 Batch    6/6   train_loss = 0.130   time_elapsed = 4048.022   time_remaining = 2721\n",
      "Epoch 1795 Batch    6/6   train_loss = 0.132   time_elapsed = 4050.191   time_remaining = 2719\n",
      "Epoch 1796 Batch    6/6   train_loss = 0.129   time_elapsed = 4052.354   time_remaining = 2717\n",
      "Epoch 1797 Batch    6/6   train_loss = 0.129   time_elapsed = 4054.526   time_remaining = 2714\n",
      "Epoch 1798 Batch    6/6   train_loss = 0.132   time_elapsed = 4056.695   time_remaining = 2712\n",
      "Epoch 1799 Batch    6/6   train_loss = 0.131   time_elapsed = 4058.863   time_remaining = 2710\n",
      "Epoch 1800 Batch    6/6   train_loss = 0.137   time_elapsed = 4061.027   time_remaining = 2707\n",
      "Epoch 1801 Batch    6/6   train_loss = 0.129   time_elapsed = 4063.195   time_remaining = 2705\n",
      "Model Trained and Saved\n",
      "Epoch 1802 Batch    6/6   train_loss = 0.133   time_elapsed = 4066.237   time_remaining = 2703\n",
      "Epoch 1803 Batch    6/6   train_loss = 0.132   time_elapsed = 4068.400   time_remaining = 2701\n",
      "Epoch 1804 Batch    6/6   train_loss = 0.135   time_elapsed = 4070.570   time_remaining = 2699\n",
      "Epoch 1805 Batch    6/6   train_loss = 0.130   time_elapsed = 4072.729   time_remaining = 2696\n",
      "Epoch 1806 Batch    6/6   train_loss = 0.129   time_elapsed = 4074.900   time_remaining = 2694\n",
      "Epoch 1807 Batch    6/6   train_loss = 0.137   time_elapsed = 4077.067   time_remaining = 2692\n",
      "Epoch 1808 Batch    6/6   train_loss = 0.136   time_elapsed = 4079.235   time_remaining = 2689\n",
      "Epoch 1809 Batch    6/6   train_loss = 0.135   time_elapsed = 4081.400   time_remaining = 2687\n",
      "Epoch 1810 Batch    6/6   train_loss = 0.131   time_elapsed = 4083.569   time_remaining = 2685\n",
      "Epoch 1811 Batch    6/6   train_loss = 0.136   time_elapsed = 4085.736   time_remaining = 2682\n",
      "Model Trained and Saved\n",
      "Epoch 1812 Batch    6/6   train_loss = 0.131   time_elapsed = 4088.809   time_remaining = 2681\n",
      "Epoch 1813 Batch    6/6   train_loss = 0.134   time_elapsed = 4090.973   time_remaining = 2678\n",
      "Epoch 1814 Batch    6/6   train_loss = 0.130   time_elapsed = 4093.134   time_remaining = 2676\n",
      "Epoch 1815 Batch    6/6   train_loss = 0.138   time_elapsed = 4095.306   time_remaining = 2674\n",
      "Epoch 1816 Batch    6/6   train_loss = 0.139   time_elapsed = 4097.477   time_remaining = 2671\n",
      "Epoch 1817 Batch    6/6   train_loss = 0.128   time_elapsed = 4099.647   time_remaining = 2669\n",
      "Epoch 1818 Batch    6/6   train_loss = 0.128   time_elapsed = 4101.809   time_remaining = 2667\n",
      "Epoch 1819 Batch    6/6   train_loss = 0.130   time_elapsed = 4103.977   time_remaining = 2665\n",
      "Epoch 1820 Batch    6/6   train_loss = 0.131   time_elapsed = 4106.143   time_remaining = 2662\n",
      "Epoch 1821 Batch    6/6   train_loss = 0.132   time_elapsed = 4108.311   time_remaining = 2660\n",
      "Model Trained and Saved\n",
      "Epoch 1822 Batch    6/6   train_loss = 0.135   time_elapsed = 4111.539   time_remaining = 2658\n",
      "Epoch 1823 Batch    6/6   train_loss = 0.137   time_elapsed = 4113.699   time_remaining = 2656\n",
      "Epoch 1824 Batch    6/6   train_loss = 0.133   time_elapsed = 4115.874   time_remaining = 2654\n",
      "Epoch 1825 Batch    6/6   train_loss = 0.127   time_elapsed = 4118.038   time_remaining = 2651\n",
      "Epoch 1826 Batch    6/6   train_loss = 0.132   time_elapsed = 4120.212   time_remaining = 2649\n",
      "Epoch 1827 Batch    6/6   train_loss = 0.133   time_elapsed = 4122.371   time_remaining = 2647\n",
      "Epoch 1828 Batch    6/6   train_loss = 0.124   time_elapsed = 4124.535   time_remaining = 2644\n",
      "Epoch 1829 Batch    6/6   train_loss = 0.132   time_elapsed = 4126.703   time_remaining = 2642\n",
      "Epoch 1830 Batch    6/6   train_loss = 0.125   time_elapsed = 4128.869   time_remaining = 2640\n",
      "Epoch 1831 Batch    6/6   train_loss = 0.128   time_elapsed = 4131.042   time_remaining = 2637\n",
      "Model Trained and Saved\n",
      "Epoch 1832 Batch    6/6   train_loss = 0.122   time_elapsed = 4134.199   time_remaining = 2636\n",
      "Epoch 1833 Batch    6/6   train_loss = 0.133   time_elapsed = 4136.361   time_remaining = 2633\n",
      "Epoch 1834 Batch    6/6   train_loss = 0.123   time_elapsed = 4138.523   time_remaining = 2631\n",
      "Epoch 1835 Batch    6/6   train_loss = 0.131   time_elapsed = 4140.690   time_remaining = 2629\n",
      "Epoch 1836 Batch    6/6   train_loss = 0.127   time_elapsed = 4142.853   time_remaining = 2627\n",
      "Epoch 1837 Batch    6/6   train_loss = 0.133   time_elapsed = 4145.019   time_remaining = 2624\n",
      "Epoch 1838 Batch    6/6   train_loss = 0.135   time_elapsed = 4147.189   time_remaining = 2622\n",
      "Epoch 1839 Batch    6/6   train_loss = 0.132   time_elapsed = 4149.360   time_remaining = 2620\n",
      "Epoch 1840 Batch    6/6   train_loss = 0.124   time_elapsed = 4151.537   time_remaining = 2617\n",
      "Epoch 1841 Batch    6/6   train_loss = 0.131   time_elapsed = 4153.701   time_remaining = 2615\n",
      "Model Trained and Saved\n",
      "Epoch 1842 Batch    6/6   train_loss = 0.136   time_elapsed = 4156.779   time_remaining = 2613\n",
      "Epoch 1843 Batch    6/6   train_loss = 0.129   time_elapsed = 4158.954   time_remaining = 2611\n",
      "Epoch 1844 Batch    6/6   train_loss = 0.128   time_elapsed = 4161.133   time_remaining = 2609\n",
      "Epoch 1845 Batch    6/6   train_loss = 0.131   time_elapsed = 4163.301   time_remaining = 2606\n",
      "Epoch 1846 Batch    6/6   train_loss = 0.126   time_elapsed = 4165.469   time_remaining = 2604\n",
      "Epoch 1847 Batch    6/6   train_loss = 0.127   time_elapsed = 4167.631   time_remaining = 2602\n",
      "Epoch 1848 Batch    6/6   train_loss = 0.133   time_elapsed = 4169.796   time_remaining = 2599\n",
      "Epoch 1849 Batch    6/6   train_loss = 0.129   time_elapsed = 4171.975   time_remaining = 2597\n",
      "Epoch 1850 Batch    6/6   train_loss = 0.134   time_elapsed = 4174.149   time_remaining = 2595\n",
      "Epoch 1851 Batch    6/6   train_loss = 0.139   time_elapsed = 4176.319   time_remaining = 2592\n",
      "Model Trained and Saved\n",
      "Epoch 1852 Batch    6/6   train_loss = 0.128   time_elapsed = 4179.524   time_remaining = 2591\n",
      "Epoch 1853 Batch    6/6   train_loss = 0.134   time_elapsed = 4181.694   time_remaining = 2588\n",
      "Epoch 1854 Batch    6/6   train_loss = 0.133   time_elapsed = 4183.864   time_remaining = 2586\n",
      "Epoch 1855 Batch    6/6   train_loss = 0.129   time_elapsed = 4186.028   time_remaining = 2584\n",
      "Epoch 1856 Batch    6/6   train_loss = 0.129   time_elapsed = 4188.198   time_remaining = 2582\n",
      "Epoch 1857 Batch    6/6   train_loss = 0.128   time_elapsed = 4190.369   time_remaining = 2579\n",
      "Epoch 1858 Batch    6/6   train_loss = 0.136   time_elapsed = 4192.542   time_remaining = 2577\n",
      "Epoch 1859 Batch    6/6   train_loss = 0.134   time_elapsed = 4194.715   time_remaining = 2575\n",
      "Epoch 1860 Batch    6/6   train_loss = 0.133   time_elapsed = 4196.892   time_remaining = 2572\n",
      "Epoch 1861 Batch    6/6   train_loss = 0.134   time_elapsed = 4199.064   time_remaining = 2570\n",
      "Model Trained and Saved\n",
      "Epoch 1862 Batch    6/6   train_loss = 0.127   time_elapsed = 4202.193   time_remaining = 2568\n",
      "Epoch 1863 Batch    6/6   train_loss = 0.127   time_elapsed = 4204.362   time_remaining = 2566\n",
      "Epoch 1864 Batch    6/6   train_loss = 0.122   time_elapsed = 4206.530   time_remaining = 2564\n",
      "Epoch 1865 Batch    6/6   train_loss = 0.128   time_elapsed = 4208.697   time_remaining = 2561\n",
      "Epoch 1866 Batch    6/6   train_loss = 0.126   time_elapsed = 4210.867   time_remaining = 2559\n",
      "Epoch 1867 Batch    6/6   train_loss = 0.122   time_elapsed = 4213.045   time_remaining = 2557\n",
      "Epoch 1868 Batch    6/6   train_loss = 0.130   time_elapsed = 4215.224   time_remaining = 2554\n",
      "Epoch 1869 Batch    6/6   train_loss = 0.129   time_elapsed = 4217.393   time_remaining = 2552\n",
      "Epoch 1870 Batch    6/6   train_loss = 0.130   time_elapsed = 4219.560   time_remaining = 2550\n",
      "Epoch 1871 Batch    6/6   train_loss = 0.127   time_elapsed = 4221.730   time_remaining = 2547\n",
      "Model Trained and Saved\n",
      "Epoch 1872 Batch    6/6   train_loss = 0.119   time_elapsed = 4224.827   time_remaining = 2546\n",
      "Epoch 1873 Batch    6/6   train_loss = 0.133   time_elapsed = 4226.991   time_remaining = 2543\n",
      "Epoch 1874 Batch    6/6   train_loss = 0.128   time_elapsed = 4229.162   time_remaining = 2541\n",
      "Epoch 1875 Batch    6/6   train_loss = 0.127   time_elapsed = 4231.322   time_remaining = 2539\n",
      "Epoch 1876 Batch    6/6   train_loss = 0.123   time_elapsed = 4233.495   time_remaining = 2536\n",
      "Epoch 1877 Batch    6/6   train_loss = 0.121   time_elapsed = 4235.662   time_remaining = 2534\n",
      "Epoch 1878 Batch    6/6   train_loss = 0.124   time_elapsed = 4237.825   time_remaining = 2532\n",
      "Epoch 1879 Batch    6/6   train_loss = 0.122   time_elapsed = 4239.991   time_remaining = 2530\n",
      "Epoch 1880 Batch    6/6   train_loss = 0.132   time_elapsed = 4242.159   time_remaining = 2527\n",
      "Epoch 1881 Batch    6/6   train_loss = 0.132   time_elapsed = 4244.330   time_remaining = 2525\n",
      "Model Trained and Saved\n",
      "Epoch 1882 Batch    6/6   train_loss = 0.133   time_elapsed = 4247.424   time_remaining = 2523\n",
      "Epoch 1883 Batch    6/6   train_loss = 0.137   time_elapsed = 4249.590   time_remaining = 2521\n",
      "Epoch 1884 Batch    6/6   train_loss = 0.127   time_elapsed = 4251.759   time_remaining = 2519\n",
      "Epoch 1885 Batch    6/6   train_loss = 0.120   time_elapsed = 4253.925   time_remaining = 2516\n",
      "Epoch 1886 Batch    6/6   train_loss = 0.128   time_elapsed = 4256.095   time_remaining = 2514\n",
      "Epoch 1887 Batch    6/6   train_loss = 0.127   time_elapsed = 4258.267   time_remaining = 2512\n",
      "Epoch 1888 Batch    6/6   train_loss = 0.134   time_elapsed = 4260.437   time_remaining = 2509\n",
      "Epoch 1889 Batch    6/6   train_loss = 0.130   time_elapsed = 4262.608   time_remaining = 2507\n",
      "Epoch 1890 Batch    6/6   train_loss = 0.136   time_elapsed = 4264.784   time_remaining = 2505\n",
      "Epoch 1891 Batch    6/6   train_loss = 0.128   time_elapsed = 4266.951   time_remaining = 2502\n",
      "Model Trained and Saved\n",
      "Epoch 1892 Batch    6/6   train_loss = 0.130   time_elapsed = 4270.175   time_remaining = 2501\n",
      "Epoch 1893 Batch    6/6   train_loss = 0.132   time_elapsed = 4272.340   time_remaining = 2498\n",
      "Epoch 1894 Batch    6/6   train_loss = 0.127   time_elapsed = 4274.507   time_remaining = 2496\n",
      "Epoch 1895 Batch    6/6   train_loss = 0.126   time_elapsed = 4276.676   time_remaining = 2494\n",
      "Epoch 1896 Batch    6/6   train_loss = 0.130   time_elapsed = 4278.847   time_remaining = 2491\n",
      "Epoch 1897 Batch    6/6   train_loss = 0.126   time_elapsed = 4281.018   time_remaining = 2489\n",
      "Epoch 1898 Batch    6/6   train_loss = 0.132   time_elapsed = 4283.191   time_remaining = 2487\n",
      "Epoch 1899 Batch    6/6   train_loss = 0.118   time_elapsed = 4285.357   time_remaining = 2485\n",
      "Epoch 1900 Batch    6/6   train_loss = 0.121   time_elapsed = 4287.525   time_remaining = 2482\n",
      "Epoch 1901 Batch    6/6   train_loss = 0.121   time_elapsed = 4289.694   time_remaining = 2480\n",
      "Model Trained and Saved\n",
      "Epoch 1902 Batch    6/6   train_loss = 0.128   time_elapsed = 4292.783   time_remaining = 2478\n",
      "Epoch 1903 Batch    6/6   train_loss = 0.126   time_elapsed = 4294.959   time_remaining = 2476\n",
      "Epoch 1904 Batch    6/6   train_loss = 0.123   time_elapsed = 4297.128   time_remaining = 2474\n",
      "Epoch 1905 Batch    6/6   train_loss = 0.128   time_elapsed = 4299.296   time_remaining = 2471\n",
      "Epoch 1906 Batch    6/6   train_loss = 0.125   time_elapsed = 4301.464   time_remaining = 2469\n",
      "Epoch 1907 Batch    6/6   train_loss = 0.120   time_elapsed = 4303.629   time_remaining = 2467\n",
      "Epoch 1908 Batch    6/6   train_loss = 0.119   time_elapsed = 4305.803   time_remaining = 2464\n",
      "Epoch 1909 Batch    6/6   train_loss = 0.126   time_elapsed = 4307.968   time_remaining = 2462\n",
      "Epoch 1910 Batch    6/6   train_loss = 0.124   time_elapsed = 4310.133   time_remaining = 2460\n",
      "Epoch 1911 Batch    6/6   train_loss = 0.125   time_elapsed = 4312.298   time_remaining = 2457\n",
      "Model Trained and Saved\n",
      "Epoch 1912 Batch    6/6   train_loss = 0.116   time_elapsed = 4315.391   time_remaining = 2456\n",
      "Epoch 1913 Batch    6/6   train_loss = 0.126   time_elapsed = 4317.560   time_remaining = 2453\n",
      "Epoch 1914 Batch    6/6   train_loss = 0.126   time_elapsed = 4319.728   time_remaining = 2451\n",
      "Epoch 1915 Batch    6/6   train_loss = 0.125   time_elapsed = 4321.892   time_remaining = 2449\n",
      "Epoch 1916 Batch    6/6   train_loss = 0.128   time_elapsed = 4324.061   time_remaining = 2446\n",
      "Epoch 1917 Batch    6/6   train_loss = 0.121   time_elapsed = 4326.226   time_remaining = 2444\n",
      "Epoch 1918 Batch    6/6   train_loss = 0.122   time_elapsed = 4328.410   time_remaining = 2442\n",
      "Epoch 1919 Batch    6/6   train_loss = 0.120   time_elapsed = 4330.582   time_remaining = 2439\n",
      "Epoch 1920 Batch    6/6   train_loss = 0.123   time_elapsed = 4332.747   time_remaining = 2437\n",
      "Epoch 1921 Batch    6/6   train_loss = 0.119   time_elapsed = 4334.921   time_remaining = 2435\n",
      "Model Trained and Saved\n",
      "Epoch 1922 Batch    6/6   train_loss = 0.120   time_elapsed = 4338.031   time_remaining = 2433\n",
      "Epoch 1923 Batch    6/6   train_loss = 0.119   time_elapsed = 4340.201   time_remaining = 2431\n",
      "Epoch 1924 Batch    6/6   train_loss = 0.120   time_elapsed = 4342.373   time_remaining = 2428\n",
      "Epoch 1925 Batch    6/6   train_loss = 0.123   time_elapsed = 4344.540   time_remaining = 2426\n",
      "Epoch 1926 Batch    6/6   train_loss = 0.129   time_elapsed = 4346.711   time_remaining = 2424\n",
      "Epoch 1927 Batch    6/6   train_loss = 0.117   time_elapsed = 4348.887   time_remaining = 2422\n",
      "Epoch 1928 Batch    6/6   train_loss = 0.130   time_elapsed = 4351.062   time_remaining = 2419\n",
      "Epoch 1929 Batch    6/6   train_loss = 0.123   time_elapsed = 4353.231   time_remaining = 2417\n",
      "Epoch 1930 Batch    6/6   train_loss = 0.122   time_elapsed = 4355.400   time_remaining = 2415\n",
      "Epoch 1931 Batch    6/6   train_loss = 0.128   time_elapsed = 4357.561   time_remaining = 2412\n",
      "Model Trained and Saved\n",
      "Epoch 1932 Batch    6/6   train_loss = 0.122   time_elapsed = 4360.898   time_remaining = 2411\n",
      "Epoch 1933 Batch    6/6   train_loss = 0.125   time_elapsed = 4363.065   time_remaining = 2408\n",
      "Epoch 1934 Batch    6/6   train_loss = 0.123   time_elapsed = 4365.233   time_remaining = 2406\n",
      "Epoch 1935 Batch    6/6   train_loss = 0.122   time_elapsed = 4367.396   time_remaining = 2404\n",
      "Epoch 1936 Batch    6/6   train_loss = 0.125   time_elapsed = 4369.574   time_remaining = 2401\n",
      "Epoch 1937 Batch    6/6   train_loss = 0.119   time_elapsed = 4371.734   time_remaining = 2399\n",
      "Epoch 1938 Batch    6/6   train_loss = 0.122   time_elapsed = 4373.899   time_remaining = 2397\n",
      "Epoch 1939 Batch    6/6   train_loss = 0.122   time_elapsed = 4376.062   time_remaining = 2395\n",
      "Epoch 1940 Batch    6/6   train_loss = 0.117   time_elapsed = 4378.226   time_remaining = 2392\n",
      "Epoch 1941 Batch    6/6   train_loss = 0.115   time_elapsed = 4380.385   time_remaining = 2390\n",
      "Model Trained and Saved\n",
      "Epoch 1942 Batch    6/6   train_loss = 0.123   time_elapsed = 4383.488   time_remaining = 2388\n",
      "Epoch 1943 Batch    6/6   train_loss = 0.121   time_elapsed = 4385.656   time_remaining = 2386\n",
      "Epoch 1944 Batch    6/6   train_loss = 0.119   time_elapsed = 4387.818   time_remaining = 2384\n",
      "Epoch 1945 Batch    6/6   train_loss = 0.121   time_elapsed = 4389.978   time_remaining = 2381\n",
      "Epoch 1946 Batch    6/6   train_loss = 0.118   time_elapsed = 4392.141   time_remaining = 2379\n",
      "Epoch 1947 Batch    6/6   train_loss = 0.123   time_elapsed = 4394.306   time_remaining = 2377\n",
      "Epoch 1948 Batch    6/6   train_loss = 0.127   time_elapsed = 4396.470   time_remaining = 2374\n",
      "Epoch 1949 Batch    6/6   train_loss = 0.127   time_elapsed = 4398.646   time_remaining = 2372\n",
      "Epoch 1950 Batch    6/6   train_loss = 0.118   time_elapsed = 4400.810   time_remaining = 2370\n",
      "Epoch 1951 Batch    6/6   train_loss = 0.122   time_elapsed = 4402.976   time_remaining = 2367\n",
      "Model Trained and Saved\n",
      "Epoch 1952 Batch    6/6   train_loss = 0.124   time_elapsed = 4406.079   time_remaining = 2366\n",
      "Epoch 1953 Batch    6/6   train_loss = 0.122   time_elapsed = 4408.251   time_remaining = 2363\n",
      "Epoch 1954 Batch    6/6   train_loss = 0.124   time_elapsed = 4410.415   time_remaining = 2361\n",
      "Epoch 1955 Batch    6/6   train_loss = 0.130   time_elapsed = 4412.590   time_remaining = 2359\n",
      "Epoch 1956 Batch    6/6   train_loss = 0.124   time_elapsed = 4414.762   time_remaining = 2356\n",
      "Epoch 1957 Batch    6/6   train_loss = 0.120   time_elapsed = 4416.932   time_remaining = 2354\n",
      "Epoch 1958 Batch    6/6   train_loss = 0.121   time_elapsed = 4419.102   time_remaining = 2352\n",
      "Epoch 1959 Batch    6/6   train_loss = 0.119   time_elapsed = 4421.271   time_remaining = 2349\n",
      "Epoch 1960 Batch    6/6   train_loss = 0.120   time_elapsed = 4423.437   time_remaining = 2347\n",
      "Epoch 1961 Batch    6/6   train_loss = 0.127   time_elapsed = 4425.605   time_remaining = 2345\n",
      "Model Trained and Saved\n",
      "Epoch 1962 Batch    6/6   train_loss = 0.120   time_elapsed = 4428.845   time_remaining = 2343\n",
      "Epoch 1963 Batch    6/6   train_loss = 0.114   time_elapsed = 4431.017   time_remaining = 2341\n",
      "Epoch 1964 Batch    6/6   train_loss = 0.126   time_elapsed = 4433.180   time_remaining = 2338\n",
      "Epoch 1965 Batch    6/6   train_loss = 0.123   time_elapsed = 4435.350   time_remaining = 2336\n",
      "Epoch 1966 Batch    6/6   train_loss = 0.116   time_elapsed = 4437.522   time_remaining = 2334\n",
      "Epoch 1967 Batch    6/6   train_loss = 0.120   time_elapsed = 4439.688   time_remaining = 2332\n",
      "Epoch 1968 Batch    6/6   train_loss = 0.114   time_elapsed = 4441.857   time_remaining = 2329\n",
      "Epoch 1969 Batch    6/6   train_loss = 0.122   time_elapsed = 4444.025   time_remaining = 2327\n",
      "Epoch 1970 Batch    6/6   train_loss = 0.116   time_elapsed = 4446.200   time_remaining = 2325\n",
      "Epoch 1971 Batch    6/6   train_loss = 0.115   time_elapsed = 4448.368   time_remaining = 2322\n",
      "Model Trained and Saved\n",
      "Epoch 1972 Batch    6/6   train_loss = 0.118   time_elapsed = 4451.497   time_remaining = 2321\n",
      "Epoch 1973 Batch    6/6   train_loss = 0.122   time_elapsed = 4453.663   time_remaining = 2318\n",
      "Epoch 1974 Batch    6/6   train_loss = 0.119   time_elapsed = 4455.837   time_remaining = 2316\n",
      "Epoch 1975 Batch    6/6   train_loss = 0.125   time_elapsed = 4458.008   time_remaining = 2314\n",
      "Epoch 1976 Batch    6/6   train_loss = 0.117   time_elapsed = 4460.177   time_remaining = 2311\n",
      "Epoch 1977 Batch    6/6   train_loss = 0.122   time_elapsed = 4462.347   time_remaining = 2309\n",
      "Epoch 1978 Batch    6/6   train_loss = 0.115   time_elapsed = 4464.508   time_remaining = 2307\n",
      "Epoch 1979 Batch    6/6   train_loss = 0.116   time_elapsed = 4466.677   time_remaining = 2304\n",
      "Epoch 1980 Batch    6/6   train_loss = 0.119   time_elapsed = 4468.840   time_remaining = 2302\n",
      "Epoch 1981 Batch    6/6   train_loss = 0.122   time_elapsed = 4471.013   time_remaining = 2300\n",
      "Model Trained and Saved\n",
      "Epoch 1982 Batch    6/6   train_loss = 0.122   time_elapsed = 4474.118   time_remaining = 2298\n",
      "Epoch 1983 Batch    6/6   train_loss = 0.123   time_elapsed = 4476.285   time_remaining = 2296\n",
      "Epoch 1984 Batch    6/6   train_loss = 0.118   time_elapsed = 4478.445   time_remaining = 2293\n",
      "Epoch 1985 Batch    6/6   train_loss = 0.131   time_elapsed = 4480.621   time_remaining = 2291\n",
      "Epoch 1986 Batch    6/6   train_loss = 0.113   time_elapsed = 4482.794   time_remaining = 2289\n",
      "Epoch 1987 Batch    6/6   train_loss = 0.129   time_elapsed = 4484.963   time_remaining = 2286\n",
      "Epoch 1988 Batch    6/6   train_loss = 0.122   time_elapsed = 4487.132   time_remaining = 2284\n",
      "Epoch 1989 Batch    6/6   train_loss = 0.118   time_elapsed = 4489.303   time_remaining = 2282\n",
      "Epoch 1990 Batch    6/6   train_loss = 0.120   time_elapsed = 4491.473   time_remaining = 2280\n",
      "Epoch 1991 Batch    6/6   train_loss = 0.119   time_elapsed = 4493.641   time_remaining = 2277\n",
      "Model Trained and Saved\n",
      "Epoch 1992 Batch    6/6   train_loss = 0.119   time_elapsed = 4496.776   time_remaining = 2275\n",
      "Epoch 1993 Batch    6/6   train_loss = 0.112   time_elapsed = 4498.941   time_remaining = 2273\n",
      "Epoch 1994 Batch    6/6   train_loss = 0.121   time_elapsed = 4501.119   time_remaining = 2271\n",
      "Epoch 1995 Batch    6/6   train_loss = 0.121   time_elapsed = 4503.285   time_remaining = 2269\n",
      "Epoch 1996 Batch    6/6   train_loss = 0.122   time_elapsed = 4505.449   time_remaining = 2266\n",
      "Epoch 1997 Batch    6/6   train_loss = 0.122   time_elapsed = 4507.620   time_remaining = 2264\n",
      "Epoch 1998 Batch    6/6   train_loss = 0.119   time_elapsed = 4509.792   time_remaining = 2262\n",
      "Epoch 1999 Batch    6/6   train_loss = 0.123   time_elapsed = 4511.955   time_remaining = 2259\n",
      "Epoch 2000 Batch    6/6   train_loss = 0.120   time_elapsed = 4514.121   time_remaining = 2257\n",
      "Epoch 2001 Batch    6/6   train_loss = 0.119   time_elapsed = 4516.288   time_remaining = 2255\n",
      "Model Trained and Saved\n",
      "Epoch 2002 Batch    6/6   train_loss = 0.111   time_elapsed = 4519.425   time_remaining = 2253\n",
      "Epoch 2003 Batch    6/6   train_loss = 0.120   time_elapsed = 4521.592   time_remaining = 2251\n",
      "Epoch 2004 Batch    6/6   train_loss = 0.114   time_elapsed = 4523.760   time_remaining = 2248\n",
      "Epoch 2005 Batch    6/6   train_loss = 0.120   time_elapsed = 4525.930   time_remaining = 2246\n",
      "Epoch 2006 Batch    6/6   train_loss = 0.115   time_elapsed = 4528.094   time_remaining = 2244\n",
      "Epoch 2007 Batch    6/6   train_loss = 0.119   time_elapsed = 4530.261   time_remaining = 2241\n",
      "Epoch 2008 Batch    6/6   train_loss = 0.124   time_elapsed = 4532.425   time_remaining = 2239\n",
      "Epoch 2009 Batch    6/6   train_loss = 0.122   time_elapsed = 4534.593   time_remaining = 2237\n",
      "Epoch 2010 Batch    6/6   train_loss = 0.117   time_elapsed = 4536.764   time_remaining = 2235\n",
      "Epoch 2011 Batch    6/6   train_loss = 0.116   time_elapsed = 4538.928   time_remaining = 2232\n",
      "Model Trained and Saved\n",
      "Epoch 2012 Batch    6/6   train_loss = 0.121   time_elapsed = 4542.091   time_remaining = 2230\n",
      "Epoch 2013 Batch    6/6   train_loss = 0.117   time_elapsed = 4544.248   time_remaining = 2228\n",
      "Epoch 2014 Batch    6/6   train_loss = 0.119   time_elapsed = 4546.421   time_remaining = 2226\n",
      "Epoch 2015 Batch    6/6   train_loss = 0.122   time_elapsed = 4548.595   time_remaining = 2224\n",
      "Epoch 2016 Batch    6/6   train_loss = 0.119   time_elapsed = 4550.757   time_remaining = 2221\n",
      "Epoch 2017 Batch    6/6   train_loss = 0.115   time_elapsed = 4552.922   time_remaining = 2219\n",
      "Epoch 2018 Batch    6/6   train_loss = 0.116   time_elapsed = 4555.093   time_remaining = 2217\n",
      "Epoch 2019 Batch    6/6   train_loss = 0.118   time_elapsed = 4557.269   time_remaining = 2214\n",
      "Epoch 2020 Batch    6/6   train_loss = 0.120   time_elapsed = 4559.434   time_remaining = 2212\n",
      "Epoch 2021 Batch    6/6   train_loss = 0.116   time_elapsed = 4561.602   time_remaining = 2210\n",
      "Model Trained and Saved\n",
      "Epoch 2022 Batch    6/6   train_loss = 0.114   time_elapsed = 4564.859   time_remaining = 2208\n",
      "Epoch 2023 Batch    6/6   train_loss = 0.116   time_elapsed = 4567.026   time_remaining = 2206\n",
      "Epoch 2024 Batch    6/6   train_loss = 0.114   time_elapsed = 4569.190   time_remaining = 2203\n",
      "Epoch 2025 Batch    6/6   train_loss = 0.115   time_elapsed = 4571.359   time_remaining = 2201\n",
      "Epoch 2026 Batch    6/6   train_loss = 0.120   time_elapsed = 4573.532   time_remaining = 2199\n",
      "Epoch 2027 Batch    6/6   train_loss = 0.121   time_elapsed = 4575.690   time_remaining = 2196\n",
      "Epoch 2028 Batch    6/6   train_loss = 0.117   time_elapsed = 4577.855   time_remaining = 2194\n",
      "Epoch 2029 Batch    6/6   train_loss = 0.116   time_elapsed = 4580.020   time_remaining = 2192\n",
      "Epoch 2030 Batch    6/6   train_loss = 0.119   time_elapsed = 4582.186   time_remaining = 2190\n",
      "Epoch 2031 Batch    6/6   train_loss = 0.115   time_elapsed = 4584.351   time_remaining = 2187\n",
      "Model Trained and Saved\n",
      "Epoch 2032 Batch    6/6   train_loss = 0.124   time_elapsed = 4587.455   time_remaining = 2185\n",
      "Epoch 2033 Batch    6/6   train_loss = 0.122   time_elapsed = 4589.625   time_remaining = 2183\n",
      "Epoch 2034 Batch    6/6   train_loss = 0.112   time_elapsed = 4591.790   time_remaining = 2181\n",
      "Epoch 2035 Batch    6/6   train_loss = 0.120   time_elapsed = 4593.958   time_remaining = 2178\n",
      "Epoch 2036 Batch    6/6   train_loss = 0.115   time_elapsed = 4596.133   time_remaining = 2176\n",
      "Epoch 2037 Batch    6/6   train_loss = 0.117   time_elapsed = 4598.295   time_remaining = 2174\n",
      "Epoch 2038 Batch    6/6   train_loss = 0.117   time_elapsed = 4600.468   time_remaining = 2172\n",
      "Epoch 2039 Batch    6/6   train_loss = 0.122   time_elapsed = 4602.649   time_remaining = 2169\n",
      "Epoch 2040 Batch    6/6   train_loss = 0.119   time_elapsed = 4604.814   time_remaining = 2167\n",
      "Epoch 2041 Batch    6/6   train_loss = 0.117   time_elapsed = 4606.979   time_remaining = 2165\n",
      "Model Trained and Saved\n",
      "Epoch 2042 Batch    6/6   train_loss = 0.116   time_elapsed = 4610.111   time_remaining = 2163\n",
      "Epoch 2043 Batch    6/6   train_loss = 0.114   time_elapsed = 4612.285   time_remaining = 2161\n",
      "Epoch 2044 Batch    6/6   train_loss = 0.115   time_elapsed = 4614.446   time_remaining = 2158\n",
      "Epoch 2045 Batch    6/6   train_loss = 0.119   time_elapsed = 4616.610   time_remaining = 2156\n",
      "Epoch 2046 Batch    6/6   train_loss = 0.112   time_elapsed = 4618.778   time_remaining = 2154\n",
      "Epoch 2047 Batch    6/6   train_loss = 0.120   time_elapsed = 4620.948   time_remaining = 2151\n",
      "Epoch 2048 Batch    6/6   train_loss = 0.113   time_elapsed = 4623.116   time_remaining = 2149\n",
      "Epoch 2049 Batch    6/6   train_loss = 0.120   time_elapsed = 4625.281   time_remaining = 2147\n",
      "Epoch 2050 Batch    6/6   train_loss = 0.115   time_elapsed = 4627.446   time_remaining = 2144\n",
      "Epoch 2051 Batch    6/6   train_loss = 0.117   time_elapsed = 4629.612   time_remaining = 2142\n",
      "Model Trained and Saved\n",
      "Epoch 2052 Batch    6/6   train_loss = 0.119   time_elapsed = 4632.739   time_remaining = 2140\n",
      "Epoch 2053 Batch    6/6   train_loss = 0.109   time_elapsed = 4634.900   time_remaining = 2138\n",
      "Epoch 2054 Batch    6/6   train_loss = 0.114   time_elapsed = 4637.067   time_remaining = 2136\n",
      "Epoch 2055 Batch    6/6   train_loss = 0.120   time_elapsed = 4639.236   time_remaining = 2133\n",
      "Epoch 2056 Batch    6/6   train_loss = 0.116   time_elapsed = 4641.402   time_remaining = 2131\n",
      "Epoch 2057 Batch    6/6   train_loss = 0.113   time_elapsed = 4643.569   time_remaining = 2129\n",
      "Epoch 2058 Batch    6/6   train_loss = 0.116   time_elapsed = 4645.744   time_remaining = 2126\n",
      "Epoch 2059 Batch    6/6   train_loss = 0.113   time_elapsed = 4647.913   time_remaining = 2124\n",
      "Epoch 2060 Batch    6/6   train_loss = 0.117   time_elapsed = 4650.077   time_remaining = 2122\n",
      "Epoch 2061 Batch    6/6   train_loss = 0.117   time_elapsed = 4652.252   time_remaining = 2120\n",
      "Model Trained and Saved\n",
      "Epoch 2062 Batch    6/6   train_loss = 0.114   time_elapsed = 4655.369   time_remaining = 2118\n",
      "Epoch 2063 Batch    6/6   train_loss = 0.119   time_elapsed = 4657.524   time_remaining = 2115\n",
      "Epoch 2064 Batch    6/6   train_loss = 0.114   time_elapsed = 4659.699   time_remaining = 2113\n",
      "Epoch 2065 Batch    6/6   train_loss = 0.116   time_elapsed = 4661.864   time_remaining = 2111\n",
      "Epoch 2066 Batch    6/6   train_loss = 0.121   time_elapsed = 4664.036   time_remaining = 2109\n",
      "Epoch 2067 Batch    6/6   train_loss = 0.116   time_elapsed = 4666.203   time_remaining = 2106\n",
      "Epoch 2068 Batch    6/6   train_loss = 0.114   time_elapsed = 4668.362   time_remaining = 2104\n",
      "Epoch 2069 Batch    6/6   train_loss = 0.117   time_elapsed = 4670.532   time_remaining = 2102\n",
      "Epoch 2070 Batch    6/6   train_loss = 0.124   time_elapsed = 4672.697   time_remaining = 2099\n",
      "Epoch 2071 Batch    6/6   train_loss = 0.119   time_elapsed = 4674.863   time_remaining = 2097\n",
      "Model Trained and Saved\n",
      "Epoch 2072 Batch    6/6   train_loss = 0.111   time_elapsed = 4678.003   time_remaining = 2095\n",
      "Epoch 2073 Batch    6/6   train_loss = 0.119   time_elapsed = 4680.169   time_remaining = 2093\n",
      "Epoch 2074 Batch    6/6   train_loss = 0.111   time_elapsed = 4682.328   time_remaining = 2091\n",
      "Epoch 2075 Batch    6/6   train_loss = 0.114   time_elapsed = 4684.498   time_remaining = 2088\n",
      "Epoch 2076 Batch    6/6   train_loss = 0.113   time_elapsed = 4686.671   time_remaining = 2086\n",
      "Epoch 2077 Batch    6/6   train_loss = 0.112   time_elapsed = 4688.837   time_remaining = 2084\n",
      "Epoch 2078 Batch    6/6   train_loss = 0.115   time_elapsed = 4691.005   time_remaining = 2081\n",
      "Epoch 2079 Batch    6/6   train_loss = 0.114   time_elapsed = 4693.173   time_remaining = 2079\n",
      "Epoch 2080 Batch    6/6   train_loss = 0.115   time_elapsed = 4695.338   time_remaining = 2077\n",
      "Epoch 2081 Batch    6/6   train_loss = 0.113   time_elapsed = 4697.513   time_remaining = 2074\n",
      "Model Trained and Saved\n",
      "Epoch 2082 Batch    6/6   train_loss = 0.122   time_elapsed = 4700.659   time_remaining = 2073\n",
      "Epoch 2083 Batch    6/6   train_loss = 0.110   time_elapsed = 4702.824   time_remaining = 2070\n",
      "Epoch 2084 Batch    6/6   train_loss = 0.112   time_elapsed = 4704.993   time_remaining = 2068\n",
      "Epoch 2085 Batch    6/6   train_loss = 0.114   time_elapsed = 4707.157   time_remaining = 2066\n",
      "Epoch 2086 Batch    6/6   train_loss = 0.112   time_elapsed = 4709.327   time_remaining = 2063\n",
      "Epoch 2087 Batch    6/6   train_loss = 0.109   time_elapsed = 4711.503   time_remaining = 2061\n",
      "Epoch 2088 Batch    6/6   train_loss = 0.117   time_elapsed = 4713.663   time_remaining = 2059\n",
      "Epoch 2089 Batch    6/6   train_loss = 0.109   time_elapsed = 4715.837   time_remaining = 2057\n",
      "Epoch 2090 Batch    6/6   train_loss = 0.119   time_elapsed = 4718.013   time_remaining = 2054\n",
      "Epoch 2091 Batch    6/6   train_loss = 0.113   time_elapsed = 4720.186   time_remaining = 2052\n",
      "Model Trained and Saved\n",
      "Epoch 2092 Batch    6/6   train_loss = 0.110   time_elapsed = 4723.327   time_remaining = 2050\n",
      "Epoch 2093 Batch    6/6   train_loss = 0.113   time_elapsed = 4725.492   time_remaining = 2048\n",
      "Epoch 2094 Batch    6/6   train_loss = 0.111   time_elapsed = 4727.662   time_remaining = 2045\n",
      "Epoch 2095 Batch    6/6   train_loss = 0.114   time_elapsed = 4729.831   time_remaining = 2043\n",
      "Epoch 2096 Batch    6/6   train_loss = 0.117   time_elapsed = 4732.000   time_remaining = 2041\n",
      "Epoch 2097 Batch    6/6   train_loss = 0.124   time_elapsed = 4734.173   time_remaining = 2039\n",
      "Epoch 2098 Batch    6/6   train_loss = 0.109   time_elapsed = 4736.339   time_remaining = 2036\n",
      "Epoch 2099 Batch    6/6   train_loss = 0.116   time_elapsed = 4738.515   time_remaining = 2034\n",
      "Epoch 2100 Batch    6/6   train_loss = 0.117   time_elapsed = 4740.687   time_remaining = 2032\n",
      "Epoch 2101 Batch    6/6   train_loss = 0.112   time_elapsed = 4742.858   time_remaining = 2029\n",
      "Model Trained and Saved\n",
      "Epoch 2102 Batch    6/6   train_loss = 0.113   time_elapsed = 4745.991   time_remaining = 2028\n",
      "Epoch 2103 Batch    6/6   train_loss = 0.109   time_elapsed = 4748.154   time_remaining = 2025\n",
      "Epoch 2104 Batch    6/6   train_loss = 0.117   time_elapsed = 4750.315   time_remaining = 2023\n",
      "Epoch 2105 Batch    6/6   train_loss = 0.113   time_elapsed = 4752.487   time_remaining = 2021\n",
      "Epoch 2106 Batch    6/6   train_loss = 0.110   time_elapsed = 4754.654   time_remaining = 2018\n",
      "Epoch 2107 Batch    6/6   train_loss = 0.116   time_elapsed = 4756.823   time_remaining = 2016\n",
      "Epoch 2108 Batch    6/6   train_loss = 0.111   time_elapsed = 4758.987   time_remaining = 2014\n",
      "Epoch 2109 Batch    6/6   train_loss = 0.117   time_elapsed = 4761.153   time_remaining = 2011\n",
      "Epoch 2110 Batch    6/6   train_loss = 0.109   time_elapsed = 4763.332   time_remaining = 2009\n",
      "Epoch 2111 Batch    6/6   train_loss = 0.113   time_elapsed = 4765.498   time_remaining = 2007\n",
      "Model Trained and Saved\n",
      "Epoch 2112 Batch    6/6   train_loss = 0.112   time_elapsed = 4768.619   time_remaining = 2005\n",
      "Epoch 2113 Batch    6/6   train_loss = 0.109   time_elapsed = 4770.783   time_remaining = 2003\n",
      "Epoch 2114 Batch    6/6   train_loss = 0.111   time_elapsed = 4772.944   time_remaining = 2000\n",
      "Epoch 2115 Batch    6/6   train_loss = 0.110   time_elapsed = 4775.109   time_remaining = 1998\n",
      "Epoch 2116 Batch    6/6   train_loss = 0.119   time_elapsed = 4777.278   time_remaining = 1996\n",
      "Epoch 2117 Batch    6/6   train_loss = 0.111   time_elapsed = 4779.440   time_remaining = 1994\n",
      "Epoch 2118 Batch    6/6   train_loss = 0.108   time_elapsed = 4781.616   time_remaining = 1991\n",
      "Epoch 2119 Batch    6/6   train_loss = 0.108   time_elapsed = 4783.784   time_remaining = 1989\n",
      "Epoch 2120 Batch    6/6   train_loss = 0.110   time_elapsed = 4785.957   time_remaining = 1987\n",
      "Epoch 2121 Batch    6/6   train_loss = 0.114   time_elapsed = 4788.131   time_remaining = 1984\n",
      "Model Trained and Saved\n",
      "Epoch 2122 Batch    6/6   train_loss = 0.107   time_elapsed = 4791.258   time_remaining = 1982\n",
      "Epoch 2123 Batch    6/6   train_loss = 0.114   time_elapsed = 4793.423   time_remaining = 1980\n",
      "Epoch 2124 Batch    6/6   train_loss = 0.114   time_elapsed = 4795.590   time_remaining = 1978\n",
      "Epoch 2125 Batch    6/6   train_loss = 0.109   time_elapsed = 4797.761   time_remaining = 1976\n",
      "Epoch 2126 Batch    6/6   train_loss = 0.106   time_elapsed = 4799.926   time_remaining = 1973\n",
      "Epoch 2127 Batch    6/6   train_loss = 0.120   time_elapsed = 4802.096   time_remaining = 1971\n",
      "Epoch 2128 Batch    6/6   train_loss = 0.113   time_elapsed = 4804.261   time_remaining = 1969\n",
      "Epoch 2129 Batch    6/6   train_loss = 0.111   time_elapsed = 4806.426   time_remaining = 1966\n",
      "Epoch 2130 Batch    6/6   train_loss = 0.107   time_elapsed = 4808.603   time_remaining = 1964\n",
      "Epoch 2131 Batch    6/6   train_loss = 0.110   time_elapsed = 4810.771   time_remaining = 1962\n",
      "Model Trained and Saved\n",
      "Epoch 2132 Batch    6/6   train_loss = 0.112   time_elapsed = 4813.911   time_remaining = 1960\n",
      "Epoch 2133 Batch    6/6   train_loss = 0.108   time_elapsed = 4816.078   time_remaining = 1958\n",
      "Epoch 2134 Batch    6/6   train_loss = 0.110   time_elapsed = 4818.242   time_remaining = 1955\n",
      "Epoch 2135 Batch    6/6   train_loss = 0.114   time_elapsed = 4820.398   time_remaining = 1953\n",
      "Epoch 2136 Batch    6/6   train_loss = 0.109   time_elapsed = 4822.569   time_remaining = 1951\n",
      "Epoch 2137 Batch    6/6   train_loss = 0.107   time_elapsed = 4824.740   time_remaining = 1948\n",
      "Epoch 2138 Batch    6/6   train_loss = 0.111   time_elapsed = 4826.896   time_remaining = 1946\n",
      "Epoch 2139 Batch    6/6   train_loss = 0.108   time_elapsed = 4829.071   time_remaining = 1944\n",
      "Epoch 2140 Batch    6/6   train_loss = 0.113   time_elapsed = 4831.246   time_remaining = 1942\n",
      "Epoch 2141 Batch    6/6   train_loss = 0.115   time_elapsed = 4833.408   time_remaining = 1939\n",
      "Model Trained and Saved\n",
      "Epoch 2142 Batch    6/6   train_loss = 0.111   time_elapsed = 4836.532   time_remaining = 1937\n",
      "Epoch 2143 Batch    6/6   train_loss = 0.109   time_elapsed = 4838.693   time_remaining = 1935\n",
      "Epoch 2144 Batch    6/6   train_loss = 0.114   time_elapsed = 4840.865   time_remaining = 1933\n",
      "Epoch 2145 Batch    6/6   train_loss = 0.113   time_elapsed = 4843.029   time_remaining = 1930\n",
      "Epoch 2146 Batch    6/6   train_loss = 0.106   time_elapsed = 4845.190   time_remaining = 1928\n",
      "Epoch 2147 Batch    6/6   train_loss = 0.114   time_elapsed = 4847.353   time_remaining = 1926\n",
      "Epoch 2148 Batch    6/6   train_loss = 0.116   time_elapsed = 4849.518   time_remaining = 1924\n",
      "Epoch 2149 Batch    6/6   train_loss = 0.110   time_elapsed = 4851.681   time_remaining = 1921\n",
      "Epoch 2150 Batch    6/6   train_loss = 0.112   time_elapsed = 4853.851   time_remaining = 1919\n",
      "Epoch 2151 Batch    6/6   train_loss = 0.118   time_elapsed = 4856.015   time_remaining = 1917\n",
      "Model Trained and Saved\n",
      "Epoch 2152 Batch    6/6   train_loss = 0.112   time_elapsed = 4859.269   time_remaining = 1915\n",
      "Epoch 2153 Batch    6/6   train_loss = 0.120   time_elapsed = 4861.428   time_remaining = 1913\n",
      "Epoch 2154 Batch    6/6   train_loss = 0.111   time_elapsed = 4863.596   time_remaining = 1910\n",
      "Epoch 2155 Batch    6/6   train_loss = 0.115   time_elapsed = 4865.761   time_remaining = 1908\n",
      "Epoch 2156 Batch    6/6   train_loss = 0.112   time_elapsed = 4867.922   time_remaining = 1906\n",
      "Epoch 2157 Batch    6/6   train_loss = 0.116   time_elapsed = 4870.093   time_remaining = 1903\n",
      "Epoch 2158 Batch    6/6   train_loss = 0.118   time_elapsed = 4872.257   time_remaining = 1901\n",
      "Epoch 2159 Batch    6/6   train_loss = 0.115   time_elapsed = 4874.429   time_remaining = 1899\n",
      "Epoch 2160 Batch    6/6   train_loss = 0.110   time_elapsed = 4876.601   time_remaining = 1896\n",
      "Epoch 2161 Batch    6/6   train_loss = 0.110   time_elapsed = 4878.768   time_remaining = 1894\n",
      "Model Trained and Saved\n",
      "Epoch 2162 Batch    6/6   train_loss = 0.110   time_elapsed = 4881.933   time_remaining = 1892\n",
      "Epoch 2163 Batch    6/6   train_loss = 0.111   time_elapsed = 4884.104   time_remaining = 1890\n",
      "Epoch 2164 Batch    6/6   train_loss = 0.118   time_elapsed = 4886.269   time_remaining = 1888\n",
      "Epoch 2165 Batch    6/6   train_loss = 0.113   time_elapsed = 4888.431   time_remaining = 1885\n",
      "Epoch 2166 Batch    6/6   train_loss = 0.107   time_elapsed = 4890.600   time_remaining = 1883\n",
      "Epoch 2167 Batch    6/6   train_loss = 0.111   time_elapsed = 4892.768   time_remaining = 1881\n",
      "Epoch 2168 Batch    6/6   train_loss = 0.106   time_elapsed = 4894.938   time_remaining = 1879\n",
      "Epoch 2169 Batch    6/6   train_loss = 0.108   time_elapsed = 4897.115   time_remaining = 1876\n",
      "Epoch 2170 Batch    6/6   train_loss = 0.106   time_elapsed = 4899.275   time_remaining = 1874\n",
      "Epoch 2171 Batch    6/6   train_loss = 0.112   time_elapsed = 4901.446   time_remaining = 1872\n",
      "Model Trained and Saved\n",
      "Epoch 2172 Batch    6/6   train_loss = 0.113   time_elapsed = 4904.607   time_remaining = 1870\n",
      "Epoch 2173 Batch    6/6   train_loss = 0.113   time_elapsed = 4906.776   time_remaining = 1867\n",
      "Epoch 2174 Batch    6/6   train_loss = 0.107   time_elapsed = 4908.952   time_remaining = 1865\n",
      "Epoch 2175 Batch    6/6   train_loss = 0.112   time_elapsed = 4911.119   time_remaining = 1863\n",
      "Epoch 2176 Batch    6/6   train_loss = 0.106   time_elapsed = 4913.284   time_remaining = 1861\n",
      "Epoch 2177 Batch    6/6   train_loss = 0.117   time_elapsed = 4915.445   time_remaining = 1858\n",
      "Epoch 2178 Batch    6/6   train_loss = 0.116   time_elapsed = 4917.617   time_remaining = 1856\n",
      "Epoch 2179 Batch    6/6   train_loss = 0.113   time_elapsed = 4919.786   time_remaining = 1854\n",
      "Epoch 2180 Batch    6/6   train_loss = 0.110   time_elapsed = 4921.952   time_remaining = 1851\n",
      "Epoch 2181 Batch    6/6   train_loss = 0.109   time_elapsed = 4924.130   time_remaining = 1849\n",
      "Model Trained and Saved\n",
      "Epoch 2182 Batch    6/6   train_loss = 0.110   time_elapsed = 4927.329   time_remaining = 1847\n",
      "Epoch 2183 Batch    6/6   train_loss = 0.107   time_elapsed = 4929.484   time_remaining = 1845\n",
      "Epoch 2184 Batch    6/6   train_loss = 0.111   time_elapsed = 4931.656   time_remaining = 1843\n",
      "Epoch 2185 Batch    6/6   train_loss = 0.113   time_elapsed = 4933.822   time_remaining = 1840\n",
      "Epoch 2186 Batch    6/6   train_loss = 0.115   time_elapsed = 4935.986   time_remaining = 1838\n",
      "Epoch 2187 Batch    6/6   train_loss = 0.105   time_elapsed = 4938.153   time_remaining = 1836\n",
      "Epoch 2188 Batch    6/6   train_loss = 0.109   time_elapsed = 4940.317   time_remaining = 1833\n",
      "Epoch 2189 Batch    6/6   train_loss = 0.106   time_elapsed = 4942.489   time_remaining = 1831\n",
      "Epoch 2190 Batch    6/6   train_loss = 0.107   time_elapsed = 4944.656   time_remaining = 1829\n",
      "Epoch 2191 Batch    6/6   train_loss = 0.112   time_elapsed = 4946.824   time_remaining = 1827\n",
      "Model Trained and Saved\n",
      "Epoch 2192 Batch    6/6   train_loss = 0.109   time_elapsed = 4949.994   time_remaining = 1825\n",
      "Epoch 2193 Batch    6/6   train_loss = 0.110   time_elapsed = 4952.159   time_remaining = 1822\n",
      "Epoch 2194 Batch    6/6   train_loss = 0.114   time_elapsed = 4954.318   time_remaining = 1820\n",
      "Epoch 2195 Batch    6/6   train_loss = 0.107   time_elapsed = 4956.485   time_remaining = 1818\n",
      "Epoch 2196 Batch    6/6   train_loss = 0.106   time_elapsed = 4958.655   time_remaining = 1815\n",
      "Epoch 2197 Batch    6/6   train_loss = 0.108   time_elapsed = 4960.823   time_remaining = 1813\n",
      "Epoch 2198 Batch    6/6   train_loss = 0.107   time_elapsed = 4962.998   time_remaining = 1811\n",
      "Epoch 2199 Batch    6/6   train_loss = 0.108   time_elapsed = 4965.166   time_remaining = 1809\n",
      "Epoch 2200 Batch    6/6   train_loss = 0.104   time_elapsed = 4967.334   time_remaining = 1806\n",
      "Epoch 2201 Batch    6/6   train_loss = 0.110   time_elapsed = 4969.507   time_remaining = 1804\n",
      "Model Trained and Saved\n",
      "Epoch 2202 Batch    6/6   train_loss = 0.110   time_elapsed = 4972.683   time_remaining = 1802\n",
      "Epoch 2203 Batch    6/6   train_loss = 0.109   time_elapsed = 4974.851   time_remaining = 1800\n",
      "Epoch 2204 Batch    6/6   train_loss = 0.114   time_elapsed = 4977.019   time_remaining = 1798\n",
      "Epoch 2205 Batch    6/6   train_loss = 0.107   time_elapsed = 4979.190   time_remaining = 1795\n",
      "Epoch 2206 Batch    6/6   train_loss = 0.110   time_elapsed = 4981.367   time_remaining = 1793\n",
      "Epoch 2207 Batch    6/6   train_loss = 0.109   time_elapsed = 4983.540   time_remaining = 1791\n",
      "Epoch 2208 Batch    6/6   train_loss = 0.099   time_elapsed = 4985.706   time_remaining = 1788\n",
      "Epoch 2209 Batch    6/6   train_loss = 0.109   time_elapsed = 4987.884   time_remaining = 1786\n",
      "Epoch 2210 Batch    6/6   train_loss = 0.110   time_elapsed = 4990.060   time_remaining = 1784\n",
      "Epoch 2211 Batch    6/6   train_loss = 0.112   time_elapsed = 4992.221   time_remaining = 1781\n",
      "Model Trained and Saved\n",
      "Epoch 2212 Batch    6/6   train_loss = 0.109   time_elapsed = 4995.533   time_remaining = 1780\n",
      "Epoch 2213 Batch    6/6   train_loss = 0.107   time_elapsed = 4997.700   time_remaining = 1777\n",
      "Epoch 2214 Batch    6/6   train_loss = 0.113   time_elapsed = 4999.869   time_remaining = 1775\n",
      "Epoch 2215 Batch    6/6   train_loss = 0.105   time_elapsed = 5002.039   time_remaining = 1773\n",
      "Epoch 2216 Batch    6/6   train_loss = 0.104   time_elapsed = 5004.207   time_remaining = 1770\n",
      "Epoch 2217 Batch    6/6   train_loss = 0.105   time_elapsed = 5006.374   time_remaining = 1768\n",
      "Epoch 2218 Batch    6/6   train_loss = 0.106   time_elapsed = 5008.551   time_remaining = 1766\n",
      "Epoch 2219 Batch    6/6   train_loss = 0.110   time_elapsed = 5010.722   time_remaining = 1764\n",
      "Epoch 2220 Batch    6/6   train_loss = 0.110   time_elapsed = 5012.891   time_remaining = 1761\n",
      "Epoch 2221 Batch    6/6   train_loss = 0.106   time_elapsed = 5015.053   time_remaining = 1759\n",
      "Model Trained and Saved\n",
      "Epoch 2222 Batch    6/6   train_loss = 0.111   time_elapsed = 5018.344   time_remaining = 1757\n",
      "Epoch 2223 Batch    6/6   train_loss = 0.112   time_elapsed = 5020.515   time_remaining = 1755\n",
      "Epoch 2224 Batch    6/6   train_loss = 0.107   time_elapsed = 5022.682   time_remaining = 1753\n",
      "Epoch 2225 Batch    6/6   train_loss = 0.114   time_elapsed = 5024.851   time_remaining = 1750\n",
      "Epoch 2226 Batch    6/6   train_loss = 0.107   time_elapsed = 5027.020   time_remaining = 1748\n",
      "Epoch 2227 Batch    6/6   train_loss = 0.106   time_elapsed = 5029.196   time_remaining = 1746\n",
      "Epoch 2228 Batch    6/6   train_loss = 0.108   time_elapsed = 5031.359   time_remaining = 1743\n",
      "Epoch 2229 Batch    6/6   train_loss = 0.109   time_elapsed = 5033.523   time_remaining = 1741\n",
      "Epoch 2230 Batch    6/6   train_loss = 0.109   time_elapsed = 5035.700   time_remaining = 1739\n",
      "Epoch 2231 Batch    6/6   train_loss = 0.110   time_elapsed = 5037.864   time_remaining = 1736\n",
      "Model Trained and Saved\n",
      "Epoch 2232 Batch    6/6   train_loss = 0.112   time_elapsed = 5041.034   time_remaining = 1735\n",
      "Epoch 2233 Batch    6/6   train_loss = 0.116   time_elapsed = 5043.208   time_remaining = 1732\n",
      "Epoch 2234 Batch    6/6   train_loss = 0.107   time_elapsed = 5045.378   time_remaining = 1730\n",
      "Epoch 2235 Batch    6/6   train_loss = 0.109   time_elapsed = 5047.552   time_remaining = 1728\n",
      "Epoch 2236 Batch    6/6   train_loss = 0.104   time_elapsed = 5049.720   time_remaining = 1725\n",
      "Epoch 2237 Batch    6/6   train_loss = 0.106   time_elapsed = 5051.885   time_remaining = 1723\n",
      "Epoch 2238 Batch    6/6   train_loss = 0.107   time_elapsed = 5054.053   time_remaining = 1721\n",
      "Epoch 2239 Batch    6/6   train_loss = 0.109   time_elapsed = 5056.218   time_remaining = 1719\n",
      "Epoch 2240 Batch    6/6   train_loss = 0.109   time_elapsed = 5058.390   time_remaining = 1716\n",
      "Epoch 2241 Batch    6/6   train_loss = 0.107   time_elapsed = 5060.561   time_remaining = 1714\n",
      "Model Trained and Saved\n",
      "Epoch 2242 Batch    6/6   train_loss = 0.103   time_elapsed = 5063.722   time_remaining = 1712\n",
      "Epoch 2243 Batch    6/6   train_loss = 0.106   time_elapsed = 5065.894   time_remaining = 1710\n",
      "Epoch 2244 Batch    6/6   train_loss = 0.103   time_elapsed = 5068.056   time_remaining = 1707\n",
      "Epoch 2245 Batch    6/6   train_loss = 0.105   time_elapsed = 5070.224   time_remaining = 1705\n",
      "Epoch 2246 Batch    6/6   train_loss = 0.106   time_elapsed = 5072.390   time_remaining = 1703\n",
      "Epoch 2247 Batch    6/6   train_loss = 0.108   time_elapsed = 5074.573   time_remaining = 1701\n",
      "Epoch 2248 Batch    6/6   train_loss = 0.107   time_elapsed = 5076.738   time_remaining = 1698\n",
      "Epoch 2249 Batch    6/6   train_loss = 0.106   time_elapsed = 5078.908   time_remaining = 1696\n",
      "Epoch 2250 Batch    6/6   train_loss = 0.107   time_elapsed = 5081.082   time_remaining = 1694\n",
      "Epoch 2251 Batch    6/6   train_loss = 0.107   time_elapsed = 5083.254   time_remaining = 1691\n",
      "Model Trained and Saved\n",
      "Epoch 2252 Batch    6/6   train_loss = 0.111   time_elapsed = 5086.417   time_remaining = 1689\n",
      "Epoch 2253 Batch    6/6   train_loss = 0.100   time_elapsed = 5088.580   time_remaining = 1687\n",
      "Epoch 2254 Batch    6/6   train_loss = 0.104   time_elapsed = 5090.747   time_remaining = 1685\n",
      "Epoch 2255 Batch    6/6   train_loss = 0.099   time_elapsed = 5092.917   time_remaining = 1683\n",
      "Epoch 2256 Batch    6/6   train_loss = 0.107   time_elapsed = 5095.089   time_remaining = 1680\n",
      "Epoch 2257 Batch    6/6   train_loss = 0.109   time_elapsed = 5097.263   time_remaining = 1678\n",
      "Epoch 2258 Batch    6/6   train_loss = 0.107   time_elapsed = 5099.433   time_remaining = 1676\n",
      "Epoch 2259 Batch    6/6   train_loss = 0.110   time_elapsed = 5101.603   time_remaining = 1673\n",
      "Epoch 2260 Batch    6/6   train_loss = 0.109   time_elapsed = 5103.774   time_remaining = 1671\n",
      "Epoch 2261 Batch    6/6   train_loss = 0.108   time_elapsed = 5105.948   time_remaining = 1669\n",
      "Model Trained and Saved\n",
      "Epoch 2262 Batch    6/6   train_loss = 0.105   time_elapsed = 5109.127   time_remaining = 1667\n",
      "Epoch 2263 Batch    6/6   train_loss = 0.113   time_elapsed = 5111.297   time_remaining = 1665\n",
      "Epoch 2264 Batch    6/6   train_loss = 0.110   time_elapsed = 5113.464   time_remaining = 1662\n",
      "Epoch 2265 Batch    6/6   train_loss = 0.110   time_elapsed = 5115.628   time_remaining = 1660\n",
      "Epoch 2266 Batch    6/6   train_loss = 0.107   time_elapsed = 5117.793   time_remaining = 1658\n",
      "Epoch 2267 Batch    6/6   train_loss = 0.105   time_elapsed = 5119.957   time_remaining = 1655\n",
      "Epoch 2268 Batch    6/6   train_loss = 0.110   time_elapsed = 5122.124   time_remaining = 1653\n",
      "Epoch 2269 Batch    6/6   train_loss = 0.103   time_elapsed = 5124.293   time_remaining = 1651\n",
      "Epoch 2270 Batch    6/6   train_loss = 0.105   time_elapsed = 5126.469   time_remaining = 1649\n",
      "Epoch 2271 Batch    6/6   train_loss = 0.108   time_elapsed = 5128.633   time_remaining = 1646\n",
      "Model Trained and Saved\n",
      "Epoch 2272 Batch    6/6   train_loss = 0.102   time_elapsed = 5131.821   time_remaining = 1644\n",
      "Epoch 2273 Batch    6/6   train_loss = 0.103   time_elapsed = 5133.997   time_remaining = 1642\n",
      "Epoch 2274 Batch    6/6   train_loss = 0.110   time_elapsed = 5136.163   time_remaining = 1640\n",
      "Epoch 2275 Batch    6/6   train_loss = 0.102   time_elapsed = 5138.336   time_remaining = 1637\n",
      "Epoch 2276 Batch    6/6   train_loss = 0.103   time_elapsed = 5140.508   time_remaining = 1635\n",
      "Epoch 2277 Batch    6/6   train_loss = 0.102   time_elapsed = 5142.673   time_remaining = 1633\n",
      "Epoch 2278 Batch    6/6   train_loss = 0.105   time_elapsed = 5144.843   time_remaining = 1631\n",
      "Epoch 2279 Batch    6/6   train_loss = 0.106   time_elapsed = 5147.008   time_remaining = 1628\n",
      "Epoch 2280 Batch    6/6   train_loss = 0.105   time_elapsed = 5149.182   time_remaining = 1626\n",
      "Epoch 2281 Batch    6/6   train_loss = 0.103   time_elapsed = 5151.349   time_remaining = 1624\n",
      "Model Trained and Saved\n",
      "Epoch 2282 Batch    6/6   train_loss = 0.100   time_elapsed = 5154.518   time_remaining = 1622\n",
      "Epoch 2283 Batch    6/6   train_loss = 0.108   time_elapsed = 5156.690   time_remaining = 1620\n",
      "Epoch 2284 Batch    6/6   train_loss = 0.104   time_elapsed = 5158.859   time_remaining = 1617\n",
      "Epoch 2285 Batch    6/6   train_loss = 0.107   time_elapsed = 5161.029   time_remaining = 1615\n",
      "Epoch 2286 Batch    6/6   train_loss = 0.104   time_elapsed = 5163.201   time_remaining = 1613\n",
      "Epoch 2287 Batch    6/6   train_loss = 0.106   time_elapsed = 5165.368   time_remaining = 1610\n",
      "Epoch 2288 Batch    6/6   train_loss = 0.105   time_elapsed = 5167.532   time_remaining = 1608\n",
      "Epoch 2289 Batch    6/6   train_loss = 0.107   time_elapsed = 5169.697   time_remaining = 1606\n",
      "Epoch 2290 Batch    6/6   train_loss = 0.112   time_elapsed = 5171.868   time_remaining = 1604\n",
      "Epoch 2291 Batch    6/6   train_loss = 0.105   time_elapsed = 5174.035   time_remaining = 1601\n",
      "Model Trained and Saved\n",
      "Epoch 2292 Batch    6/6   train_loss = 0.111   time_elapsed = 5177.449   time_remaining = 1599\n",
      "Epoch 2293 Batch    6/6   train_loss = 0.106   time_elapsed = 5179.622   time_remaining = 1597\n",
      "Epoch 2294 Batch    6/6   train_loss = 0.108   time_elapsed = 5181.786   time_remaining = 1595\n",
      "Epoch 2295 Batch    6/6   train_loss = 0.102   time_elapsed = 5183.946   time_remaining = 1592\n",
      "Epoch 2296 Batch    6/6   train_loss = 0.102   time_elapsed = 5186.107   time_remaining = 1590\n",
      "Epoch 2297 Batch    6/6   train_loss = 0.108   time_elapsed = 5188.275   time_remaining = 1588\n",
      "Epoch 2298 Batch    6/6   train_loss = 0.102   time_elapsed = 5190.447   time_remaining = 1586\n",
      "Epoch 2299 Batch    6/6   train_loss = 0.108   time_elapsed = 5192.617   time_remaining = 1583\n",
      "Epoch 2300 Batch    6/6   train_loss = 0.108   time_elapsed = 5194.788   time_remaining = 1581\n",
      "Epoch 2301 Batch    6/6   train_loss = 0.109   time_elapsed = 5196.955   time_remaining = 1579\n",
      "Model Trained and Saved\n",
      "Epoch 2302 Batch    6/6   train_loss = 0.109   time_elapsed = 5200.276   time_remaining = 1577\n",
      "Epoch 2303 Batch    6/6   train_loss = 0.108   time_elapsed = 5202.445   time_remaining = 1575\n",
      "Epoch 2304 Batch    6/6   train_loss = 0.106   time_elapsed = 5204.619   time_remaining = 1572\n",
      "Epoch 2305 Batch    6/6   train_loss = 0.112   time_elapsed = 5206.780   time_remaining = 1570\n",
      "Epoch 2306 Batch    6/6   train_loss = 0.110   time_elapsed = 5208.947   time_remaining = 1568\n",
      "Epoch 2307 Batch    6/6   train_loss = 0.104   time_elapsed = 5211.115   time_remaining = 1565\n",
      "Epoch 2308 Batch    6/6   train_loss = 0.106   time_elapsed = 5213.289   time_remaining = 1563\n",
      "Epoch 2309 Batch    6/6   train_loss = 0.106   time_elapsed = 5215.465   time_remaining = 1561\n",
      "Epoch 2310 Batch    6/6   train_loss = 0.103   time_elapsed = 5217.629   time_remaining = 1559\n",
      "Epoch 2311 Batch    6/6   train_loss = 0.104   time_elapsed = 5219.791   time_remaining = 1556\n",
      "Model Trained and Saved\n",
      "Epoch 2312 Batch    6/6   train_loss = 0.100   time_elapsed = 5223.213   time_remaining = 1554\n",
      "Epoch 2313 Batch    6/6   train_loss = 0.106   time_elapsed = 5225.387   time_remaining = 1552\n",
      "Epoch 2314 Batch    6/6   train_loss = 0.109   time_elapsed = 5227.553   time_remaining = 1550\n",
      "Epoch 2315 Batch    6/6   train_loss = 0.107   time_elapsed = 5229.725   time_remaining = 1547\n",
      "Epoch 2316 Batch    6/6   train_loss = 0.101   time_elapsed = 5231.890   time_remaining = 1545\n",
      "Epoch 2317 Batch    6/6   train_loss = 0.104   time_elapsed = 5234.060   time_remaining = 1543\n",
      "Epoch 2318 Batch    6/6   train_loss = 0.101   time_elapsed = 5236.235   time_remaining = 1541\n",
      "Epoch 2319 Batch    6/6   train_loss = 0.097   time_elapsed = 5238.409   time_remaining = 1538\n",
      "Epoch 2320 Batch    6/6   train_loss = 0.106   time_elapsed = 5240.579   time_remaining = 1536\n",
      "Epoch 2321 Batch    6/6   train_loss = 0.099   time_elapsed = 5242.746   time_remaining = 1534\n",
      "Model Trained and Saved\n",
      "Epoch 2322 Batch    6/6   train_loss = 0.108   time_elapsed = 5245.945   time_remaining = 1532\n",
      "Epoch 2323 Batch    6/6   train_loss = 0.104   time_elapsed = 5248.115   time_remaining = 1529\n",
      "Epoch 2324 Batch    6/6   train_loss = 0.102   time_elapsed = 5250.284   time_remaining = 1527\n",
      "Epoch 2325 Batch    6/6   train_loss = 0.107   time_elapsed = 5252.451   time_remaining = 1525\n",
      "Epoch 2326 Batch    6/6   train_loss = 0.105   time_elapsed = 5254.617   time_remaining = 1523\n",
      "Epoch 2327 Batch    6/6   train_loss = 0.105   time_elapsed = 5256.779   time_remaining = 1520\n",
      "Epoch 2328 Batch    6/6   train_loss = 0.104   time_elapsed = 5258.952   time_remaining = 1518\n",
      "Epoch 2329 Batch    6/6   train_loss = 0.109   time_elapsed = 5261.116   time_remaining = 1516\n",
      "Epoch 2330 Batch    6/6   train_loss = 0.104   time_elapsed = 5263.284   time_remaining = 1513\n",
      "Epoch 2331 Batch    6/6   train_loss = 0.107   time_elapsed = 5265.456   time_remaining = 1511\n",
      "Model Trained and Saved\n",
      "Epoch 2332 Batch    6/6   train_loss = 0.106   time_elapsed = 5268.799   time_remaining = 1509\n",
      "Epoch 2333 Batch    6/6   train_loss = 0.105   time_elapsed = 5270.980   time_remaining = 1507\n",
      "Epoch 2334 Batch    6/6   train_loss = 0.108   time_elapsed = 5273.143   time_remaining = 1505\n",
      "Epoch 2335 Batch    6/6   train_loss = 0.101   time_elapsed = 5275.309   time_remaining = 1502\n",
      "Epoch 2336 Batch    6/6   train_loss = 0.106   time_elapsed = 5277.471   time_remaining = 1500\n",
      "Epoch 2337 Batch    6/6   train_loss = 0.112   time_elapsed = 5279.637   time_remaining = 1498\n",
      "Epoch 2338 Batch    6/6   train_loss = 0.106   time_elapsed = 5281.800   time_remaining = 1496\n",
      "Epoch 2339 Batch    6/6   train_loss = 0.109   time_elapsed = 5283.969   time_remaining = 1493\n",
      "Epoch 2340 Batch    6/6   train_loss = 0.118   time_elapsed = 5286.146   time_remaining = 1491\n",
      "Epoch 2341 Batch    6/6   train_loss = 0.110   time_elapsed = 5288.317   time_remaining = 1489\n",
      "Model Trained and Saved\n",
      "Epoch 2342 Batch    6/6   train_loss = 0.108   time_elapsed = 5291.635   time_remaining = 1487\n",
      "Epoch 2343 Batch    6/6   train_loss = 0.105   time_elapsed = 5293.809   time_remaining = 1484\n",
      "Epoch 2344 Batch    6/6   train_loss = 0.106   time_elapsed = 5295.978   time_remaining = 1482\n",
      "Epoch 2345 Batch    6/6   train_loss = 0.105   time_elapsed = 5298.142   time_remaining = 1480\n",
      "Epoch 2346 Batch    6/6   train_loss = 0.107   time_elapsed = 5300.317   time_remaining = 1478\n",
      "Epoch 2347 Batch    6/6   train_loss = 0.103   time_elapsed = 5302.477   time_remaining = 1475\n",
      "Epoch 2348 Batch    6/6   train_loss = 0.102   time_elapsed = 5304.641   time_remaining = 1473\n",
      "Epoch 2349 Batch    6/6   train_loss = 0.109   time_elapsed = 5306.809   time_remaining = 1471\n",
      "Epoch 2350 Batch    6/6   train_loss = 0.107   time_elapsed = 5308.974   time_remaining = 1468\n",
      "Epoch 2351 Batch    6/6   train_loss = 0.102   time_elapsed = 5311.142   time_remaining = 1466\n",
      "Model Trained and Saved\n",
      "Epoch 2352 Batch    6/6   train_loss = 0.103   time_elapsed = 5314.330   time_remaining = 1464\n",
      "Epoch 2353 Batch    6/6   train_loss = 0.108   time_elapsed = 5316.492   time_remaining = 1462\n",
      "Epoch 2354 Batch    6/6   train_loss = 0.107   time_elapsed = 5318.666   time_remaining = 1460\n",
      "Epoch 2355 Batch    6/6   train_loss = 0.109   time_elapsed = 5320.841   time_remaining = 1457\n",
      "Epoch 2356 Batch    6/6   train_loss = 0.100   time_elapsed = 5323.014   time_remaining = 1455\n",
      "Epoch 2357 Batch    6/6   train_loss = 0.105   time_elapsed = 5325.185   time_remaining = 1453\n",
      "Epoch 2358 Batch    6/6   train_loss = 0.104   time_elapsed = 5327.353   time_remaining = 1450\n",
      "Epoch 2359 Batch    6/6   train_loss = 0.104   time_elapsed = 5329.515   time_remaining = 1448\n",
      "Epoch 2360 Batch    6/6   train_loss = 0.108   time_elapsed = 5331.674   time_remaining = 1446\n",
      "Epoch 2361 Batch    6/6   train_loss = 0.099   time_elapsed = 5333.848   time_remaining = 1444\n",
      "Model Trained and Saved\n",
      "Epoch 2362 Batch    6/6   train_loss = 0.105   time_elapsed = 5337.071   time_remaining = 1442\n",
      "Epoch 2363 Batch    6/6   train_loss = 0.104   time_elapsed = 5339.241   time_remaining = 1439\n",
      "Epoch 2364 Batch    6/6   train_loss = 0.107   time_elapsed = 5341.402   time_remaining = 1437\n",
      "Epoch 2365 Batch    6/6   train_loss = 0.106   time_elapsed = 5343.565   time_remaining = 1435\n",
      "Epoch 2366 Batch    6/6   train_loss = 0.100   time_elapsed = 5345.732   time_remaining = 1432\n",
      "Epoch 2367 Batch    6/6   train_loss = 0.100   time_elapsed = 5347.905   time_remaining = 1430\n",
      "Epoch 2368 Batch    6/6   train_loss = 0.105   time_elapsed = 5350.072   time_remaining = 1428\n",
      "Epoch 2369 Batch    6/6   train_loss = 0.102   time_elapsed = 5352.243   time_remaining = 1426\n",
      "Epoch 2370 Batch    6/6   train_loss = 0.102   time_elapsed = 5354.410   time_remaining = 1423\n",
      "Epoch 2371 Batch    6/6   train_loss = 0.094   time_elapsed = 5356.579   time_remaining = 1421\n",
      "Model Trained and Saved\n",
      "Epoch 2372 Batch    6/6   train_loss = 0.104   time_elapsed = 5359.996   time_remaining = 1419\n",
      "Epoch 2373 Batch    6/6   train_loss = 0.101   time_elapsed = 5362.165   time_remaining = 1417\n",
      "Epoch 2374 Batch    6/6   train_loss = 0.103   time_elapsed = 5364.334   time_remaining = 1415\n",
      "Epoch 2375 Batch    6/6   train_loss = 0.099   time_elapsed = 5366.499   time_remaining = 1412\n",
      "Epoch 2376 Batch    6/6   train_loss = 0.101   time_elapsed = 5368.666   time_remaining = 1410\n",
      "Epoch 2377 Batch    6/6   train_loss = 0.103   time_elapsed = 5370.834   time_remaining = 1408\n",
      "Epoch 2378 Batch    6/6   train_loss = 0.098   time_elapsed = 5373.014   time_remaining = 1405\n",
      "Epoch 2379 Batch    6/6   train_loss = 0.106   time_elapsed = 5375.177   time_remaining = 1403\n",
      "Epoch 2380 Batch    6/6   train_loss = 0.100   time_elapsed = 5377.350   time_remaining = 1401\n",
      "Epoch 2381 Batch    6/6   train_loss = 0.104   time_elapsed = 5379.521   time_remaining = 1399\n",
      "Model Trained and Saved\n",
      "Epoch 2382 Batch    6/6   train_loss = 0.103   time_elapsed = 5382.840   time_remaining = 1397\n",
      "Epoch 2383 Batch    6/6   train_loss = 0.103   time_elapsed = 5385.014   time_remaining = 1394\n",
      "Epoch 2384 Batch    6/6   train_loss = 0.102   time_elapsed = 5387.185   time_remaining = 1392\n",
      "Epoch 2385 Batch    6/6   train_loss = 0.101   time_elapsed = 5389.359   time_remaining = 1390\n",
      "Epoch 2386 Batch    6/6   train_loss = 0.100   time_elapsed = 5391.527   time_remaining = 1387\n",
      "Epoch 2387 Batch    6/6   train_loss = 0.103   time_elapsed = 5393.702   time_remaining = 1385\n",
      "Epoch 2388 Batch    6/6   train_loss = 0.104   time_elapsed = 5395.876   time_remaining = 1383\n",
      "Epoch 2389 Batch    6/6   train_loss = 0.106   time_elapsed = 5398.044   time_remaining = 1381\n",
      "Epoch 2390 Batch    6/6   train_loss = 0.099   time_elapsed = 5400.210   time_remaining = 1378\n",
      "Epoch 2391 Batch    6/6   train_loss = 0.101   time_elapsed = 5402.386   time_remaining = 1376\n",
      "Model Trained and Saved\n",
      "Epoch 2392 Batch    6/6   train_loss = 0.108   time_elapsed = 5405.834   time_remaining = 1374\n",
      "Epoch 2393 Batch    6/6   train_loss = 0.096   time_elapsed = 5407.999   time_remaining = 1372\n",
      "Epoch 2394 Batch    6/6   train_loss = 0.104   time_elapsed = 5410.174   time_remaining = 1369\n",
      "Epoch 2395 Batch    6/6   train_loss = 0.104   time_elapsed = 5412.341   time_remaining = 1367\n",
      "Epoch 2396 Batch    6/6   train_loss = 0.100   time_elapsed = 5414.513   time_remaining = 1365\n",
      "Epoch 2397 Batch    6/6   train_loss = 0.100   time_elapsed = 5416.677   time_remaining = 1363\n",
      "Epoch 2398 Batch    6/6   train_loss = 0.099   time_elapsed = 5418.845   time_remaining = 1360\n",
      "Epoch 2399 Batch    6/6   train_loss = 0.104   time_elapsed = 5421.009   time_remaining = 1358\n",
      "Epoch 2400 Batch    6/6   train_loss = 0.097   time_elapsed = 5423.174   time_remaining = 1356\n",
      "Epoch 2401 Batch    6/6   train_loss = 0.105   time_elapsed = 5425.351   time_remaining = 1354\n",
      "Model Trained and Saved\n",
      "Epoch 2402 Batch    6/6   train_loss = 0.105   time_elapsed = 5428.804   time_remaining = 1352\n",
      "Epoch 2403 Batch    6/6   train_loss = 0.096   time_elapsed = 5430.971   time_remaining = 1349\n",
      "Epoch 2404 Batch    6/6   train_loss = 0.102   time_elapsed = 5433.143   time_remaining = 1347\n",
      "Epoch 2405 Batch    6/6   train_loss = 0.103   time_elapsed = 5435.310   time_remaining = 1345\n",
      "Epoch 2406 Batch    6/6   train_loss = 0.103   time_elapsed = 5437.478   time_remaining = 1342\n",
      "Epoch 2407 Batch    6/6   train_loss = 0.105   time_elapsed = 5439.640   time_remaining = 1340\n",
      "Epoch 2408 Batch    6/6   train_loss = 0.102   time_elapsed = 5441.817   time_remaining = 1338\n",
      "Epoch 2409 Batch    6/6   train_loss = 0.101   time_elapsed = 5443.986   time_remaining = 1336\n",
      "Epoch 2410 Batch    6/6   train_loss = 0.105   time_elapsed = 5446.158   time_remaining = 1333\n",
      "Epoch 2411 Batch    6/6   train_loss = 0.103   time_elapsed = 5448.327   time_remaining = 1331\n",
      "Model Trained and Saved\n",
      "Epoch 2412 Batch    6/6   train_loss = 0.107   time_elapsed = 5451.536   time_remaining = 1329\n",
      "Epoch 2413 Batch    6/6   train_loss = 0.099   time_elapsed = 5453.711   time_remaining = 1327\n",
      "Epoch 2414 Batch    6/6   train_loss = 0.100   time_elapsed = 5455.883   time_remaining = 1324\n",
      "Epoch 2415 Batch    6/6   train_loss = 0.105   time_elapsed = 5458.055   time_remaining = 1322\n",
      "Epoch 2416 Batch    6/6   train_loss = 0.104   time_elapsed = 5460.226   time_remaining = 1320\n",
      "Epoch 2417 Batch    6/6   train_loss = 0.105   time_elapsed = 5462.399   time_remaining = 1318\n",
      "Epoch 2418 Batch    6/6   train_loss = 0.102   time_elapsed = 5464.562   time_remaining = 1315\n",
      "Epoch 2419 Batch    6/6   train_loss = 0.099   time_elapsed = 5466.732   time_remaining = 1313\n",
      "Epoch 2420 Batch    6/6   train_loss = 0.097   time_elapsed = 5468.907   time_remaining = 1311\n",
      "Epoch 2421 Batch    6/6   train_loss = 0.098   time_elapsed = 5471.076   time_remaining = 1308\n",
      "Model Trained and Saved\n",
      "Epoch 2422 Batch    6/6   train_loss = 0.098   time_elapsed = 5474.696   time_remaining = 1307\n",
      "Epoch 2423 Batch    6/6   train_loss = 0.096   time_elapsed = 5476.860   time_remaining = 1304\n",
      "Epoch 2424 Batch    6/6   train_loss = 0.098   time_elapsed = 5479.026   time_remaining = 1302\n",
      "Epoch 2425 Batch    6/6   train_loss = 0.103   time_elapsed = 5481.194   time_remaining = 1300\n",
      "Epoch 2426 Batch    6/6   train_loss = 0.107   time_elapsed = 5483.363   time_remaining = 1297\n",
      "Epoch 2427 Batch    6/6   train_loss = 0.102   time_elapsed = 5485.528   time_remaining = 1295\n",
      "Epoch 2428 Batch    6/6   train_loss = 0.102   time_elapsed = 5487.695   time_remaining = 1293\n",
      "Epoch 2429 Batch    6/6   train_loss = 0.097   time_elapsed = 5489.870   time_remaining = 1291\n",
      "Epoch 2430 Batch    6/6   train_loss = 0.099   time_elapsed = 5492.032   time_remaining = 1288\n",
      "Epoch 2431 Batch    6/6   train_loss = 0.104   time_elapsed = 5494.200   time_remaining = 1286\n",
      "Model Trained and Saved\n",
      "Epoch 2432 Batch    6/6   train_loss = 0.101   time_elapsed = 5497.712   time_remaining = 1284\n",
      "Epoch 2433 Batch    6/6   train_loss = 0.099   time_elapsed = 5499.877   time_remaining = 1282\n",
      "Epoch 2434 Batch    6/6   train_loss = 0.098   time_elapsed = 5502.042   time_remaining = 1279\n",
      "Epoch 2435 Batch    6/6   train_loss = 0.101   time_elapsed = 5504.205   time_remaining = 1277\n",
      "Epoch 2436 Batch    6/6   train_loss = 0.098   time_elapsed = 5506.366   time_remaining = 1275\n",
      "Epoch 2437 Batch    6/6   train_loss = 0.101   time_elapsed = 5508.527   time_remaining = 1273\n",
      "Epoch 2438 Batch    6/6   train_loss = 0.105   time_elapsed = 5510.694   time_remaining = 1270\n",
      "Epoch 2439 Batch    6/6   train_loss = 0.100   time_elapsed = 5512.859   time_remaining = 1268\n",
      "Epoch 2440 Batch    6/6   train_loss = 0.102   time_elapsed = 5515.032   time_remaining = 1266\n",
      "Epoch 2441 Batch    6/6   train_loss = 0.100   time_elapsed = 5517.198   time_remaining = 1263\n",
      "Model Trained and Saved\n",
      "Epoch 2442 Batch    6/6   train_loss = 0.103   time_elapsed = 5520.708   time_remaining = 1261\n",
      "Epoch 2443 Batch    6/6   train_loss = 0.092   time_elapsed = 5522.871   time_remaining = 1259\n",
      "Epoch 2444 Batch    6/6   train_loss = 0.097   time_elapsed = 5525.047   time_remaining = 1257\n",
      "Epoch 2445 Batch    6/6   train_loss = 0.107   time_elapsed = 5527.219   time_remaining = 1255\n",
      "Epoch 2446 Batch    6/6   train_loss = 0.102   time_elapsed = 5529.396   time_remaining = 1252\n",
      "Epoch 2447 Batch    6/6   train_loss = 0.102   time_elapsed = 5531.566   time_remaining = 1250\n",
      "Epoch 2448 Batch    6/6   train_loss = 0.100   time_elapsed = 5533.735   time_remaining = 1248\n",
      "Epoch 2449 Batch    6/6   train_loss = 0.104   time_elapsed = 5535.916   time_remaining = 1246\n",
      "Epoch 2450 Batch    6/6   train_loss = 0.096   time_elapsed = 5538.085   time_remaining = 1243\n",
      "Epoch 2451 Batch    6/6   train_loss = 0.103   time_elapsed = 5540.248   time_remaining = 1241\n",
      "Model Trained and Saved\n",
      "Epoch 2452 Batch    6/6   train_loss = 0.100   time_elapsed = 5543.488   time_remaining = 1239\n",
      "Epoch 2453 Batch    6/6   train_loss = 0.098   time_elapsed = 5545.644   time_remaining = 1237\n",
      "Epoch 2454 Batch    6/6   train_loss = 0.100   time_elapsed = 5547.814   time_remaining = 1234\n",
      "Epoch 2455 Batch    6/6   train_loss = 0.096   time_elapsed = 5549.982   time_remaining = 1232\n",
      "Epoch 2456 Batch    6/6   train_loss = 0.102   time_elapsed = 5552.150   time_remaining = 1230\n",
      "Epoch 2457 Batch    6/6   train_loss = 0.103   time_elapsed = 5554.316   time_remaining = 1228\n",
      "Epoch 2458 Batch    6/6   train_loss = 0.103   time_elapsed = 5556.478   time_remaining = 1225\n",
      "Epoch 2459 Batch    6/6   train_loss = 0.095   time_elapsed = 5558.645   time_remaining = 1223\n",
      "Epoch 2460 Batch    6/6   train_loss = 0.098   time_elapsed = 5560.819   time_remaining = 1221\n",
      "Epoch 2461 Batch    6/6   train_loss = 0.098   time_elapsed = 5562.986   time_remaining = 1218\n",
      "Model Trained and Saved\n",
      "Epoch 2462 Batch    6/6   train_loss = 0.096   time_elapsed = 5566.247   time_remaining = 1216\n",
      "Epoch 2463 Batch    6/6   train_loss = 0.099   time_elapsed = 5568.404   time_remaining = 1214\n",
      "Epoch 2464 Batch    6/6   train_loss = 0.102   time_elapsed = 5570.578   time_remaining = 1212\n",
      "Epoch 2465 Batch    6/6   train_loss = 0.102   time_elapsed = 5572.745   time_remaining = 1210\n",
      "Epoch 2466 Batch    6/6   train_loss = 0.101   time_elapsed = 5574.913   time_remaining = 1207\n",
      "Epoch 2467 Batch    6/6   train_loss = 0.093   time_elapsed = 5577.079   time_remaining = 1205\n",
      "Epoch 2468 Batch    6/6   train_loss = 0.097   time_elapsed = 5579.245   time_remaining = 1203\n",
      "Epoch 2469 Batch    6/6   train_loss = 0.094   time_elapsed = 5581.412   time_remaining = 1200\n",
      "Epoch 2470 Batch    6/6   train_loss = 0.101   time_elapsed = 5583.573   time_remaining = 1198\n",
      "Epoch 2471 Batch    6/6   train_loss = 0.103   time_elapsed = 5585.745   time_remaining = 1196\n",
      "Model Trained and Saved\n",
      "Epoch 2472 Batch    6/6   train_loss = 0.099   time_elapsed = 5589.240   time_remaining = 1194\n",
      "Epoch 2473 Batch    6/6   train_loss = 0.098   time_elapsed = 5591.400   time_remaining = 1192\n",
      "Epoch 2474 Batch    6/6   train_loss = 0.099   time_elapsed = 5593.580   time_remaining = 1189\n",
      "Epoch 2475 Batch    6/6   train_loss = 0.103   time_elapsed = 5595.749   time_remaining = 1187\n",
      "Epoch 2476 Batch    6/6   train_loss = 0.102   time_elapsed = 5597.923   time_remaining = 1185\n",
      "Epoch 2477 Batch    6/6   train_loss = 0.099   time_elapsed = 5600.099   time_remaining = 1182\n",
      "Epoch 2478 Batch    6/6   train_loss = 0.094   time_elapsed = 5602.270   time_remaining = 1180\n",
      "Epoch 2479 Batch    6/6   train_loss = 0.100   time_elapsed = 5604.439   time_remaining = 1178\n",
      "Epoch 2480 Batch    6/6   train_loss = 0.095   time_elapsed = 5606.613   time_remaining = 1176\n",
      "Epoch 2481 Batch    6/6   train_loss = 0.093   time_elapsed = 5608.784   time_remaining = 1173\n",
      "Model Trained and Saved\n",
      "Epoch 2482 Batch    6/6   train_loss = 0.097   time_elapsed = 5612.016   time_remaining = 1171\n",
      "Epoch 2483 Batch    6/6   train_loss = 0.094   time_elapsed = 5614.188   time_remaining = 1169\n",
      "Epoch 2484 Batch    6/6   train_loss = 0.097   time_elapsed = 5616.357   time_remaining = 1167\n",
      "Epoch 2485 Batch    6/6   train_loss = 0.098   time_elapsed = 5618.524   time_remaining = 1164\n",
      "Epoch 2486 Batch    6/6   train_loss = 0.098   time_elapsed = 5620.696   time_remaining = 1162\n",
      "Epoch 2487 Batch    6/6   train_loss = 0.099   time_elapsed = 5622.861   time_remaining = 1160\n",
      "Epoch 2488 Batch    6/6   train_loss = 0.098   time_elapsed = 5625.030   time_remaining = 1158\n",
      "Epoch 2489 Batch    6/6   train_loss = 0.101   time_elapsed = 5627.203   time_remaining = 1155\n",
      "Epoch 2490 Batch    6/6   train_loss = 0.092   time_elapsed = 5629.375   time_remaining = 1153\n",
      "Epoch 2491 Batch    6/6   train_loss = 0.100   time_elapsed = 5631.546   time_remaining = 1151\n",
      "Model Trained and Saved\n",
      "Epoch 2492 Batch    6/6   train_loss = 0.094   time_elapsed = 5634.931   time_remaining = 1149\n",
      "Epoch 2493 Batch    6/6   train_loss = 0.100   time_elapsed = 5637.092   time_remaining = 1146\n",
      "Epoch 2494 Batch    6/6   train_loss = 0.101   time_elapsed = 5639.266   time_remaining = 1144\n",
      "Epoch 2495 Batch    6/6   train_loss = 0.095   time_elapsed = 5641.431   time_remaining = 1142\n",
      "Epoch 2496 Batch    6/6   train_loss = 0.094   time_elapsed = 5643.597   time_remaining = 1140\n",
      "Epoch 2497 Batch    6/6   train_loss = 0.100   time_elapsed = 5645.762   time_remaining = 1137\n",
      "Epoch 2498 Batch    6/6   train_loss = 0.098   time_elapsed = 5647.926   time_remaining = 1135\n",
      "Epoch 2499 Batch    6/6   train_loss = 0.101   time_elapsed = 5650.093   time_remaining = 1133\n",
      "Epoch 2500 Batch    6/6   train_loss = 0.101   time_elapsed = 5652.253   time_remaining = 1130\n",
      "Epoch 2501 Batch    6/6   train_loss = 0.100   time_elapsed = 5654.421   time_remaining = 1128\n",
      "Model Trained and Saved\n",
      "Epoch 2502 Batch    6/6   train_loss = 0.094   time_elapsed = 5657.657   time_remaining = 1126\n",
      "Epoch 2503 Batch    6/6   train_loss = 0.102   time_elapsed = 5659.823   time_remaining = 1124\n",
      "Epoch 2504 Batch    6/6   train_loss = 0.097   time_elapsed = 5661.992   time_remaining = 1122\n",
      "Epoch 2505 Batch    6/6   train_loss = 0.104   time_elapsed = 5664.172   time_remaining = 1119\n",
      "Epoch 2506 Batch    6/6   train_loss = 0.097   time_elapsed = 5666.342   time_remaining = 1117\n",
      "Epoch 2507 Batch    6/6   train_loss = 0.100   time_elapsed = 5668.510   time_remaining = 1115\n",
      "Epoch 2508 Batch    6/6   train_loss = 0.098   time_elapsed = 5670.674   time_remaining = 1112\n",
      "Epoch 2509 Batch    6/6   train_loss = 0.104   time_elapsed = 5672.837   time_remaining = 1110\n",
      "Epoch 2510 Batch    6/6   train_loss = 0.097   time_elapsed = 5675.012   time_remaining = 1108\n",
      "Epoch 2511 Batch    6/6   train_loss = 0.096   time_elapsed = 5677.182   time_remaining = 1106\n",
      "Model Trained and Saved\n",
      "Epoch 2512 Batch    6/6   train_loss = 0.103   time_elapsed = 5680.449   time_remaining = 1104\n",
      "Epoch 2513 Batch    6/6   train_loss = 0.093   time_elapsed = 5682.616   time_remaining = 1101\n",
      "Epoch 2514 Batch    6/6   train_loss = 0.098   time_elapsed = 5684.782   time_remaining = 1099\n",
      "Epoch 2515 Batch    6/6   train_loss = 0.104   time_elapsed = 5687.049   time_remaining = 1097\n",
      "Epoch 2516 Batch    6/6   train_loss = 0.099   time_elapsed = 5689.212   time_remaining = 1094\n",
      "Epoch 2517 Batch    6/6   train_loss = 0.101   time_elapsed = 5691.385   time_remaining = 1092\n",
      "Epoch 2518 Batch    6/6   train_loss = 0.100   time_elapsed = 5693.546   time_remaining = 1090\n",
      "Epoch 2519 Batch    6/6   train_loss = 0.101   time_elapsed = 5695.705   time_remaining = 1088\n",
      "Epoch 2520 Batch    6/6   train_loss = 0.097   time_elapsed = 5697.868   time_remaining = 1085\n",
      "Epoch 2521 Batch    6/6   train_loss = 0.096   time_elapsed = 5700.035   time_remaining = 1083\n",
      "Model Trained and Saved\n",
      "Epoch 2522 Batch    6/6   train_loss = 0.100   time_elapsed = 5703.292   time_remaining = 1081\n",
      "Epoch 2523 Batch    6/6   train_loss = 0.098   time_elapsed = 5705.461   time_remaining = 1079\n",
      "Epoch 2524 Batch    6/6   train_loss = 0.096   time_elapsed = 5707.629   time_remaining = 1076\n",
      "Epoch 2525 Batch    6/6   train_loss = 0.100   time_elapsed = 5709.793   time_remaining = 1074\n",
      "Epoch 2526 Batch    6/6   train_loss = 0.097   time_elapsed = 5711.959   time_remaining = 1072\n",
      "Epoch 2527 Batch    6/6   train_loss = 0.099   time_elapsed = 5714.128   time_remaining = 1070\n",
      "Epoch 2528 Batch    6/6   train_loss = 0.100   time_elapsed = 5716.301   time_remaining = 1067\n",
      "Epoch 2529 Batch    6/6   train_loss = 0.104   time_elapsed = 5718.474   time_remaining = 1065\n",
      "Epoch 2530 Batch    6/6   train_loss = 0.102   time_elapsed = 5720.646   time_remaining = 1063\n",
      "Epoch 2531 Batch    6/6   train_loss = 0.099   time_elapsed = 5722.819   time_remaining = 1060\n",
      "Model Trained and Saved\n",
      "Epoch 2532 Batch    6/6   train_loss = 0.101   time_elapsed = 5726.101   time_remaining = 1058\n",
      "Epoch 2533 Batch    6/6   train_loss = 0.101   time_elapsed = 5728.272   time_remaining = 1056\n",
      "Epoch 2534 Batch    6/6   train_loss = 0.098   time_elapsed = 5730.452   time_remaining = 1054\n",
      "Epoch 2535 Batch    6/6   train_loss = 0.094   time_elapsed = 5732.623   time_remaining = 1052\n",
      "Epoch 2536 Batch    6/6   train_loss = 0.098   time_elapsed = 5734.799   time_remaining = 1049\n",
      "Epoch 2537 Batch    6/6   train_loss = 0.095   time_elapsed = 5736.968   time_remaining = 1047\n",
      "Epoch 2538 Batch    6/6   train_loss = 0.097   time_elapsed = 5739.133   time_remaining = 1045\n",
      "Epoch 2539 Batch    6/6   train_loss = 0.095   time_elapsed = 5741.311   time_remaining = 1042\n",
      "Epoch 2540 Batch    6/6   train_loss = 0.101   time_elapsed = 5743.479   time_remaining = 1040\n",
      "Epoch 2541 Batch    6/6   train_loss = 0.097   time_elapsed = 5745.639   time_remaining = 1038\n",
      "Model Trained and Saved\n",
      "Epoch 2542 Batch    6/6   train_loss = 0.102   time_elapsed = 5749.063   time_remaining = 1036\n",
      "Epoch 2543 Batch    6/6   train_loss = 0.099   time_elapsed = 5751.236   time_remaining = 1034\n",
      "Epoch 2544 Batch    6/6   train_loss = 0.099   time_elapsed = 5753.395   time_remaining = 1031\n",
      "Epoch 2545 Batch    6/6   train_loss = 0.102   time_elapsed = 5755.574   time_remaining = 1029\n",
      "Epoch 2546 Batch    6/6   train_loss = 0.099   time_elapsed = 5757.745   time_remaining = 1027\n",
      "Epoch 2547 Batch    6/6   train_loss = 0.096   time_elapsed = 5759.911   time_remaining = 1024\n",
      "Epoch 2548 Batch    6/6   train_loss = 0.097   time_elapsed = 5762.084   time_remaining = 1022\n",
      "Epoch 2549 Batch    6/6   train_loss = 0.095   time_elapsed = 5764.249   time_remaining = 1020\n",
      "Epoch 2550 Batch    6/6   train_loss = 0.095   time_elapsed = 5766.422   time_remaining = 1018\n",
      "Epoch 2551 Batch    6/6   train_loss = 0.094   time_elapsed = 5768.596   time_remaining = 1015\n",
      "Model Trained and Saved\n",
      "Epoch 2552 Batch    6/6   train_loss = 0.097   time_elapsed = 5771.895   time_remaining = 1013\n",
      "Epoch 2553 Batch    6/6   train_loss = 0.097   time_elapsed = 5774.056   time_remaining = 1011\n",
      "Epoch 2554 Batch    6/6   train_loss = 0.095   time_elapsed = 5776.228   time_remaining = 1009\n",
      "Epoch 2555 Batch    6/6   train_loss = 0.098   time_elapsed = 5778.384   time_remaining = 1006\n",
      "Epoch 2556 Batch    6/6   train_loss = 0.097   time_elapsed = 5780.544   time_remaining = 1004\n",
      "Epoch 2557 Batch    6/6   train_loss = 0.095   time_elapsed = 5782.701   time_remaining = 1002\n",
      "Epoch 2558 Batch    6/6   train_loss = 0.100   time_elapsed = 5784.860   time_remaining = 1000\n",
      "Epoch 2559 Batch    6/6   train_loss = 0.099   time_elapsed = 5787.018   time_remaining = 997\n",
      "Epoch 2560 Batch    6/6   train_loss = 0.096   time_elapsed = 5789.179   time_remaining = 995\n",
      "Epoch 2561 Batch    6/6   train_loss = 0.097   time_elapsed = 5791.334   time_remaining = 993\n",
      "Model Trained and Saved\n",
      "Epoch 2562 Batch    6/6   train_loss = 0.096   time_elapsed = 5794.594   time_remaining = 991\n",
      "Epoch 2563 Batch    6/6   train_loss = 0.101   time_elapsed = 5796.746   time_remaining = 988\n",
      "Epoch 2564 Batch    6/6   train_loss = 0.094   time_elapsed = 5798.903   time_remaining = 986\n",
      "Epoch 2565 Batch    6/6   train_loss = 0.100   time_elapsed = 5801.052   time_remaining = 984\n",
      "Epoch 2566 Batch    6/6   train_loss = 0.093   time_elapsed = 5803.202   time_remaining = 982\n",
      "Epoch 2567 Batch    6/6   train_loss = 0.099   time_elapsed = 5805.350   time_remaining = 979\n",
      "Epoch 2568 Batch    6/6   train_loss = 0.101   time_elapsed = 5807.501   time_remaining = 977\n",
      "Epoch 2569 Batch    6/6   train_loss = 0.097   time_elapsed = 5809.662   time_remaining = 975\n",
      "Epoch 2570 Batch    6/6   train_loss = 0.100   time_elapsed = 5811.811   time_remaining = 972\n",
      "Epoch 2571 Batch    6/6   train_loss = 0.100   time_elapsed = 5813.973   time_remaining = 970\n",
      "Model Trained and Saved\n",
      "Epoch 2572 Batch    6/6   train_loss = 0.096   time_elapsed = 5817.229   time_remaining = 968\n",
      "Epoch 2573 Batch    6/6   train_loss = 0.101   time_elapsed = 5819.388   time_remaining = 966\n",
      "Epoch 2574 Batch    6/6   train_loss = 0.098   time_elapsed = 5821.546   time_remaining = 963\n",
      "Epoch 2575 Batch    6/6   train_loss = 0.097   time_elapsed = 5823.702   time_remaining = 961\n",
      "Epoch 2576 Batch    6/6   train_loss = 0.092   time_elapsed = 5825.861   time_remaining = 959\n",
      "Epoch 2577 Batch    6/6   train_loss = 0.098   time_elapsed = 5828.015   time_remaining = 957\n",
      "Epoch 2578 Batch    6/6   train_loss = 0.099   time_elapsed = 5830.163   time_remaining = 954\n",
      "Epoch 2579 Batch    6/6   train_loss = 0.096   time_elapsed = 5832.320   time_remaining = 952\n",
      "Epoch 2580 Batch    6/6   train_loss = 0.096   time_elapsed = 5834.475   time_remaining = 950\n",
      "Epoch 2581 Batch    6/6   train_loss = 0.098   time_elapsed = 5836.623   time_remaining = 948\n",
      "Model Trained and Saved\n",
      "Epoch 2582 Batch    6/6   train_loss = 0.097   time_elapsed = 5839.895   time_remaining = 945\n",
      "Epoch 2583 Batch    6/6   train_loss = 0.093   time_elapsed = 5842.049   time_remaining = 943\n",
      "Epoch 2584 Batch    6/6   train_loss = 0.094   time_elapsed = 5844.206   time_remaining = 941\n",
      "Epoch 2585 Batch    6/6   train_loss = 0.098   time_elapsed = 5846.363   time_remaining = 939\n",
      "Epoch 2586 Batch    6/6   train_loss = 0.101   time_elapsed = 5848.517   time_remaining = 936\n",
      "Epoch 2587 Batch    6/6   train_loss = 0.091   time_elapsed = 5850.675   time_remaining = 934\n",
      "Epoch 2588 Batch    6/6   train_loss = 0.099   time_elapsed = 5852.836   time_remaining = 932\n",
      "Epoch 2589 Batch    6/6   train_loss = 0.098   time_elapsed = 5854.994   time_remaining = 929\n",
      "Epoch 2590 Batch    6/6   train_loss = 0.101   time_elapsed = 5857.150   time_remaining = 927\n",
      "Epoch 2591 Batch    6/6   train_loss = 0.095   time_elapsed = 5859.299   time_remaining = 925\n",
      "Model Trained and Saved\n",
      "Epoch 2592 Batch    6/6   train_loss = 0.099   time_elapsed = 5862.566   time_remaining = 923\n",
      "Epoch 2593 Batch    6/6   train_loss = 0.091   time_elapsed = 5864.725   time_remaining = 921\n",
      "Epoch 2594 Batch    6/6   train_loss = 0.094   time_elapsed = 5866.869   time_remaining = 918\n",
      "Epoch 2595 Batch    6/6   train_loss = 0.098   time_elapsed = 5869.024   time_remaining = 916\n",
      "Epoch 2596 Batch    6/6   train_loss = 0.095   time_elapsed = 5871.178   time_remaining = 914\n",
      "Epoch 2597 Batch    6/6   train_loss = 0.096   time_elapsed = 5873.334   time_remaining = 911\n",
      "Epoch 2598 Batch    6/6   train_loss = 0.093   time_elapsed = 5875.489   time_remaining = 909\n",
      "Epoch 2599 Batch    6/6   train_loss = 0.101   time_elapsed = 5877.643   time_remaining = 907\n",
      "Epoch 2600 Batch    6/6   train_loss = 0.099   time_elapsed = 5879.798   time_remaining = 905\n",
      "Epoch 2601 Batch    6/6   train_loss = 0.096   time_elapsed = 5881.950   time_remaining = 902\n",
      "Model Trained and Saved\n",
      "Epoch 2602 Batch    6/6   train_loss = 0.095   time_elapsed = 5885.207   time_remaining = 900\n",
      "Epoch 2603 Batch    6/6   train_loss = 0.095   time_elapsed = 5887.363   time_remaining = 898\n",
      "Epoch 2604 Batch    6/6   train_loss = 0.098   time_elapsed = 5889.515   time_remaining = 896\n",
      "Epoch 2605 Batch    6/6   train_loss = 0.103   time_elapsed = 5891.667   time_remaining = 893\n",
      "Epoch 2606 Batch    6/6   train_loss = 0.107   time_elapsed = 5893.828   time_remaining = 891\n",
      "Epoch 2607 Batch    6/6   train_loss = 0.098   time_elapsed = 5895.983   time_remaining = 889\n",
      "Epoch 2608 Batch    6/6   train_loss = 0.097   time_elapsed = 5898.140   time_remaining = 887\n",
      "Epoch 2609 Batch    6/6   train_loss = 0.099   time_elapsed = 5900.296   time_remaining = 884\n",
      "Epoch 2610 Batch    6/6   train_loss = 0.100   time_elapsed = 5902.455   time_remaining = 882\n",
      "Epoch 2611 Batch    6/6   train_loss = 0.094   time_elapsed = 5904.615   time_remaining = 880\n",
      "Model Trained and Saved\n",
      "Epoch 2612 Batch    6/6   train_loss = 0.098   time_elapsed = 5907.872   time_remaining = 878\n",
      "Epoch 2613 Batch    6/6   train_loss = 0.100   time_elapsed = 5910.036   time_remaining = 875\n",
      "Epoch 2614 Batch    6/6   train_loss = 0.093   time_elapsed = 5912.193   time_remaining = 873\n",
      "Epoch 2615 Batch    6/6   train_loss = 0.096   time_elapsed = 5914.355   time_remaining = 871\n",
      "Epoch 2616 Batch    6/6   train_loss = 0.095   time_elapsed = 5916.511   time_remaining = 868\n",
      "Epoch 2617 Batch    6/6   train_loss = 0.097   time_elapsed = 5918.673   time_remaining = 866\n",
      "Epoch 2618 Batch    6/6   train_loss = 0.094   time_elapsed = 5920.840   time_remaining = 864\n",
      "Epoch 2619 Batch    6/6   train_loss = 0.100   time_elapsed = 5923.001   time_remaining = 862\n",
      "Epoch 2620 Batch    6/6   train_loss = 0.094   time_elapsed = 5925.162   time_remaining = 859\n",
      "Epoch 2621 Batch    6/6   train_loss = 0.095   time_elapsed = 5927.328   time_remaining = 857\n",
      "Model Trained and Saved\n",
      "Epoch 2622 Batch    6/6   train_loss = 0.097   time_elapsed = 5930.904   time_remaining = 855\n",
      "Epoch 2623 Batch    6/6   train_loss = 0.095   time_elapsed = 5933.059   time_remaining = 853\n",
      "Epoch 2624 Batch    6/6   train_loss = 0.098   time_elapsed = 5935.225   time_remaining = 850\n",
      "Epoch 2625 Batch    6/6   train_loss = 0.093   time_elapsed = 5937.394   time_remaining = 848\n",
      "Epoch 2626 Batch    6/6   train_loss = 0.100   time_elapsed = 5939.561   time_remaining = 846\n",
      "Epoch 2627 Batch    6/6   train_loss = 0.095   time_elapsed = 5941.728   time_remaining = 844\n",
      "Epoch 2628 Batch    6/6   train_loss = 0.098   time_elapsed = 5943.892   time_remaining = 841\n",
      "Epoch 2629 Batch    6/6   train_loss = 0.096   time_elapsed = 5946.063   time_remaining = 839\n",
      "Epoch 2630 Batch    6/6   train_loss = 0.097   time_elapsed = 5948.219   time_remaining = 837\n",
      "Epoch 2631 Batch    6/6   train_loss = 0.097   time_elapsed = 5950.393   time_remaining = 835\n",
      "Model Trained and Saved\n",
      "Epoch 2632 Batch    6/6   train_loss = 0.093   time_elapsed = 5953.665   time_remaining = 832\n",
      "Epoch 2633 Batch    6/6   train_loss = 0.100   time_elapsed = 5955.835   time_remaining = 830\n",
      "Epoch 2634 Batch    6/6   train_loss = 0.104   time_elapsed = 5958.007   time_remaining = 828\n",
      "Epoch 2635 Batch    6/6   train_loss = 0.095   time_elapsed = 5960.164   time_remaining = 826\n",
      "Epoch 2636 Batch    6/6   train_loss = 0.094   time_elapsed = 5962.336   time_remaining = 823\n",
      "Epoch 2637 Batch    6/6   train_loss = 0.096   time_elapsed = 5964.499   time_remaining = 821\n",
      "Epoch 2638 Batch    6/6   train_loss = 0.095   time_elapsed = 5966.667   time_remaining = 819\n",
      "Epoch 2639 Batch    6/6   train_loss = 0.099   time_elapsed = 5968.829   time_remaining = 817\n",
      "Epoch 2640 Batch    6/6   train_loss = 0.093   time_elapsed = 5970.995   time_remaining = 814\n",
      "Epoch 2641 Batch    6/6   train_loss = 0.094   time_elapsed = 5973.164   time_remaining = 812\n",
      "Model Trained and Saved\n",
      "Epoch 2642 Batch    6/6   train_loss = 0.096   time_elapsed = 5976.446   time_remaining = 810\n",
      "Epoch 2643 Batch    6/6   train_loss = 0.098   time_elapsed = 5978.618   time_remaining = 808\n",
      "Epoch 2644 Batch    6/6   train_loss = 0.095   time_elapsed = 5980.780   time_remaining = 805\n",
      "Epoch 2645 Batch    6/6   train_loss = 0.091   time_elapsed = 5982.950   time_remaining = 803\n",
      "Epoch 2646 Batch    6/6   train_loss = 0.098   time_elapsed = 5985.117   time_remaining = 801\n",
      "Epoch 2647 Batch    6/6   train_loss = 0.094   time_elapsed = 5987.286   time_remaining = 798\n",
      "Epoch 2648 Batch    6/6   train_loss = 0.094   time_elapsed = 5989.462   time_remaining = 796\n",
      "Epoch 2649 Batch    6/6   train_loss = 0.090   time_elapsed = 5991.629   time_remaining = 794\n",
      "Epoch 2650 Batch    6/6   train_loss = 0.097   time_elapsed = 5993.799   time_remaining = 792\n",
      "Epoch 2651 Batch    6/6   train_loss = 0.099   time_elapsed = 5995.965   time_remaining = 789\n",
      "Model Trained and Saved\n",
      "Epoch 2652 Batch    6/6   train_loss = 0.095   time_elapsed = 5999.265   time_remaining = 787\n",
      "Epoch 2653 Batch    6/6   train_loss = 0.096   time_elapsed = 6001.434   time_remaining = 785\n",
      "Epoch 2654 Batch    6/6   train_loss = 0.097   time_elapsed = 6003.602   time_remaining = 783\n",
      "Epoch 2655 Batch    6/6   train_loss = 0.096   time_elapsed = 6005.769   time_remaining = 780\n",
      "Epoch 2656 Batch    6/6   train_loss = 0.096   time_elapsed = 6007.938   time_remaining = 778\n",
      "Epoch 2657 Batch    6/6   train_loss = 0.097   time_elapsed = 6010.108   time_remaining = 776\n",
      "Epoch 2658 Batch    6/6   train_loss = 0.091   time_elapsed = 6012.274   time_remaining = 774\n",
      "Epoch 2659 Batch    6/6   train_loss = 0.095   time_elapsed = 6014.438   time_remaining = 771\n",
      "Epoch 2660 Batch    6/6   train_loss = 0.092   time_elapsed = 6016.607   time_remaining = 769\n",
      "Epoch 2661 Batch    6/6   train_loss = 0.098   time_elapsed = 6018.771   time_remaining = 767\n",
      "Model Trained and Saved\n",
      "Epoch 2662 Batch    6/6   train_loss = 0.093   time_elapsed = 6022.061   time_remaining = 765\n",
      "Epoch 2663 Batch    6/6   train_loss = 0.091   time_elapsed = 6024.223   time_remaining = 762\n",
      "Epoch 2664 Batch    6/6   train_loss = 0.094   time_elapsed = 6026.392   time_remaining = 760\n",
      "Epoch 2665 Batch    6/6   train_loss = 0.091   time_elapsed = 6028.561   time_remaining = 758\n",
      "Epoch 2666 Batch    6/6   train_loss = 0.091   time_elapsed = 6030.728   time_remaining = 756\n",
      "Epoch 2667 Batch    6/6   train_loss = 0.090   time_elapsed = 6032.891   time_remaining = 753\n",
      "Epoch 2668 Batch    6/6   train_loss = 0.097   time_elapsed = 6035.057   time_remaining = 751\n",
      "Epoch 2669 Batch    6/6   train_loss = 0.097   time_elapsed = 6037.224   time_remaining = 749\n",
      "Epoch 2670 Batch    6/6   train_loss = 0.093   time_elapsed = 6039.386   time_remaining = 746\n",
      "Epoch 2671 Batch    6/6   train_loss = 0.091   time_elapsed = 6041.547   time_remaining = 744\n",
      "Model Trained and Saved\n",
      "Epoch 2672 Batch    6/6   train_loss = 0.094   time_elapsed = 6044.833   time_remaining = 742\n",
      "Epoch 2673 Batch    6/6   train_loss = 0.093   time_elapsed = 6047.000   time_remaining = 740\n",
      "Epoch 2674 Batch    6/6   train_loss = 0.094   time_elapsed = 6049.168   time_remaining = 737\n",
      "Epoch 2675 Batch    6/6   train_loss = 0.093   time_elapsed = 6051.338   time_remaining = 735\n",
      "Epoch 2676 Batch    6/6   train_loss = 0.092   time_elapsed = 6053.502   time_remaining = 733\n",
      "Epoch 2677 Batch    6/6   train_loss = 0.092   time_elapsed = 6055.665   time_remaining = 731\n",
      "Epoch 2678 Batch    6/6   train_loss = 0.094   time_elapsed = 6057.845   time_remaining = 728\n",
      "Epoch 2679 Batch    6/6   train_loss = 0.095   time_elapsed = 6060.021   time_remaining = 726\n",
      "Epoch 2680 Batch    6/6   train_loss = 0.094   time_elapsed = 6062.190   time_remaining = 724\n",
      "Epoch 2681 Batch    6/6   train_loss = 0.090   time_elapsed = 6064.365   time_remaining = 722\n",
      "Model Trained and Saved\n",
      "Epoch 2682 Batch    6/6   train_loss = 0.094   time_elapsed = 6067.633   time_remaining = 719\n",
      "Epoch 2683 Batch    6/6   train_loss = 0.094   time_elapsed = 6069.800   time_remaining = 717\n",
      "Epoch 2684 Batch    6/6   train_loss = 0.096   time_elapsed = 6071.965   time_remaining = 715\n",
      "Epoch 2685 Batch    6/6   train_loss = 0.098   time_elapsed = 6074.130   time_remaining = 713\n",
      "Epoch 2686 Batch    6/6   train_loss = 0.093   time_elapsed = 6076.297   time_remaining = 710\n",
      "Epoch 2687 Batch    6/6   train_loss = 0.098   time_elapsed = 6078.471   time_remaining = 708\n",
      "Epoch 2688 Batch    6/6   train_loss = 0.094   time_elapsed = 6080.648   time_remaining = 706\n",
      "Epoch 2689 Batch    6/6   train_loss = 0.090   time_elapsed = 6082.817   time_remaining = 704\n",
      "Epoch 2690 Batch    6/6   train_loss = 0.094   time_elapsed = 6084.990   time_remaining = 701\n",
      "Epoch 2691 Batch    6/6   train_loss = 0.095   time_elapsed = 6087.162   time_remaining = 699\n",
      "Model Trained and Saved\n",
      "Epoch 2692 Batch    6/6   train_loss = 0.095   time_elapsed = 6090.530   time_remaining = 697\n",
      "Epoch 2693 Batch    6/6   train_loss = 0.096   time_elapsed = 6092.699   time_remaining = 695\n",
      "Epoch 2694 Batch    6/6   train_loss = 0.097   time_elapsed = 6094.869   time_remaining = 692\n",
      "Epoch 2695 Batch    6/6   train_loss = 0.092   time_elapsed = 6097.037   time_remaining = 690\n",
      "Epoch 2696 Batch    6/6   train_loss = 0.092   time_elapsed = 6099.214   time_remaining = 688\n",
      "Epoch 2697 Batch    6/6   train_loss = 0.092   time_elapsed = 6101.379   time_remaining = 685\n",
      "Epoch 2698 Batch    6/6   train_loss = 0.093   time_elapsed = 6103.549   time_remaining = 683\n",
      "Epoch 2699 Batch    6/6   train_loss = 0.086   time_elapsed = 6105.715   time_remaining = 681\n",
      "Epoch 2700 Batch    6/6   train_loss = 0.091   time_elapsed = 6107.883   time_remaining = 679\n",
      "Epoch 2701 Batch    6/6   train_loss = 0.092   time_elapsed = 6110.052   time_remaining = 676\n",
      "Model Trained and Saved\n",
      "Epoch 2702 Batch    6/6   train_loss = 0.089   time_elapsed = 6113.398   time_remaining = 674\n",
      "Epoch 2703 Batch    6/6   train_loss = 0.101   time_elapsed = 6115.571   time_remaining = 672\n",
      "Epoch 2704 Batch    6/6   train_loss = 0.097   time_elapsed = 6117.738   time_remaining = 670\n",
      "Epoch 2705 Batch    6/6   train_loss = 0.092   time_elapsed = 6119.910   time_remaining = 667\n",
      "Epoch 2706 Batch    6/6   train_loss = 0.098   time_elapsed = 6122.072   time_remaining = 665\n",
      "Epoch 2707 Batch    6/6   train_loss = 0.091   time_elapsed = 6124.239   time_remaining = 663\n",
      "Epoch 2708 Batch    6/6   train_loss = 0.094   time_elapsed = 6126.407   time_remaining = 661\n",
      "Epoch 2709 Batch    6/6   train_loss = 0.092   time_elapsed = 6128.574   time_remaining = 658\n",
      "Epoch 2710 Batch    6/6   train_loss = 0.093   time_elapsed = 6130.746   time_remaining = 656\n",
      "Epoch 2711 Batch    6/6   train_loss = 0.091   time_elapsed = 6132.911   time_remaining = 654\n",
      "Model Trained and Saved\n",
      "Epoch 2712 Batch    6/6   train_loss = 0.092   time_elapsed = 6136.222   time_remaining = 652\n",
      "Epoch 2713 Batch    6/6   train_loss = 0.091   time_elapsed = 6138.394   time_remaining = 649\n",
      "Epoch 2714 Batch    6/6   train_loss = 0.090   time_elapsed = 6140.558   time_remaining = 647\n",
      "Epoch 2715 Batch    6/6   train_loss = 0.100   time_elapsed = 6142.730   time_remaining = 645\n",
      "Epoch 2716 Batch    6/6   train_loss = 0.095   time_elapsed = 6144.902   time_remaining = 643\n",
      "Epoch 2717 Batch    6/6   train_loss = 0.099   time_elapsed = 6147.070   time_remaining = 640\n",
      "Epoch 2718 Batch    6/6   train_loss = 0.099   time_elapsed = 6149.251   time_remaining = 638\n",
      "Epoch 2719 Batch    6/6   train_loss = 0.091   time_elapsed = 6151.414   time_remaining = 636\n",
      "Epoch 2720 Batch    6/6   train_loss = 0.098   time_elapsed = 6153.582   time_remaining = 633\n",
      "Epoch 2721 Batch    6/6   train_loss = 0.094   time_elapsed = 6155.754   time_remaining = 631\n",
      "Model Trained and Saved\n",
      "Epoch 2722 Batch    6/6   train_loss = 0.090   time_elapsed = 6159.065   time_remaining = 629\n",
      "Epoch 2723 Batch    6/6   train_loss = 0.092   time_elapsed = 6161.229   time_remaining = 627\n",
      "Epoch 2724 Batch    6/6   train_loss = 0.093   time_elapsed = 6163.405   time_remaining = 624\n",
      "Epoch 2725 Batch    6/6   train_loss = 0.089   time_elapsed = 6165.569   time_remaining = 622\n",
      "Epoch 2726 Batch    6/6   train_loss = 0.089   time_elapsed = 6167.735   time_remaining = 620\n",
      "Epoch 2727 Batch    6/6   train_loss = 0.087   time_elapsed = 6169.906   time_remaining = 618\n",
      "Epoch 2728 Batch    6/6   train_loss = 0.089   time_elapsed = 6172.076   time_remaining = 615\n",
      "Epoch 2729 Batch    6/6   train_loss = 0.093   time_elapsed = 6174.245   time_remaining = 613\n",
      "Epoch 2730 Batch    6/6   train_loss = 0.088   time_elapsed = 6176.414   time_remaining = 611\n",
      "Epoch 2731 Batch    6/6   train_loss = 0.094   time_elapsed = 6178.583   time_remaining = 609\n",
      "Model Trained and Saved\n",
      "Epoch 2732 Batch    6/6   train_loss = 0.091   time_elapsed = 6181.896   time_remaining = 606\n",
      "Epoch 2733 Batch    6/6   train_loss = 0.095   time_elapsed = 6184.060   time_remaining = 604\n",
      "Epoch 2734 Batch    6/6   train_loss = 0.093   time_elapsed = 6186.230   time_remaining = 602\n",
      "Epoch 2735 Batch    6/6   train_loss = 0.088   time_elapsed = 6188.406   time_remaining = 600\n",
      "Epoch 2736 Batch    6/6   train_loss = 0.091   time_elapsed = 6190.575   time_remaining = 597\n",
      "Epoch 2737 Batch    6/6   train_loss = 0.098   time_elapsed = 6192.745   time_remaining = 595\n",
      "Epoch 2738 Batch    6/6   train_loss = 0.092   time_elapsed = 6194.936   time_remaining = 593\n",
      "Epoch 2739 Batch    6/6   train_loss = 0.101   time_elapsed = 6197.104   time_remaining = 591\n",
      "Epoch 2740 Batch    6/6   train_loss = 0.091   time_elapsed = 6199.272   time_remaining = 588\n",
      "Epoch 2741 Batch    6/6   train_loss = 0.091   time_elapsed = 6201.446   time_remaining = 586\n",
      "Model Trained and Saved\n",
      "Epoch 2742 Batch    6/6   train_loss = 0.092   time_elapsed = 6204.757   time_remaining = 584\n",
      "Epoch 2743 Batch    6/6   train_loss = 0.094   time_elapsed = 6206.917   time_remaining = 582\n",
      "Epoch 2744 Batch    6/6   train_loss = 0.089   time_elapsed = 6209.089   time_remaining = 579\n",
      "Epoch 2745 Batch    6/6   train_loss = 0.088   time_elapsed = 6211.253   time_remaining = 577\n",
      "Epoch 2746 Batch    6/6   train_loss = 0.097   time_elapsed = 6213.427   time_remaining = 575\n",
      "Epoch 2747 Batch    6/6   train_loss = 0.091   time_elapsed = 6215.604   time_remaining = 572\n",
      "Epoch 2748 Batch    6/6   train_loss = 0.097   time_elapsed = 6217.775   time_remaining = 570\n",
      "Epoch 2749 Batch    6/6   train_loss = 0.093   time_elapsed = 6219.946   time_remaining = 568\n",
      "Epoch 2750 Batch    6/6   train_loss = 0.095   time_elapsed = 6222.117   time_remaining = 566\n",
      "Epoch 2751 Batch    6/6   train_loss = 0.091   time_elapsed = 6224.287   time_remaining = 563\n",
      "Model Trained and Saved\n",
      "Epoch 2752 Batch    6/6   train_loss = 0.095   time_elapsed = 6227.628   time_remaining = 561\n",
      "Epoch 2753 Batch    6/6   train_loss = 0.093   time_elapsed = 6229.792   time_remaining = 559\n",
      "Epoch 2754 Batch    6/6   train_loss = 0.090   time_elapsed = 6231.959   time_remaining = 557\n",
      "Epoch 2755 Batch    6/6   train_loss = 0.093   time_elapsed = 6234.119   time_remaining = 554\n",
      "Epoch 2756 Batch    6/6   train_loss = 0.093   time_elapsed = 6236.289   time_remaining = 552\n",
      "Epoch 2757 Batch    6/6   train_loss = 0.092   time_elapsed = 6238.446   time_remaining = 550\n",
      "Epoch 2758 Batch    6/6   train_loss = 0.088   time_elapsed = 6240.619   time_remaining = 548\n",
      "Epoch 2759 Batch    6/6   train_loss = 0.092   time_elapsed = 6242.790   time_remaining = 545\n",
      "Epoch 2760 Batch    6/6   train_loss = 0.090   time_elapsed = 6244.958   time_remaining = 543\n",
      "Epoch 2761 Batch    6/6   train_loss = 0.094   time_elapsed = 6247.129   time_remaining = 541\n",
      "Model Trained and Saved\n",
      "Epoch 2762 Batch    6/6   train_loss = 0.091   time_elapsed = 6250.568   time_remaining = 539\n",
      "Epoch 2763 Batch    6/6   train_loss = 0.094   time_elapsed = 6252.739   time_remaining = 536\n",
      "Epoch 2764 Batch    6/6   train_loss = 0.090   time_elapsed = 6254.900   time_remaining = 534\n",
      "Epoch 2765 Batch    6/6   train_loss = 0.090   time_elapsed = 6257.067   time_remaining = 532\n",
      "Epoch 2766 Batch    6/6   train_loss = 0.092   time_elapsed = 6259.233   time_remaining = 530\n",
      "Epoch 2767 Batch    6/6   train_loss = 0.091   time_elapsed = 6261.399   time_remaining = 527\n",
      "Epoch 2768 Batch    6/6   train_loss = 0.092   time_elapsed = 6263.568   time_remaining = 525\n",
      "Epoch 2769 Batch    6/6   train_loss = 0.094   time_elapsed = 6265.736   time_remaining = 523\n",
      "Epoch 2770 Batch    6/6   train_loss = 0.093   time_elapsed = 6267.904   time_remaining = 520\n",
      "Epoch 2771 Batch    6/6   train_loss = 0.094   time_elapsed = 6270.069   time_remaining = 518\n",
      "Model Trained and Saved\n",
      "Epoch 2772 Batch    6/6   train_loss = 0.093   time_elapsed = 6273.401   time_remaining = 516\n",
      "Epoch 2773 Batch    6/6   train_loss = 0.097   time_elapsed = 6275.568   time_remaining = 514\n",
      "Epoch 2774 Batch    6/6   train_loss = 0.094   time_elapsed = 6277.734   time_remaining = 511\n",
      "Epoch 2775 Batch    6/6   train_loss = 0.096   time_elapsed = 6279.903   time_remaining = 509\n",
      "Epoch 2776 Batch    6/6   train_loss = 0.099   time_elapsed = 6282.072   time_remaining = 507\n",
      "Epoch 2777 Batch    6/6   train_loss = 0.095   time_elapsed = 6284.237   time_remaining = 505\n",
      "Epoch 2778 Batch    6/6   train_loss = 0.097   time_elapsed = 6286.409   time_remaining = 502\n",
      "Epoch 2779 Batch    6/6   train_loss = 0.097   time_elapsed = 6288.587   time_remaining = 500\n",
      "Epoch 2780 Batch    6/6   train_loss = 0.093   time_elapsed = 6290.755   time_remaining = 498\n",
      "Epoch 2781 Batch    6/6   train_loss = 0.092   time_elapsed = 6292.925   time_remaining = 496\n",
      "Model Trained and Saved\n",
      "Epoch 2782 Batch    6/6   train_loss = 0.096   time_elapsed = 6296.465   time_remaining = 493\n",
      "Epoch 2783 Batch    6/6   train_loss = 0.090   time_elapsed = 6298.634   time_remaining = 491\n",
      "Epoch 2784 Batch    6/6   train_loss = 0.091   time_elapsed = 6300.809   time_remaining = 489\n",
      "Epoch 2785 Batch    6/6   train_loss = 0.091   time_elapsed = 6302.984   time_remaining = 487\n",
      "Epoch 2786 Batch    6/6   train_loss = 0.094   time_elapsed = 6305.158   time_remaining = 484\n",
      "Epoch 2787 Batch    6/6   train_loss = 0.098   time_elapsed = 6307.328   time_remaining = 482\n",
      "Epoch 2788 Batch    6/6   train_loss = 0.094   time_elapsed = 6309.500   time_remaining = 480\n",
      "Epoch 2789 Batch    6/6   train_loss = 0.094   time_elapsed = 6311.669   time_remaining = 478\n",
      "Epoch 2790 Batch    6/6   train_loss = 0.090   time_elapsed = 6313.840   time_remaining = 475\n",
      "Epoch 2791 Batch    6/6   train_loss = 0.091   time_elapsed = 6316.007   time_remaining = 473\n",
      "Model Trained and Saved\n",
      "Epoch 2792 Batch    6/6   train_loss = 0.092   time_elapsed = 6319.335   time_remaining = 471\n",
      "Epoch 2793 Batch    6/6   train_loss = 0.092   time_elapsed = 6321.501   time_remaining = 469\n",
      "Epoch 2794 Batch    6/6   train_loss = 0.092   time_elapsed = 6323.678   time_remaining = 466\n",
      "Epoch 2795 Batch    6/6   train_loss = 0.093   time_elapsed = 6325.862   time_remaining = 464\n",
      "Epoch 2796 Batch    6/6   train_loss = 0.093   time_elapsed = 6328.036   time_remaining = 462\n",
      "Epoch 2797 Batch    6/6   train_loss = 0.095   time_elapsed = 6330.208   time_remaining = 459\n",
      "Epoch 2798 Batch    6/6   train_loss = 0.094   time_elapsed = 6332.381   time_remaining = 457\n",
      "Epoch 2799 Batch    6/6   train_loss = 0.098   time_elapsed = 6334.549   time_remaining = 455\n",
      "Epoch 2800 Batch    6/6   train_loss = 0.097   time_elapsed = 6336.716   time_remaining = 453\n",
      "Epoch 2801 Batch    6/6   train_loss = 0.087   time_elapsed = 6338.882   time_remaining = 450\n",
      "Model Trained and Saved\n",
      "Epoch 2802 Batch    6/6   train_loss = 0.094   time_elapsed = 6342.214   time_remaining = 448\n",
      "Epoch 2803 Batch    6/6   train_loss = 0.089   time_elapsed = 6344.382   time_remaining = 446\n",
      "Epoch 2804 Batch    6/6   train_loss = 0.092   time_elapsed = 6346.559   time_remaining = 444\n",
      "Epoch 2805 Batch    6/6   train_loss = 0.091   time_elapsed = 6348.736   time_remaining = 441\n",
      "Epoch 2806 Batch    6/6   train_loss = 0.092   time_elapsed = 6350.898   time_remaining = 439\n",
      "Epoch 2807 Batch    6/6   train_loss = 0.088   time_elapsed = 6353.065   time_remaining = 437\n",
      "Epoch 2808 Batch    6/6   train_loss = 0.094   time_elapsed = 6355.231   time_remaining = 435\n",
      "Epoch 2809 Batch    6/6   train_loss = 0.097   time_elapsed = 6357.401   time_remaining = 432\n",
      "Epoch 2810 Batch    6/6   train_loss = 0.088   time_elapsed = 6359.567   time_remaining = 430\n",
      "Epoch 2811 Batch    6/6   train_loss = 0.093   time_elapsed = 6361.741   time_remaining = 428\n",
      "Model Trained and Saved\n",
      "Epoch 2812 Batch    6/6   train_loss = 0.089   time_elapsed = 6365.055   time_remaining = 426\n",
      "Epoch 2813 Batch    6/6   train_loss = 0.092   time_elapsed = 6367.224   time_remaining = 423\n",
      "Epoch 2814 Batch    6/6   train_loss = 0.090   time_elapsed = 6369.396   time_remaining = 421\n",
      "Epoch 2815 Batch    6/6   train_loss = 0.096   time_elapsed = 6371.571   time_remaining = 419\n",
      "Epoch 2816 Batch    6/6   train_loss = 0.099   time_elapsed = 6373.731   time_remaining = 416\n",
      "Epoch 2817 Batch    6/6   train_loss = 0.095   time_elapsed = 6375.901   time_remaining = 414\n",
      "Epoch 2818 Batch    6/6   train_loss = 0.093   time_elapsed = 6378.065   time_remaining = 412\n",
      "Epoch 2819 Batch    6/6   train_loss = 0.089   time_elapsed = 6380.230   time_remaining = 410\n",
      "Epoch 2820 Batch    6/6   train_loss = 0.088   time_elapsed = 6382.397   time_remaining = 407\n",
      "Epoch 2821 Batch    6/6   train_loss = 0.089   time_elapsed = 6384.570   time_remaining = 405\n",
      "Model Trained and Saved\n",
      "Epoch 2822 Batch    6/6   train_loss = 0.091   time_elapsed = 6388.096   time_remaining = 403\n",
      "Epoch 2823 Batch    6/6   train_loss = 0.087   time_elapsed = 6390.275   time_remaining = 401\n",
      "Epoch 2824 Batch    6/6   train_loss = 0.091   time_elapsed = 6392.441   time_remaining = 398\n",
      "Epoch 2825 Batch    6/6   train_loss = 0.093   time_elapsed = 6394.620   time_remaining = 396\n",
      "Epoch 2826 Batch    6/6   train_loss = 0.093   time_elapsed = 6396.789   time_remaining = 394\n",
      "Epoch 2827 Batch    6/6   train_loss = 0.092   time_elapsed = 6398.958   time_remaining = 392\n",
      "Epoch 2828 Batch    6/6   train_loss = 0.084   time_elapsed = 6401.127   time_remaining = 389\n",
      "Epoch 2829 Batch    6/6   train_loss = 0.093   time_elapsed = 6403.300   time_remaining = 387\n",
      "Epoch 2830 Batch    6/6   train_loss = 0.086   time_elapsed = 6405.462   time_remaining = 385\n",
      "Epoch 2831 Batch    6/6   train_loss = 0.088   time_elapsed = 6407.629   time_remaining = 383\n",
      "Model Trained and Saved\n",
      "Epoch 2832 Batch    6/6   train_loss = 0.088   time_elapsed = 6411.189   time_remaining = 380\n",
      "Epoch 2833 Batch    6/6   train_loss = 0.091   time_elapsed = 6413.349   time_remaining = 378\n",
      "Epoch 2834 Batch    6/6   train_loss = 0.092   time_elapsed = 6415.511   time_remaining = 376\n",
      "Epoch 2835 Batch    6/6   train_loss = 0.092   time_elapsed = 6417.687   time_remaining = 374\n",
      "Epoch 2836 Batch    6/6   train_loss = 0.092   time_elapsed = 6419.855   time_remaining = 371\n",
      "Epoch 2837 Batch    6/6   train_loss = 0.087   time_elapsed = 6422.024   time_remaining = 369\n",
      "Epoch 2838 Batch    6/6   train_loss = 0.090   time_elapsed = 6424.186   time_remaining = 367\n",
      "Epoch 2839 Batch    6/6   train_loss = 0.087   time_elapsed = 6426.356   time_remaining = 364\n",
      "Epoch 2840 Batch    6/6   train_loss = 0.091   time_elapsed = 6428.528   time_remaining = 362\n",
      "Epoch 2841 Batch    6/6   train_loss = 0.089   time_elapsed = 6430.694   time_remaining = 360\n",
      "Model Trained and Saved\n",
      "Epoch 2842 Batch    6/6   train_loss = 0.093   time_elapsed = 6434.587   time_remaining = 358\n",
      "Epoch 2843 Batch    6/6   train_loss = 0.092   time_elapsed = 6436.759   time_remaining = 355\n",
      "Epoch 2844 Batch    6/6   train_loss = 0.089   time_elapsed = 6438.917   time_remaining = 353\n",
      "Epoch 2845 Batch    6/6   train_loss = 0.095   time_elapsed = 6441.081   time_remaining = 351\n",
      "Epoch 2846 Batch    6/6   train_loss = 0.093   time_elapsed = 6443.245   time_remaining = 349\n",
      "Epoch 2847 Batch    6/6   train_loss = 0.090   time_elapsed = 6445.408   time_remaining = 346\n",
      "Epoch 2848 Batch    6/6   train_loss = 0.095   time_elapsed = 6447.574   time_remaining = 344\n",
      "Epoch 2849 Batch    6/6   train_loss = 0.094   time_elapsed = 6449.738   time_remaining = 342\n",
      "Epoch 2850 Batch    6/6   train_loss = 0.091   time_elapsed = 6451.906   time_remaining = 340\n",
      "Epoch 2851 Batch    6/6   train_loss = 0.091   time_elapsed = 6454.067   time_remaining = 337\n",
      "Model Trained and Saved\n",
      "Epoch 2852 Batch    6/6   train_loss = 0.094   time_elapsed = 6457.493   time_remaining = 335\n",
      "Epoch 2853 Batch    6/6   train_loss = 0.088   time_elapsed = 6459.658   time_remaining = 333\n",
      "Epoch 2854 Batch    6/6   train_loss = 0.091   time_elapsed = 6461.821   time_remaining = 331\n",
      "Epoch 2855 Batch    6/6   train_loss = 0.096   time_elapsed = 6463.994   time_remaining = 328\n",
      "Epoch 2856 Batch    6/6   train_loss = 0.090   time_elapsed = 6466.161   time_remaining = 326\n",
      "Epoch 2857 Batch    6/6   train_loss = 0.092   time_elapsed = 6468.318   time_remaining = 324\n",
      "Epoch 2858 Batch    6/6   train_loss = 0.095   time_elapsed = 6470.489   time_remaining = 321\n",
      "Epoch 2859 Batch    6/6   train_loss = 0.093   time_elapsed = 6472.648   time_remaining = 319\n",
      "Epoch 2860 Batch    6/6   train_loss = 0.090   time_elapsed = 6474.810   time_remaining = 317\n",
      "Epoch 2861 Batch    6/6   train_loss = 0.090   time_elapsed = 6476.972   time_remaining = 315\n",
      "Model Trained and Saved\n",
      "Epoch 2862 Batch    6/6   train_loss = 0.088   time_elapsed = 6480.280   time_remaining = 312\n",
      "Epoch 2863 Batch    6/6   train_loss = 0.090   time_elapsed = 6482.442   time_remaining = 310\n",
      "Epoch 2864 Batch    6/6   train_loss = 0.089   time_elapsed = 6484.597   time_remaining = 308\n",
      "Epoch 2865 Batch    6/6   train_loss = 0.095   time_elapsed = 6486.760   time_remaining = 306\n",
      "Epoch 2866 Batch    6/6   train_loss = 0.089   time_elapsed = 6488.921   time_remaining = 303\n",
      "Epoch 2867 Batch    6/6   train_loss = 0.094   time_elapsed = 6491.085   time_remaining = 301\n",
      "Epoch 2868 Batch    6/6   train_loss = 0.091   time_elapsed = 6493.251   time_remaining = 299\n",
      "Epoch 2869 Batch    6/6   train_loss = 0.087   time_elapsed = 6495.405   time_remaining = 297\n",
      "Epoch 2870 Batch    6/6   train_loss = 0.094   time_elapsed = 6497.564   time_remaining = 294\n",
      "Epoch 2871 Batch    6/6   train_loss = 0.093   time_elapsed = 6499.728   time_remaining = 292\n",
      "Model Trained and Saved\n",
      "Epoch 2872 Batch    6/6   train_loss = 0.089   time_elapsed = 6503.031   time_remaining = 290\n",
      "Epoch 2873 Batch    6/6   train_loss = 0.082   time_elapsed = 6505.195   time_remaining = 288\n",
      "Epoch 2874 Batch    6/6   train_loss = 0.088   time_elapsed = 6507.345   time_remaining = 285\n",
      "Epoch 2875 Batch    6/6   train_loss = 0.091   time_elapsed = 6509.504   time_remaining = 283\n",
      "Epoch 2876 Batch    6/6   train_loss = 0.088   time_elapsed = 6511.663   time_remaining = 281\n",
      "Epoch 2877 Batch    6/6   train_loss = 0.088   time_elapsed = 6513.815   time_remaining = 278\n",
      "Epoch 2878 Batch    6/6   train_loss = 0.093   time_elapsed = 6515.985   time_remaining = 276\n",
      "Epoch 2879 Batch    6/6   train_loss = 0.087   time_elapsed = 6518.135   time_remaining = 274\n",
      "Epoch 2880 Batch    6/6   train_loss = 0.091   time_elapsed = 6520.296   time_remaining = 272\n",
      "Epoch 2881 Batch    6/6   train_loss = 0.089   time_elapsed = 6522.453   time_remaining = 269\n",
      "Model Trained and Saved\n",
      "Epoch 2882 Batch    6/6   train_loss = 0.092   time_elapsed = 6525.723   time_remaining = 267\n",
      "Epoch 2883 Batch    6/6   train_loss = 0.087   time_elapsed = 6527.886   time_remaining = 265\n",
      "Epoch 2884 Batch    6/6   train_loss = 0.094   time_elapsed = 6530.049   time_remaining = 263\n",
      "Epoch 2885 Batch    6/6   train_loss = 0.090   time_elapsed = 6532.207   time_remaining = 260\n",
      "Epoch 2886 Batch    6/6   train_loss = 0.089   time_elapsed = 6534.361   time_remaining = 258\n",
      "Epoch 2887 Batch    6/6   train_loss = 0.090   time_elapsed = 6536.518   time_remaining = 256\n",
      "Epoch 2888 Batch    6/6   train_loss = 0.090   time_elapsed = 6538.673   time_remaining = 254\n",
      "Epoch 2889 Batch    6/6   train_loss = 0.088   time_elapsed = 6540.824   time_remaining = 251\n",
      "Epoch 2890 Batch    6/6   train_loss = 0.088   time_elapsed = 6542.984   time_remaining = 249\n",
      "Epoch 2891 Batch    6/6   train_loss = 0.090   time_elapsed = 6545.138   time_remaining = 247\n",
      "Model Trained and Saved\n",
      "Epoch 2892 Batch    6/6   train_loss = 0.088   time_elapsed = 6548.406   time_remaining = 245\n",
      "Epoch 2893 Batch    6/6   train_loss = 0.087   time_elapsed = 6550.564   time_remaining = 242\n",
      "Epoch 2894 Batch    6/6   train_loss = 0.091   time_elapsed = 6552.721   time_remaining = 240\n",
      "Epoch 2895 Batch    6/6   train_loss = 0.092   time_elapsed = 6554.881   time_remaining = 238\n",
      "Epoch 2896 Batch    6/6   train_loss = 0.091   time_elapsed = 6557.032   time_remaining = 235\n",
      "Epoch 2897 Batch    6/6   train_loss = 0.089   time_elapsed = 6559.186   time_remaining = 233\n",
      "Epoch 2898 Batch    6/6   train_loss = 0.087   time_elapsed = 6561.341   time_remaining = 231\n",
      "Epoch 2899 Batch    6/6   train_loss = 0.089   time_elapsed = 6563.499   time_remaining = 229\n",
      "Epoch 2900 Batch    6/6   train_loss = 0.093   time_elapsed = 6565.645   time_remaining = 226\n",
      "Epoch 2901 Batch    6/6   train_loss = 0.088   time_elapsed = 6567.796   time_remaining = 224\n",
      "Model Trained and Saved\n",
      "Epoch 2902 Batch    6/6   train_loss = 0.085   time_elapsed = 6571.049   time_remaining = 222\n",
      "Epoch 2903 Batch    6/6   train_loss = 0.088   time_elapsed = 6573.197   time_remaining = 220\n",
      "Epoch 2904 Batch    6/6   train_loss = 0.093   time_elapsed = 6575.345   time_remaining = 217\n",
      "Epoch 2905 Batch    6/6   train_loss = 0.087   time_elapsed = 6577.492   time_remaining = 215\n",
      "Epoch 2906 Batch    6/6   train_loss = 0.089   time_elapsed = 6579.645   time_remaining = 213\n",
      "Epoch 2907 Batch    6/6   train_loss = 0.090   time_elapsed = 6581.796   time_remaining = 211\n",
      "Epoch 2908 Batch    6/6   train_loss = 0.087   time_elapsed = 6583.954   time_remaining = 208\n",
      "Epoch 2909 Batch    6/6   train_loss = 0.087   time_elapsed = 6586.112   time_remaining = 206\n",
      "Epoch 2910 Batch    6/6   train_loss = 0.088   time_elapsed = 6588.269   time_remaining = 204\n",
      "Epoch 2911 Batch    6/6   train_loss = 0.087   time_elapsed = 6590.416   time_remaining = 201\n",
      "Model Trained and Saved\n",
      "Epoch 2912 Batch    6/6   train_loss = 0.088   time_elapsed = 6593.822   time_remaining = 199\n",
      "Epoch 2913 Batch    6/6   train_loss = 0.087   time_elapsed = 6595.965   time_remaining = 197\n",
      "Epoch 2914 Batch    6/6   train_loss = 0.089   time_elapsed = 6598.120   time_remaining = 195\n",
      "Epoch 2915 Batch    6/6   train_loss = 0.094   time_elapsed = 6600.275   time_remaining = 192\n",
      "Epoch 2916 Batch    6/6   train_loss = 0.088   time_elapsed = 6602.424   time_remaining = 190\n",
      "Epoch 2917 Batch    6/6   train_loss = 0.089   time_elapsed = 6604.569   time_remaining = 188\n",
      "Epoch 2918 Batch    6/6   train_loss = 0.089   time_elapsed = 6606.723   time_remaining = 186\n",
      "Epoch 2919 Batch    6/6   train_loss = 0.092   time_elapsed = 6608.871   time_remaining = 183\n",
      "Epoch 2920 Batch    6/6   train_loss = 0.089   time_elapsed = 6611.022   time_remaining = 181\n",
      "Epoch 2921 Batch    6/6   train_loss = 0.085   time_elapsed = 6613.176   time_remaining = 179\n",
      "Model Trained and Saved\n",
      "Epoch 2922 Batch    6/6   train_loss = 0.087   time_elapsed = 6616.443   time_remaining = 177\n",
      "Epoch 2923 Batch    6/6   train_loss = 0.085   time_elapsed = 6618.598   time_remaining = 174\n",
      "Epoch 2924 Batch    6/6   train_loss = 0.090   time_elapsed = 6620.747   time_remaining = 172\n",
      "Epoch 2925 Batch    6/6   train_loss = 0.089   time_elapsed = 6622.890   time_remaining = 170\n",
      "Epoch 2926 Batch    6/6   train_loss = 0.093   time_elapsed = 6625.042   time_remaining = 168\n",
      "Epoch 2927 Batch    6/6   train_loss = 0.091   time_elapsed = 6627.187   time_remaining = 165\n",
      "Epoch 2928 Batch    6/6   train_loss = 0.087   time_elapsed = 6629.342   time_remaining = 163\n",
      "Epoch 2929 Batch    6/6   train_loss = 0.090   time_elapsed = 6631.495   time_remaining = 161\n",
      "Epoch 2930 Batch    6/6   train_loss = 0.089   time_elapsed = 6633.645   time_remaining = 158\n",
      "Epoch 2931 Batch    6/6   train_loss = 0.089   time_elapsed = 6635.802   time_remaining = 156\n",
      "Model Trained and Saved\n",
      "Epoch 2932 Batch    6/6   train_loss = 0.096   time_elapsed = 6639.202   time_remaining = 154\n",
      "Epoch 2933 Batch    6/6   train_loss = 0.085   time_elapsed = 6641.346   time_remaining = 152\n",
      "Epoch 2934 Batch    6/6   train_loss = 0.088   time_elapsed = 6643.503   time_remaining = 149\n",
      "Epoch 2935 Batch    6/6   train_loss = 0.093   time_elapsed = 6645.656   time_remaining = 147\n",
      "Epoch 2936 Batch    6/6   train_loss = 0.090   time_elapsed = 6647.805   time_remaining = 145\n",
      "Epoch 2937 Batch    6/6   train_loss = 0.086   time_elapsed = 6649.955   time_remaining = 143\n",
      "Epoch 2938 Batch    6/6   train_loss = 0.090   time_elapsed = 6652.098   time_remaining = 140\n",
      "Epoch 2939 Batch    6/6   train_loss = 0.090   time_elapsed = 6654.257   time_remaining = 138\n",
      "Epoch 2940 Batch    6/6   train_loss = 0.090   time_elapsed = 6656.405   time_remaining = 136\n",
      "Epoch 2941 Batch    6/6   train_loss = 0.088   time_elapsed = 6658.567   time_remaining = 134\n",
      "Model Trained and Saved\n",
      "Epoch 2942 Batch    6/6   train_loss = 0.088   time_elapsed = 6661.914   time_remaining = 131\n",
      "Epoch 2943 Batch    6/6   train_loss = 0.090   time_elapsed = 6664.062   time_remaining = 129\n",
      "Epoch 2944 Batch    6/6   train_loss = 0.088   time_elapsed = 6666.207   time_remaining = 127\n",
      "Epoch 2945 Batch    6/6   train_loss = 0.084   time_elapsed = 6668.358   time_remaining = 125\n",
      "Epoch 2946 Batch    6/6   train_loss = 0.087   time_elapsed = 6670.502   time_remaining = 122\n",
      "Epoch 2947 Batch    6/6   train_loss = 0.093   time_elapsed = 6672.659   time_remaining = 120\n",
      "Epoch 2948 Batch    6/6   train_loss = 0.087   time_elapsed = 6674.803   time_remaining = 118\n",
      "Epoch 2949 Batch    6/6   train_loss = 0.092   time_elapsed = 6676.956   time_remaining = 115\n",
      "Epoch 2950 Batch    6/6   train_loss = 0.093   time_elapsed = 6679.106   time_remaining = 113\n",
      "Epoch 2951 Batch    6/6   train_loss = 0.090   time_elapsed = 6681.256   time_remaining = 111\n",
      "Model Trained and Saved\n",
      "Epoch 2952 Batch    6/6   train_loss = 0.088   time_elapsed = 6684.512   time_remaining = 109\n",
      "Epoch 2953 Batch    6/6   train_loss = 0.087   time_elapsed = 6686.657   time_remaining = 106\n",
      "Epoch 2954 Batch    6/6   train_loss = 0.097   time_elapsed = 6688.810   time_remaining = 104\n",
      "Epoch 2955 Batch    6/6   train_loss = 0.086   time_elapsed = 6690.960   time_remaining = 102\n",
      "Epoch 2956 Batch    6/6   train_loss = 0.092   time_elapsed = 6693.105   time_remaining = 100\n",
      "Epoch 2957 Batch    6/6   train_loss = 0.086   time_elapsed = 6695.252   time_remaining = 97\n",
      "Epoch 2958 Batch    6/6   train_loss = 0.091   time_elapsed = 6697.392   time_remaining = 95\n",
      "Epoch 2959 Batch    6/6   train_loss = 0.088   time_elapsed = 6699.540   time_remaining = 93\n",
      "Epoch 2960 Batch    6/6   train_loss = 0.090   time_elapsed = 6701.685   time_remaining = 91\n",
      "Epoch 2961 Batch    6/6   train_loss = 0.087   time_elapsed = 6703.833   time_remaining = 88\n",
      "Model Trained and Saved\n",
      "Epoch 2962 Batch    6/6   train_loss = 0.088   time_elapsed = 6707.097   time_remaining = 86\n",
      "Epoch 2963 Batch    6/6   train_loss = 0.091   time_elapsed = 6709.242   time_remaining = 84\n",
      "Epoch 2964 Batch    6/6   train_loss = 0.087   time_elapsed = 6711.389   time_remaining = 82\n",
      "Epoch 2965 Batch    6/6   train_loss = 0.087   time_elapsed = 6713.552   time_remaining = 79\n",
      "Epoch 2966 Batch    6/6   train_loss = 0.089   time_elapsed = 6715.697   time_remaining = 77\n",
      "Epoch 2967 Batch    6/6   train_loss = 0.084   time_elapsed = 6717.844   time_remaining = 75\n",
      "Epoch 2968 Batch    6/6   train_loss = 0.089   time_elapsed = 6719.991   time_remaining = 72\n",
      "Epoch 2969 Batch    6/6   train_loss = 0.091   time_elapsed = 6722.146   time_remaining = 70\n",
      "Epoch 2970 Batch    6/6   train_loss = 0.084   time_elapsed = 6724.294   time_remaining = 68\n",
      "Epoch 2971 Batch    6/6   train_loss = 0.088   time_elapsed = 6726.431   time_remaining = 66\n",
      "Model Trained and Saved\n",
      "Epoch 2972 Batch    6/6   train_loss = 0.087   time_elapsed = 6729.822   time_remaining = 63\n",
      "Epoch 2973 Batch    6/6   train_loss = 0.090   time_elapsed = 6731.972   time_remaining = 61\n",
      "Epoch 2974 Batch    6/6   train_loss = 0.088   time_elapsed = 6734.110   time_remaining = 59\n",
      "Epoch 2975 Batch    6/6   train_loss = 0.089   time_elapsed = 6736.263   time_remaining = 57\n",
      "Epoch 2976 Batch    6/6   train_loss = 0.091   time_elapsed = 6738.408   time_remaining = 54\n",
      "Epoch 2977 Batch    6/6   train_loss = 0.090   time_elapsed = 6740.563   time_remaining = 52\n",
      "Epoch 2978 Batch    6/6   train_loss = 0.092   time_elapsed = 6742.712   time_remaining = 50\n",
      "Epoch 2979 Batch    6/6   train_loss = 0.085   time_elapsed = 6744.849   time_remaining = 48\n",
      "Epoch 2980 Batch    6/6   train_loss = 0.086   time_elapsed = 6746.994   time_remaining = 45\n",
      "Epoch 2981 Batch    6/6   train_loss = 0.088   time_elapsed = 6749.144   time_remaining = 43\n",
      "Model Trained and Saved\n",
      "Epoch 2982 Batch    6/6   train_loss = 0.083   time_elapsed = 6752.461   time_remaining = 41\n",
      "Epoch 2983 Batch    6/6   train_loss = 0.089   time_elapsed = 6754.607   time_remaining = 38\n",
      "Epoch 2984 Batch    6/6   train_loss = 0.091   time_elapsed = 6756.740   time_remaining = 36\n",
      "Epoch 2985 Batch    6/6   train_loss = 0.086   time_elapsed = 6758.887   time_remaining = 34\n",
      "Epoch 2986 Batch    6/6   train_loss = 0.091   time_elapsed = 6761.032   time_remaining = 32\n",
      "Epoch 2987 Batch    6/6   train_loss = 0.088   time_elapsed = 6763.184   time_remaining = 29\n",
      "Epoch 2988 Batch    6/6   train_loss = 0.089   time_elapsed = 6765.329   time_remaining = 27\n",
      "Epoch 2989 Batch    6/6   train_loss = 0.094   time_elapsed = 6767.474   time_remaining = 25\n",
      "Epoch 2990 Batch    6/6   train_loss = 0.090   time_elapsed = 6769.610   time_remaining = 23\n",
      "Epoch 2991 Batch    6/6   train_loss = 0.088   time_elapsed = 6771.753   time_remaining = 20\n",
      "Model Trained and Saved\n",
      "Epoch 2992 Batch    6/6   train_loss = 0.090   time_elapsed = 6775.071   time_remaining = 18\n",
      "Epoch 2993 Batch    6/6   train_loss = 0.091   time_elapsed = 6777.217   time_remaining = 16\n",
      "Epoch 2994 Batch    6/6   train_loss = 0.087   time_elapsed = 6779.362   time_remaining = 14\n",
      "Epoch 2995 Batch    6/6   train_loss = 0.092   time_elapsed = 6781.504   time_remaining = 11\n",
      "Epoch 2996 Batch    6/6   train_loss = 0.088   time_elapsed = 6783.649   time_remaining = 9\n",
      "Epoch 2997 Batch    6/6   train_loss = 0.088   time_elapsed = 6785.798   time_remaining = 7\n",
      "Epoch 2998 Batch    6/6   train_loss = 0.089   time_elapsed = 6787.960   time_remaining = 5\n",
      "Epoch 2999 Batch    6/6   train_loss = 0.090   time_elapsed = 6790.112   time_remaining = 2\n",
      "Epoch 3000 Batch    6/6   train_loss = 0.089   time_elapsed = 6792.258   time_remaining = 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pickle.dump((n_seq, save_dir), open('params.p', 'wb'))\n",
    "batches = gather_batches(corpus_int, n_batch, n_seq)\n",
    "batch_num = len(batches)\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "        \n",
    "        for batch_index, (x, y) in enumerate(batches):\n",
    "            feed_dict = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate\n",
    "            }\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed_dict)\n",
    "            \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}   time_elapsed = {:.3f}   time_remaining = {:.0f}'.format(\n",
    "            epoch + 1,\n",
    "            batch_index + 1,\n",
    "            len(batches),\n",
    "            train_loss,\n",
    "            time_elapsed,\n",
    "            ((batch_num * n_epoch)/((epoch + 1) * (batch_index + 1))) * time_elapsed - time_elapsed))\n",
    "\n",
    " # save model every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.save(sess, save_dir)\n",
    "            print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_word(probabilities, int_to_glossary):\n",
    "    \"\"\"\n",
    "    Pick the next word with some randomness\n",
    "    :param probabilities: Probabilities of the next word\n",
    "    :param int_to_glossary: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    return np.random.choice(list(int_to_glossary.values()), 1, p=probabilities)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "beauty, with your jade self-will which,\n",
      " they know but this half you be:\n",
      " now he she can be dead and all\n",
      " most heard it of thee, i bear my receive.\n",
      " his rose, no own desire would gazed before mine?\n",
      " thus still, were i do i dwell,\n",
      " shall never be lent you for his proud of his heart,\n",
      " 'this private sighs to change quill:\n",
      " dost the banks my weak, now, not cares,\n",
      " thou pray be even\n",
      " showing me convert;\n",
      " i hast thou kept who than thy cruel heart.\n",
      " and these that mine eyes is small cheeks no eternal power\n",
      " shall any fear as tarquin could know;\n",
      " when whose high dies aloft his passion\n",
      " gave twenty posterity is strong,\n",
      " sometimes her victories of remission troth.\n",
      " upon this poor day was turns gone\n",
      " so words and those labour shall make things woo her.\n",
      " post far being hear and from must calls are rest, do even as my sit or fair desire,\n",
      " like many men but put most thine well new,\n",
      " how you is would take my cause of blind.\n",
      " else do i be together,-- my death, or shall confess,\n",
      " yet, i see patience good love's colour shall have your rhyme,\n",
      " since me i was such all or.\n",
      " that which not writ in no weak, and my sweet rhyme.\n",
      " now even thus within you will him commits, old, by thy spirit, my love in foul smooth\n",
      " too much, vile name in thee,\n",
      " or him by beauty, pace the skill embrace mine.\n",
      " and thus, if i impair not hence is but\n",
      "\n",
      " full than love, he come, my foot it then will.\n",
      " the branches of shall shows him a dead,\n",
      " if collatine, full hours so glove\n",
      " bid your soft all prosperous, but friend.\n",
      " my heart of shame; my man,\n",
      " they so him now in one than me:\n",
      " thou art no other in his twain,\n",
      " as your sweet soul, the slave to speak,\n",
      " and had the boar that brief sun with heart.\n",
      "\n",
      " when my love was no like beloved of many her.\n",
      " but thou if your true that loss, to decay;\n",
      " thus must from thy love, anatomized\n",
      " time's honor and a grief.\n",
      " quoth she by lust, to thou wilt have no husband, and for that mine. '\n",
      " i then my sovereign own love my sighs,\n",
      " many bring another grow.\n",
      " say\n",
      " against me love by an bootless bred\n"
     ]
    }
   ],
   "source": [
    "num_words = 500\n",
    "key_word = 'beauty'\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load the saved model\n",
    "    loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
    "    loader.restore(sess, save_dir)\n",
    "    \n",
    "    # Get tensors from loaded graph\n",
    "    input_text = loaded_graph.get_tensor_by_name('input:0')\n",
    "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    \n",
    "    # Sentences generation setup\n",
    "    gen_sentences = key_word.split()\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1 for word in gen_sentences]])})\n",
    "    \n",
    "    # Generate sentences\n",
    "    for n in range(num_words):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[glossary_to_int[word] for word in gen_sentences[-n_seq:]]]\n",
    "        dyn_n_seq = len(dyn_input[0])\n",
    "\n",
    "         # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "\n",
    "        pred_word = select_word(probabilities[0,dyn_n_seq-1,:], int_to_glossary)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "        \n",
    "    # Remove tokens\n",
    "    lit_text = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        lit_text = lit_text.replace(' ' + token.lower(), key)\n",
    "        \n",
    "    print(lit_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "version_dir = './generated-poems'\n",
    "if not os.path.exists(version_dir):\n",
    "    os.makedirs(version_dir)\n",
    "\n",
    "num_poems = len([name for name in os.listdir(version_dir) if os.path.isfile(os.path.join(version_dir, name))])\n",
    "next_poem = version_dir + '/poem-' + str(num_poems + 1) + '.md'\n",
    "with open(next_poem, \"w\") as text_file:\n",
    "    text_file.write(lit_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
